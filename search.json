[{"path":"/articles/components_vignette.html","id":"what-is-a-component-design-matrix","dir":"Articles","previous_headings":"","what":"What is a component design matrix?","title":"Defining model components","text":"linear additive predictor latent Gaussian model can written \\[ \\begin{equation} \\eta(u)_i = u_0 + \\sum_{k=1}^K v_{ik} u_{ik} , \\end{equation} \\] \\(u\\) multivariate Gaussian vector, \\(v_k\\) input information covariates weights random effects \\(= 1, \\ldots, n\\). can also written \\(\\eta(u) = Au\\), \\(\\) model design matrix \\(\\)-th row \\(\\left[1, v_{i1}, \\ldots, v_{iK}\\right]\\). can also conceputally think predictor sum \\(D\\) model components, partition \\(= \\left[^{(1)} \\cdots ^{(D)}\\right]\\), component associated component design matrix \\(^{(d)}\\). example, component intercept parameter, \\(^{(d)} = \\left[1, \\ldots, 1\\right]^\\intercal\\). component linear effect covariate \\(z\\) \\(^{(d)} = \\left[z_1, \\ldots, z_n\\right]^\\intercal\\). complicated effects, SPDE models, component design matrix maps latent Gaussian parameters predictor (also known “projector” matrix context). construction \\(^{(d)}\\) handled automatically bru_mapper methods.","code":""},{"path":"/articles/components_vignette.html","id":"mapper-methods","dir":"Articles","previous_headings":"What is a component design matrix?","what":"Mapper methods","title":"Defining model components","text":"component type associated method converting information given component definition component design matrix. full model design matrix used internally call INLA::inla() fit model. advantage specifying mapper methods supports automatic ‘stack building’. key feature inlabru full model stack constructed automatically component definitions. building blocks stack built using bru_mapper methods.","code":""},{"path":"/articles/components_vignette.html","id":"mapper-example-2d-spde","dir":"Articles","previous_headings":"What is a component design matrix? > Mapper methods","what":"Mapper example: 2D SPDE","title":"Defining model components","text":"mapper 2D SPDE effect takes input 2-column matrix coordinates represent locations evaluate effect. parameters SPDE component defined mesh nodes may locations effect evaluated. appropriate weights required evaluate effect observation locations can constructed using INLA::inla.spde.make.(). mapper model component takes information component definition, case minimum information required SPDE model object, 2-column matrix main evaluated . mapper calls INLA::inla.spde.make.() appropriate arguments extracted information. (NOTE: Deliberately going huge detail ; bru_mapper vignette details.)","code":""},{"path":"/articles/components_vignette.html","id":"defining-main-group-and-replicate-","dir":"Articles","previous_headings":"What is a component design matrix?","what":"Defining main, group, and replicate.","title":"Defining model components","text":"arguments main, group, replicate can take general R expression input. expression evaluated environment consists named variables data (note: sp objects includes column names @coords slot well columns @data). names found data global environment searched objects name. example, suppose data columns named x y, 2D SPDE model component specified expression cbind(x,y) internally evaluated environment contains columns data, includes variables x y. full data object can accessed using .data. key-word. equivalent way define component keyword allows code written works arbitrarily named input data, rather hardcoding specific name dataset may change future. objects required evaluate R expression found data, global environment searched. allows users access objects global environment, data-structures may different dimension response data. avoids need pre-process everything single data.frame. functionality allowing general R expressions can used extend types data can passed bru(), like() lgcp() functions. basis support spatial data structures sp objects, also experimental support allow users pass data list. inlabru thus readily extendible, given appropriate functions extract relevant information component, associated mappers convert information component design matrix.","code":"~ my_spde_effect(main = cbind(x,y),                  model = spde_model) get_xy = function(df){   cbind(df$x, df$y) } ~ my_spde_effect(main = get_xy(.data.),                  model = spde_model)"},{"path":"/articles/components_vignette.html","id":"inlabru-specific-component-types","dir":"Articles","previous_headings":"What is a component design matrix?","what":"inlabru-specific component types","title":"Defining model components","text":"addition majority latent models can defined using INLA::f() function (see INLA::inla.list.models()$latent)), inlabru also following models: 'linear', 'fixed', 'offset', 'factor_full' 'factor_contrast'). (NOTE: put documentation things? ?component . add ? can implement inlabru.list.models() function?)","code":""},{"path":"/articles/components_vignette.html","id":"shortcuts","dir":"Articles","previous_headings":"","what":"Shortcuts","title":"Defining model components","text":"shortcuts defining model components. Parameters predictor evaluations (intercept-like parameters). Using covariate stored sp Spatial* object. Defining linear effects using lm-style syntax. Behaviour main, group replicate function given arguments.","code":""},{"path":"/articles/components_vignette.html","id":"intercept-like-components","dir":"Articles","previous_headings":"Shortcuts","what":"Intercept-like components","title":"Defining model components","text":"syntax can used shortcut n length predictor vector. Note shortcut makes assumption approriate length predictor. many models can easily deduced inspecting input data, always case, example response covariate data different dimensions joint likelihood models shared components.","code":"~ my_intercept(1) ~ my_intercept(main = rep(1, n),                model = \"linear\")"},{"path":"/articles/components_vignette.html","id":"sp-covariates","dir":"Articles","previous_headings":"Shortcuts","what":"sp covariates","title":"Defining model components","text":"main, group, replicate, name sp object stored global R environment, inlabru attempts something intelligent extracting covariate information locations data passed bru() like(). case assumed data also sp object. inlabru applying sp::coordinates() data extracting covariate information using sp::(). shorcut internally calls eval_spatial() almost equivalent Note requires an_sp_object stored global R environment (environment associated model definition code) findable expression internally evaluated inlabru. Also note get_sp_covariate function extract first column sp object evaluation. general situations, one can either specify optional main_layer argument extract another named indexed column, directly use main = eval_spatial(an_sp_object, .data., layer = some_layer). Note assumes coordinates() applied input data sensible thing , might case models! example, input data SpatialPolygonsDataFrame coordinates() returns centroid polygon. specific input type support developed, special cases may given precise meaning.","code":"~ my_sp_effect(main = an_sp_object,                model = \"linear\") get_sp_covariate = function(df){   locs = coordinates(df)   over(locs, an_sp_object)[,1] }  ~ my_sp_effect(main = get_sp_covariate(.data.),                model = \"linear\")"},{"path":"/articles/components_vignette.html","id":"lm-style-syntax","dir":"Articles","previous_headings":"Shortcuts","what":"lm-style syntax","title":"Defining model components","text":"Since inlabru version 2.5.0, feature added allow users specify linear fixed effects using formula input. uses model = 'fixed' component type. syntax data columns named x1, x2, x3, x4. case, inlabru creates design matrix component running allows users define interactions concise way, utilising functionality already supported MatrixModels package. formula interpreted conventional way, x1:x2 interaction covariates x1 x2, including individual fixed effects, x3:x4 interaction x3 x4 inclusive individual fixed effects x3 x4. Note implementation technical reasons, estimated parameters appear 'summary.random' instead normal 'summary.fixed' part inla/bru output object. alternative using shortcut user define name individual components term formula.","code":"~ my_fixed_effects(main = ~ x1:x2 + x3*x4,                    model = 'fixed') MatrixModels::model.Matrix(~ x1:x2 + x3*x4, .data.)"},{"path":"/articles/components_vignette.html","id":"a-function-given-with-no-arguments","dir":"Articles","previous_headings":"Shortcuts","what":"A function given with no arguments","title":"Defining model components","text":"main, group, replicate given function covariates, function applied data. example, equivalent ","code":"~ a_component(main = a_function,               model = ...) ~ a_component(main = a_function(.data.),               model = ...)"},{"path":"/articles/components_vignette.html","id":"non-linear-predictors","dir":"Articles","previous_headings":"Shortcuts","what":"Non-linear predictors","title":"Defining model components","text":"inlabru supports non-linear predictors, \\(\\tilde{\\eta}(u)\\) non-linear function \\(u\\). important note mapping predictor vector \\(Au\\) happens non-linear function applied. , example, \\(\\tilde{\\eta}(u) = \\exp(u)\\) evaluated exp(%*% u) rather %*% exp(u).","code":""},{"path":"/articles/devel_mapper.html","id":"mappers-for-inla-mesh-objects-and-mapper-extractors","dir":"Articles","previous_headings":"","what":"Mappers for inla.mesh objects and mapper extractors","title":"Devel: Customised model components with the bru_mapper system","text":"component models referenced character label (e.g. \"iid\", \"bym2\", \"rw2\" etc), inlabru construct default mappers, cases replicate default INLA::f() behaviour. inla.mesh inla.mesh.1d classes, default mappers can constructed pre-defined bru_mapper S3 methods. 2d meshes (inla.mesh), 1d meshes (inla.mesh.1d), inla.spde inla.rgeneric model objects","code":"bru_mapper(mesh) # If ibm_values() should return mesh$loc (e.g. for \"rw2\" models with degree=1 meshes) bru_mapper(mesh, indexed = FALSE) # If ibm_values() should return seq_along(mesh$loc) (e.g. for inla.spde2.pcmatern() models) bru_mapper(mesh, indexed = TRUE) bru_get_mapper"},{"path":"/articles/devel_mapper.html","id":"customised-mappers","dir":"Articles","previous_headings":"","what":"Customised mappers","title":"Devel: Customised model components with the bru_mapper system","text":"","code":"bru_mapper_define"},{"path":"/articles/devel_mapper.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"Devel: Customised model components with the bru_mapper system","text":"Let’s build mapper class bru_mapper_p_quadratic model component takes input covariates values \\(a_{ij}\\), \\(=1,\\dots,m\\) \\(j=1,\\dots,p\\), matrix data.frame evaluates full quadratic expression \\[ \\eta_i = x_0 + \\sum_{j=1}^p a_{ij} x_j +   \\frac{1}{2}\\sum_{j=1}^p\\sum_{k=1}^j \\gamma_{j,k} a_{ij}a_{ik} x_{j,k}, \\] latent component vector \\(\\boldsymbol{x}=[x_0,x_1,\\dots,x_p,x_{1,1},\\dots,x_{p,1},x_{2,2}\\dots,x_{p,p}]\\), \\[ \\gamma_{j,k} = \\begin{cases} 1, & j = k,\\\\ 2, & j > k. \\end{cases} \\] start constructor method. Like bru_mapper_matrix, require user supply vector covariate labels, store character vector. also include min_degree parameter control intercept (min_degree <= 0) linear terms (min_degree <= 1) included model. ibm_n method can compute value \\(n\\) \\(n=1+p+\\frac{p(p+1)}{2}\\): ibm_values, default method sufficient, returning vector \\([1,\\dots,n]\\) \\(n\\) obtained ibm_n(mapper). However, clearer result naming, can use character vector, least INLA f() models allow (option argument bru_mapper_p_quadratic constructor control ): can now define main part mapper interface computes model matrix linking latent variables component effect. ’s required NULL input return \\(0\\)--\\(n\\) matrix.","code":"bru_mapper_p_quadratic <- function(labels, min_degree = 0, ...) {   if (is.factor(labels)) {     mapper <- list(       labels = levels(labels),       min_degree = min_degree     )   } else {     mapper <- list(       labels = as.character(labels),       min_degree = min_degree     )   }   bru_mapper_define(mapper, new_class = \"bru_mapper_p_quadratic\") } ibm_n.bru_mapper_p_quadratic <- function(mapper, ...) {   p <- length(mapper$labels)   (mapper$min_degree <= 0) + (mapper$min_degree <= 1) * p + p * (p + 1) / 2 } ibm_values.bru_mapper_p_quadratic <- function(mapper, ...) {   p <- length(mapper$labels)   n <- ibm_n(mapper)   jk <- expand.grid(seq_len(p), seq_len(p))   jk <- jk[jk[, 2] <= jk[, 1], , drop = FALSE]   c(if (mapper$min_degree <= 0) \"Intercept\" else NULL,     if (mapper$min_degree <= 1) mapper$labels else NULL,     paste0(mapper$labels[jk[, 1]], \":\", mapper$labels[jk[, 2]])) } ibm_amatrix.bru_mapper_p_quadratic <- function(mapper, input, ...) {   if (is.null(input)) {     return(Matrix::Matrix(0, 0, ibm_n(mapper)))   }   p <- length(mapper$labels)   n <- ibm_n(mapper)   N <- NROW(input)   A <- list()   in_ <- as(input, \"Matrix\")   idx <- 0   if (mapper$min_degree <= 0) {     idx <- idx + 1     A[[idx]] <- Matrix::Matrix(1, N)   }   if (mapper$min_degree <= 1) {     idx <- idx + 1     A[[idx]] <- in_   }   for (k in seq_len(p)) {     idx <- idx + 1     A[[idx]] <- in_[, seq(k, p, by = 1), drop = FALSE] * in_[, k]     A[[idx]][, k] <- A[[idx]][, k] / 2   }   A <- do.call(cbind, A)   colnames(A) <- as.character(ibm_values(mapper))   A }"},{"path":"/articles/linearapprox.html","id":"a-small-toy-problem","dir":"Articles","previous_headings":"","what":"A small toy problem","title":"Nonlinear model approximation","text":"Hierarchical model: \\[ \\begin{aligned} \\lambda &\\sim \\mathsf{Exp}(\\gamma) \\\\ (y_i|\\lambda) &\\sim \\mathsf{Po}(\\lambda), \\text{ independent across $=1,\\dots,n$} \\end{aligned} \\] \\(\\overline{y}=\\frac{1}{n}\\sum_{=1}^n y_i\\), posterior density \\[ \\begin{aligned} p(\\lambda | \\{y_i\\}) &\\propto p(\\lambda, y_1,\\dots,y_n) \\\\ &\\propto \\exp(-\\gamma\\lambda) \\exp(-n\\lambda) \\lambda^{n\\overline{y}} \\\\ &= \\exp\\{-(\\gamma+n)\\lambda\\} \\lambda^{n\\overline{y}}, \\end{aligned} \\] density \\(\\mathsf{Ga}(\\alpha = 1+n\\overline{y}, \\beta = \\gamma+n)\\) distribution.","code":""},{"path":"/articles/linearapprox.html","id":"latent-gaussian-predictor-version","dir":"Articles","previous_headings":"","what":"Latent Gaussian predictor version","title":"Nonlinear model approximation","text":"Introducing latent Gaussian variable \\(u\\sim\\mathsf{N}(0,1)\\), model can reformulated \\[ \\begin{aligned} \\lambda(u) &=-\\ln\\{1-\\Phi(u)\\}/\\gamma \\\\ (y_i|u) &\\sim \\mathsf{Po}(\\lambda(u)) \\end{aligned} \\] need derivatives \\(\\lambda\\) respect \\(u\\): \\[ \\begin{aligned} \\frac{\\partial\\lambda(u)}{\\partial u} &= \\frac{1}{\\gamma}\\frac{\\phi(u)}{1-\\Phi(u)}   = \\lambda'(u) \\\\ \\frac{\\partial^2\\lambda(u)}{\\partial u^2} &= - \\frac{1}{\\gamma}\\frac{\\phi(u)}{1-\\Phi(u)} \\left( u + \\frac{\\phi(u)}{1-\\Phi(u)} \\right) = -\\lambda'(u)\\left\\{u-\\gamma\\lambda'(u)\\right\\} \\\\ \\frac{\\partial\\ln\\lambda(u)}{\\partial u} &=   \\frac{1}{\\lambda(u)} \\frac{\\partial\\lambda(u)}{\\partial u}   =\\frac{1}{-\\ln\\{1-\\Phi(u)\\}} \\frac{\\phi(u)}{1-\\Phi(u)}   = \\frac{\\lambda'(u)}{\\lambda(u)} \\\\ \\frac{\\partial^2\\ln\\lambda(u)}{\\partial u^2} &=   \\frac{1}{\\lambda(u)} \\frac{\\partial^2\\lambda(u)}{\\partial u^2}   -\\frac{1}{\\lambda(u)^2} \\left(\\frac{\\partial\\lambda(u)}{\\partial u}\\right)^2   = \\frac{-\\lambda'(u)\\{u - \\gamma\\lambda'(u)\\}}{\\lambda(u)}   - \\frac{\\lambda'(u)^2}{\\lambda(u)^2}\\\\   &= -\\frac{\\lambda'(u)}{\\lambda(u)}\\left\\{   u - \\gamma\\lambda'(u) +\\frac{\\lambda'(u)}{\\lambda(u)}   \\right\\} \\end{aligned} \\]","code":"lambda <- function(u, gamma) {    -pnorm(u, lower.tail = FALSE, log.p = TRUE) / gamma } lambda_inv <- function(lambda, gamma) {   qnorm(-lambda * gamma, lower.tail = FALSE, log.p = TRUE) } D1lambda <- function(u, gamma) {   exp(dnorm(u, log = TRUE) - pnorm(u, lower.tail = FALSE, log.p = TRUE)) / gamma } D2lambda <- function(u, gamma) {   D1L <- D1lambda(u, gamma)   -D1L * (u - gamma * D1L) } D1log_lambda <- function(u, gamma) {   D1lambda(u, gamma) / lambda(u, gamma) }   D2log_lambda <- function(u, gamma) {   D1logL <- D1log_lambda(u, gamma)   -D1logL * (u - gamma * D1lambda(u, gamma = gamma) + D1logL) }"},{"path":"/articles/linearapprox.html","id":"latent-gaussian-posterior-approximations","dir":"Articles","previous_headings":"","what":"Latent Gaussian posterior approximations","title":"Nonlinear model approximation","text":"basic approximation posterior distribution \\(\\lambda\\) given \\(y\\) can defined deterministic transformation Gaussian distribution obtained 2nd order Taylor approximation \\(\\ln p(u|\\{y_i\\})\\) posterior mode \\(u_0\\) \\(p(u|\\{y_i\\})\\). needed derivatives \\[ \\begin{aligned} \\frac{\\partial\\ln p(u|\\{y_i\\})}{\\partial u} &= \\frac{\\partial\\ln\\phi(u)}{\\partial u} - n\\lambda'(u) + n\\overline{y}\\frac{\\lambda'(u)}{\\lambda(u)} = -u + n\\frac{\\lambda'(u)}{\\lambda(u)}\\left\\{ \\overline{y} - \\lambda(u) \\right\\} \\\\ \\frac{\\partial^2\\ln p(u|\\{y_i\\})}{\\partial u^2} &= -1 - n \\frac{\\lambda'(u)}{\\lambda(u)}\\left\\{ u - \\gamma\\lambda'(u) + \\frac{\\lambda'(u)}{\\lambda(u)} \\right\\} \\left\\{ \\overline{y} - \\lambda(u) \\right\\} - n \\frac{\\lambda'(u)^2}{\\lambda(u)} \\end{aligned} \\] mode \\(u_0\\), first order derivative zero, \\[ \\begin{aligned} \\left.\\frac{\\partial^2\\ln p(u|\\{y_i\\})}{\\partial u^2}\\right|_{u=u_0} &= -1 - \\left\\{ u_0 - \\gamma\\lambda'(u_0) + \\frac{\\lambda'(u_0)}{\\lambda(u_0)} \\right\\} u_0 - n \\frac{\\lambda'(u_0)^2}{\\lambda(u_0)} . \\end{aligned} \\] quadratic approximation log-posterior density mode \\(u_0\\) \\[ \\ln \\breve{p}(u|\\{y_i\\}) = \\text{const} - \\frac{(u-u_0)^2}{2} \\left[ - \\left.\\frac{\\partial^2\\ln p(u|\\{y_i\\})}{\\partial u^2}\\right|_{u=u_0} \\right] \\] inlabru, approximation first linearises \\(\\ln \\lambda(u)\\) \\(u_0\\) applying Taylor approximation \\(\\ln p(u|\\{y_i\\})\\). linearised log-predictor \\[ \\ln \\overline{\\lambda}(u) = \\ln \\lambda(u_0) + \\frac{\\lambda'(u_0)}{\\lambda(u_0)}(u - u_0) \\] \\[ \\overline{\\lambda}'(u) = \\frac{\\lambda'(u_0)}{\\lambda(u_0)} \\overline{\\lambda}(u) \\] second order derivative linearised log-posterior density \\[ \\begin{aligned} \\left.\\frac{\\partial^2\\ln \\overline{p}(u|\\{y_i\\})}{\\partial u^2}\\right|_{u=u_0} &= -1 - n \\frac{\\lambda'(u_0)^2}{\\lambda(u_0)} . \\end{aligned} \\]","code":"log_p <- function(u, y, gamma) {   L <- lambda(u, gamma)   n <- length(y)   dnorm(u, log = TRUE) - n * L + n * mean(y) * log(L) - sum(lgamma(y + 1)) } D1log_p <- function(u, y, gamma) {   n <- length(y)   -u + n * D1log_lambda(u, gamma) * (mean(y) - lambda(u, gamma)) } D2log_p <- function(u, y, gamma) {   n <- length(y)   -1 +     n * D2log_lambda(u, gamma) * (mean(y) - lambda(u, gamma)) -     n * D1log_lambda(u, gamma) * D1lambda(u, gamma) } g <- 1 y <- c(0,1,2) y <- c(0, 0, 0,0,0) y <- rpois(5, 5) mu_quad <- uniroot(D1log_p, lambda_inv((1 + sum(y)) / (g + length(y)) * c(1/10, 10), gamma = g),                    y = y, gamma = g)$root sd_quad <- (-D2log_p(mu_quad, y = y, gamma = g))^-0.5 sd_lin <- (1 + length(y) * D1log_lambda(mu_quad, gamma = g)^2 * lambda(mu_quad, gamma = g))^-0.5 lambda0 <- lambda(mu_quad, gamma = g)"},{"path":"/articles/linearapprox.html","id":"posterior-densities","dir":"Articles","previous_headings":"Latent Gaussian posterior approximations","what":"Posterior densities","title":"Nonlinear model approximation","text":"","code":"ggplot() +   xlim(     lambda(mu_quad - 4 * sd_quad, gamma = g),     lambda(mu_quad + 4 * sd_quad, gamma = g)   ) +   xlab(\"lambda\") +   ylab(\"Density\") +   geom_function(     fun = function(x) {       exp(log_p(lambda_inv(x, gamma = g), y = y, gamma = g)) /         D1lambda(lambda_inv(x, gamma = g), gamma = g) / (           exp(log_p(lambda_inv(lambda0, gamma = g), y = y, gamma = g)) /             D1lambda(lambda_inv(lambda0, gamma = g), gamma = g)         ) *         dgamma(lambda0, shape = 1 + sum(y), rate = g + length(y))     },     mapping = aes(col = \"Theory\"),     n = 1000   ) +   geom_function(     fun = dgamma,     args = list(shape = 1 + sum(y), rate = g + length(y)),     mapping = aes(col = \"Theory\"),     n = 1000   ) +   geom_function(     fun = function(x) {       dnorm(lambda_inv(x, gamma = g), mean = mu_quad, sd = sd_quad) /         D1lambda(lambda_inv(x, gamma = g), gamma = g)     },     mapping = aes(col = \"Quadratic\"),     n = 1000   ) +   geom_function(     fun = function(x) {       dnorm(lambda_inv(x, gamma = g), mean = mu_quad, sd = sd_lin) /         D1lambda(lambda_inv(x, gamma = g), gamma = g)       },     mapping = aes(col = \"Linearised\"),     n = 1000     ) +   geom_vline(mapping = aes(xintercept = (1 + sum(y)) / (g + length(y)),                            lty = \"Bayes mean\")) +   geom_vline(mapping = aes(xintercept = lambda0, lty = \"Bayes mode\")) +   geom_vline(mapping = aes(xintercept = mean(y), lty = \"Plain mean\")) ggplot() +   xlim(     lambda_inv(lambda0, gamma = g) - 4 * sd_quad,     lambda_inv(lambda0, gamma = g) + 4 * sd_quad   ) +   xlab(\"u\") +   ylab(\"Density\") +   geom_function(     fun = function(x) {       exp(log_p(x, y = y, gamma = g) -             log_p(lambda_inv(lambda0, gamma = g), y = y, gamma = g)) *         (dgamma(lambda0, shape = 1 + sum(y), rate = g + length(y)) *            D1lambda(lambda_inv(lambda0, gamma = g), gamma = g))       },     mapping = aes(col = \"Theory\"),     n = 1000) +   geom_function(     fun = function(x) {       dgamma(lambda(x, gamma = g), shape = 1 + sum(y), rate = g + length(y)) *         D1lambda(x, gamma = g)     },     mapping = aes(col = \"Theory\"),     n = 1000   ) +   geom_function(     fun = dnorm,     args = list(mean = mu_quad, sd = sd_quad),     mapping = aes(col = \"Quadratic\"),     n = 1000   ) +   geom_function(     fun = dnorm,     args = list(mean = mu_quad, sd = sd_lin),     mapping = aes(col = \"Linearised\"),     n = 1000   ) +   geom_vline(mapping = aes(xintercept = lambda_inv((1 + sum(y)) / (g + length(y)),                                      gamma = g), lty = \"Bayes mean\")) +   geom_vline(mapping = aes(xintercept = lambda_inv(lambda0, gamma = g), lty = \"Bayes mode\")) +   geom_vline(mapping = aes(xintercept = lambda_inv(mean(y), gamma = g), lty = \"Plain mean\"))"},{"path":"/articles/linearapprox.html","id":"posterior-cdfs","dir":"Articles","previous_headings":"Latent Gaussian posterior approximations","what":"Posterior CDFs","title":"Nonlinear model approximation","text":"","code":"ggplot() +   xlim(     lambda(mu_quad - 4 * sd_quad, gamma = g),     lambda(mu_quad + 4 * sd_quad, gamma = g)   ) +   xlab(\"lambda\") +   ylab(\"CDF\") +   geom_function(     fun = pgamma,     args = list(shape = 1 + sum(y), rate = g + length(y)),     mapping = aes(col = \"Theory\"),     n = 1000   ) +   geom_function(     fun = function(x) {       pnorm(lambda_inv(x, gamma = g), mean = mu_quad, sd = sd_quad)     },     mapping = aes(col = \"Quadratic\"),     n = 1000   ) +   geom_function(     fun = function(x) {       pnorm(lambda_inv(x, gamma = g), mean = mu_quad, sd = sd_lin)       },     mapping = aes(col = \"Linearised\"),     n = 1000     ) +   geom_vline(mapping = aes(xintercept = (1 + sum(y)) / (g + length(y)),                            lty = \"Bayes mean\")) +   geom_vline(mapping = aes(xintercept = lambda0, lty = \"Bayes mode\")) +   geom_vline(mapping = aes(xintercept = mean(y), lty = \"Plain mean\")) ggplot() +   xlim(     lambda_inv(lambda0, gamma = g) - 4 * sd_quad,     lambda_inv(lambda0, gamma = g) + 4 * sd_quad   ) +   xlab(\"u\") +   ylab(\"CDF\") +   geom_function(     fun = function(x) {       pgamma(lambda(x, gamma = g), shape = 1 + sum(y), rate = g + length(y))     },     mapping = aes(col = \"Theory\"),     n = 1000   ) +   geom_function(     fun = pnorm,     args = list(mean = mu_quad, sd = sd_quad),     mapping = aes(col = \"Quadratic\"),     n = 1000   ) +   geom_function(     fun = pnorm,     args = list(mean = mu_quad, sd = sd_lin),     mapping = aes(col = \"Linearised\"),     n = 1000   ) +   geom_vline(mapping = aes(     xintercept = lambda_inv((1 + sum(y)) / (g + length(y)),                             gamma = g),     lty = \"Bayes mean\")) +   geom_vline(mapping = aes(xintercept = lambda_inv(lambda0, gamma = g),                            lty = \"Bayes mode\")) +   geom_vline(mapping = aes(xintercept = lambda_inv(mean(y), gamma = g),                            lty = \"Plain mean\"))"},{"path":"/articles/method.html","id":"the-inla-method-for-linear-predictors","dir":"Articles","previous_headings":"","what":"The INLA method for linear predictors","title":"Iterative linearised INLA method","text":"INLA method used compute fast approximative posterior distribution Bayesian generalised additive models. hierarchical structure model latent Gaussian components \\(\\boldsymbol{u}\\), covariance parameters \\(\\boldsymbol{\\theta}\\), measured response variables \\(\\boldsymbol{y}\\), can written \\[ \\begin{aligned} \\boldsymbol{\\theta} &\\sim p(\\boldsymbol{\\theta}) \\\\ \\boldsymbol{u}|\\boldsymbol{\\theta} &\\sim \\mathcal{N}\\!\\left(\\boldsymbol{\\mu}_u, \\boldsymbol{Q}(\\boldsymbol{\\theta})^{-1}\\right) \\\\ \\boldsymbol{\\eta}(\\boldsymbol{u}) &= \\boldsymbol{}\\boldsymbol{u} \\\\ \\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta} & \\sim p(\\boldsymbol{y}|\\boldsymbol{\\eta}(\\boldsymbol{u}),\\boldsymbol{\\theta}) \\end{aligned} \\] typically linear predictor element, \\(\\eta_i(\\boldsymbol{u})\\), linked location parameter distribution observation \\(y_i\\), \\(\\), via (non-linear) link function \\(g^{-1}(\\cdot)\\). R-INLA implementation, observations assumed conditionally independent, given \\(\\boldsymbol{\\eta}\\) \\(\\boldsymbol{\\theta}\\).","code":""},{"path":"/articles/method.html","id":"approximate-inla-for-non-linear-predictors","dir":"Articles","previous_headings":"","what":"Approximate INLA for non-linear predictors","title":"Iterative linearised INLA method","text":"premise inlabru method non-linear predictors build existing implementation, add linearisation step. properties resulting approximation depend nature non-linearity. Let \\(\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u})\\) non-linear predictor, .e. deterministic function \\(\\boldsymbol{u}\\), \\[ \\widetilde{\\boldsymbol{\\eta}} (\\boldsymbol{u}) = \\textsf{fcn} (\\boldsymbol{u}), \\] let \\(\\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u})\\) 1st order Taylor approximation \\(\\boldsymbol{u}_0\\), \\[ \\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u}) = \\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}_0) + \\boldsymbol{B}(\\boldsymbol{u} - \\boldsymbol{u}_0) = \\left[\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}_0) - \\boldsymbol{B}\\boldsymbol{u}_0\\right] + \\boldsymbol{B}\\boldsymbol{u} , \\] \\(\\boldsymbol{B}\\) derivative matrix non-linear predictor, evaluated \\(\\boldsymbol{u}_0\\). Hence, define \\[ \\begin{aligned} \\boldsymbol{y} | \\boldsymbol{u}, {\\boldsymbol{\\theta}} &\\overset{d}{=} \\boldsymbol{y} | \\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}), {\\boldsymbol{\\theta}} \\\\ &\\sim p (\\boldsymbol{y} | g^{-1}[\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u})], {\\boldsymbol{\\theta}})\\\\ \\end{aligned} \\] non-linear observation model \\(p(\\boldsymbol{y}|g^{-1}[\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u})],\\boldsymbol{\\theta})\\) approximated replacing non-linear predictor linearisation, linearised model defined \\[ \\overline{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta}) = p(\\boldsymbol{y}|\\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u}),\\boldsymbol{\\theta}) = p(\\boldsymbol{y}|g^{-1}[\\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u})],\\boldsymbol{\\theta}) \\approx p(\\boldsymbol{y}|g^{-1}[\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u})],\\boldsymbol{\\theta}) = p(\\boldsymbol{y}|\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}),\\boldsymbol{\\theta}) = \\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta}) \\] non-linear model posterior factorised \\[ \\widetilde{p}(\\boldsymbol{\\theta},\\boldsymbol{u}|\\boldsymbol{y}) = \\widetilde{p}(\\boldsymbol{\\theta}|\\boldsymbol{y})\\widetilde{p}(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta}), \\] linear model approximation factorised \\[ \\overline{p}(\\boldsymbol{\\theta},\\boldsymbol{u}|\\boldsymbol{y}) = \\overline{p}(\\boldsymbol{\\theta}|\\boldsymbol{y})\\overline{p}(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta}). \\]","code":""},{"path":"/articles/method.html","id":"fixed-point-iteration","dir":"Articles","previous_headings":"Approximate INLA for non-linear predictors","what":"Fixed point iteration","title":"Iterative linearised INLA method","text":"remaining step approximation choose linearisation point \\(\\boldsymbol{u}_*\\). given linearisation point \\(\\boldsymbol{v}\\), INLA compute posterior mode \\(\\boldsymbol{\\theta}\\), \\[ \\widehat{\\boldsymbol{\\theta}}_{\\boldsymbol{v}} = \\mathop{\\mathrm{arg\\,max}}_{\\boldsymbol{\\theta}} \\overline{p}_\\boldsymbol{v} ( {\\boldsymbol{\\theta}} | \\boldsymbol{y} ), \\] joint conditional posterior mode \\(\\boldsymbol{u}\\), \\[ \\widehat{\\boldsymbol{u}}_{\\boldsymbol{v}} = \\mathop{\\mathrm{arg\\,max}}_{\\boldsymbol{u}} \\overline{p}_\\boldsymbol{v} ( \\boldsymbol{u} | \\boldsymbol{y}, \\widehat{\\boldsymbol{\\theta}}_{\\boldsymbol{v}} ) . \\] Define Bayesian estimation functional1 \\[ f(\\overline{p}_{\\boldsymbol{v}}) = (\\widehat{\\boldsymbol{\\theta}}_{\\boldsymbol{v}},\\widehat{\\boldsymbol{u}}_{\\boldsymbol{v}}) \\] let \\(f(p)=(\\widehat{\\boldsymbol{\\theta}},\\widehat{\\boldsymbol{u}})\\) denote corresponding posterior modes true posterior distribution, \\[ \\begin{aligned}     \\widehat{{\\boldsymbol{\\theta}}} &= \\mathop{\\mathrm{arg\\,max}}_{\\boldsymbol{\\theta}} p ( {\\boldsymbol{\\theta}} | \\boldsymbol{y} ), \\\\     \\widehat{\\boldsymbol{u}} &= \\mathop{\\mathrm{arg\\,max}}_{\\boldsymbol{u}} p (\\boldsymbol{u} | \\boldsymbol{y}, \\widehat{{\\boldsymbol{\\theta}}}). \\end{aligned} \\] fixed point \\((\\boldsymbol{\\theta}_*,\\boldsymbol{u}_*)=f(\\overline{p}_{\\boldsymbol{u}_*})\\) ideally close \\((\\widehat{\\boldsymbol{\\theta}},\\widehat{\\boldsymbol{u}})\\), .e. close true marginal/conditional posterior mode. can achieve conditional latent mode, \\(\\boldsymbol{u}_*=\\mathop{\\mathrm{arg\\,max}}_{\\boldsymbol{u}} p (\\boldsymbol{u} | \\boldsymbol{y}, \\widehat{\\boldsymbol{\\theta}}_{\\boldsymbol{u}_*})\\). therefore seek latent vector \\(\\boldsymbol{u}_*\\) generates fixed point functional, \\((\\boldsymbol{\\theta}_*,\\boldsymbol{u}_*)=f(\\overline{p}_{\\boldsymbol{u}_*})\\). One key fixed point iteration observation model linked \\(\\boldsymbol{u}\\) non-linear predictor \\(\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u})\\), since leads simplified line search method . Let \\(\\boldsymbol{u}_0\\) initial linearisation point latent variables obtained initial INLA call. Iterate following steps \\(k=0,1,2,...\\) Compute predictor linearisation \\(\\boldsymbol{u}_0\\). Compute linearised INLA posterior \\(\\overline{p}_{\\boldsymbol{u}_0}(\\boldsymbol{\\theta}|\\boldsymbol{y})\\). Let \\((\\boldsymbol{\\theta}_1,\\boldsymbol{u}_1)=(\\widehat{\\boldsymbol{\\theta}}_{\\boldsymbol{u}_0},\\widehat{\\boldsymbol{u}}_{\\boldsymbol{u}_0})=f(\\overline{p}_{\\boldsymbol{u}_0})\\) initial candidate new linearisation point. Let \\(\\boldsymbol{v}_\\alpha=(1-\\alpha)\\boldsymbol{u}_1+\\alpha\\boldsymbol{u}_0\\), find value \\(\\alpha\\) minimises \\(\\|\\widetilde{\\eta}(\\boldsymbol{v}_\\alpha)-\\overline{\\eta}(\\boldsymbol{u}_1)\\|\\). Set new linearisation point \\(\\boldsymbol{u}_0\\) equal \\(\\boldsymbol{v}_\\alpha\\) repeat step 1, unless iteration converged given tolerance. potential improvement step 4 might also take account prior distribution \\(\\boldsymbol{u}\\) minimisation penalty, avoid moving indicated full likelihood optimisation.","code":""},{"path":"/articles/method.html","id":"line-search","dir":"Articles","previous_headings":"Approximate INLA for non-linear predictors > Fixed point iteration","what":"Line search","title":"Iterative linearised INLA method","text":"step 4, ideally want \\(\\alpha\\) \\[ \\mathop{\\mathrm{arg\\,max}}_{\\alpha} \\left[\\ln p(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta}_1)\\right]_{\\boldsymbol{u}=\\boldsymbol{v}_\\alpha}. \\] However, since requires access internal likelihood prior density evaluation code, instead use simpler alternative. consider norms form \\(\\|\\widetilde{\\eta}(\\boldsymbol{v}_\\alpha)-\\overline{\\eta}(\\boldsymbol{u}_1)\\|\\) depend nonlinear linearised predictor expressions, known quantities, given \\(\\boldsymbol{u}_0\\), current INLA estimate component wise predictor variances. Let \\(\\sigma_i^2 = \\mathrm{Var}_{\\boldsymbol{u}\\sim \\overline{p}(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta}_1)}(\\overline{\\boldsymbol{\\eta}}_i(\\boldsymbol{u}))\\) current estimate posterior variance predictor element \\(\\). define inner product space predictor vectors \\[ \\langle \\boldsymbol{},\\boldsymbol{b} \\rangle_V = \\sum_i \\frac{a_i b_i}{\\sigma_i^2} . \\] squared norm difference predictor vectors \\(\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{v}_\\alpha)\\) \\(\\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u}_1)\\),respect inner product, defined \\[ \\| \\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{v}_\\alpha) - \\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u}_1)\\|^2_V = \\sum_i \\frac{|\\widetilde{\\boldsymbol{\\eta}}_i(\\boldsymbol{v}_\\alpha)-\\overline{\\boldsymbol{\\eta}}_i(\\boldsymbol{u}_1)|^2}{\\sigma_i^2} . \\] Using norm target loss function line search avoids many potentially expensive evaluations true posterior conditional log-density. evaluate \\(\\widetilde{\\boldsymbol{\\eta}}_1=\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}_1)\\) make use linearised predictor information. Let \\(\\widetilde{\\boldsymbol{\\eta}}_\\alpha=\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{v}_\\alpha)\\) \\(\\overline{\\boldsymbol{\\eta}}_\\alpha=\\overline{\\boldsymbol{\\eta}}(\\boldsymbol{v}_\\alpha)=(1-\\alpha)\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}_0)+\\alpha\\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u}_1)\\). words, \\(\\alpha=0\\) corresponds previous linear predictor, \\(\\alpha=1\\) current estimate INLA. exact line search minimise \\(\\|\\widetilde{\\boldsymbol{\\eta}}_\\alpha-\\overline{\\boldsymbol{\\eta}}_1\\|\\). Instead, define quadratic approximation non-linear predictor function \\(\\alpha\\), \\[ \\breve{\\boldsymbol{\\eta}}_\\alpha = \\overline{\\boldsymbol{\\eta}}_\\alpha + \\alpha^2 (\\widetilde{\\boldsymbol{\\eta}}_1 - \\overline{\\boldsymbol{\\eta}}_1) \\] minimise quartic polynomial \\(\\alpha\\), \\[ \\begin{aligned} \\|\\breve{\\boldsymbol{\\eta}}_\\alpha-\\overline{\\boldsymbol{\\eta}}_1\\|^2 &= \\| (\\alpha-1)(\\overline{\\boldsymbol{\\eta}}_1 - \\overline{\\boldsymbol{\\eta}}_0) + \\alpha^2 (\\widetilde{\\boldsymbol{\\eta}}_1 - \\overline{\\boldsymbol{\\eta}}_1) \\|^2 . \\end{aligned} \\] initial expansion contraction steps carried , leading initial guess \\(\\alpha=\\gamma^k\\), \\(\\gamma>1\\) scaling factor (see ?bru_options, bru_method$factor) \\(k\\) (signed) number expansions contractions, quadratic expression replaced \\[ \\begin{aligned} \\|\\breve{\\boldsymbol{\\eta}}_\\alpha-\\overline{\\boldsymbol{\\eta}}_1\\|^2 &= \\| (\\alpha-1)(\\overline{\\boldsymbol{\\eta}}_1 - \\overline{\\boldsymbol{\\eta}}_0) + \\frac{\\alpha^2}{\\gamma^{2k}} (\\widetilde{\\boldsymbol{\\eta}}_{\\gamma^k} - \\overline{\\boldsymbol{\\eta}}_{\\gamma^k}) \\|^2 , \\end{aligned} \\] minimised interval \\(\\alpha\\[\\gamma^{k-1},\\gamma^{k+1}]\\).","code":""},{"path":"/articles/method.html","id":"posterior-non-linearity-checks","dir":"Articles","previous_headings":"","what":"Posterior non-linearity checks","title":"Iterative linearised INLA method","text":"Whereas inlabru optimisation method leads estimate \\(\\| \\widetilde{\\boldsymbol{\\eta}} (\\boldsymbol{u}_*) - \\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u}_*)\\|=0\\) specific \\(\\boldsymbol{u}_*\\), overall posterior approximation accuracy depends degree nonlinearity vicinity \\(\\boldsymbol{u}_*\\). two main options evaluating nonlinearity, using sampling approximate posterior distribution. first option \\[ \\begin{aligned} \\sum_i \\frac{E_{\\boldsymbol{u}\\sim \\overline{p}(\\boldsymbol{u}|\\boldsymbol{y})}\\left[ |\\overline{\\boldsymbol{\\eta}}_i(\\boldsymbol{u})-\\widetilde{\\boldsymbol{\\eta}}_i(\\boldsymbol{u})|^2\\right]}{\\mathrm{Var}_{\\boldsymbol{u}\\sim \\overline{p}(\\boldsymbol{u}|\\boldsymbol{y})}(\\overline{\\boldsymbol{\\eta}}_i(\\boldsymbol{u}))} , \\end{aligned} \\] posterior expectation component-wise variance-normalised squared deviation non-linear linearised predictor. Note normalising variance includes variability induced posterior uncertainty \\(\\boldsymbol{\\theta}\\), whereas \\(\\|\\cdot\\|_V\\) norm used line search used posterior mode. Another option \\[ E_{(\\boldsymbol{u},\\boldsymbol{\\theta})\\sim \\overline{p}(\\boldsymbol{u},\\boldsymbol{\\theta}|\\boldsymbol{y})} \\left[\\ln \\frac{\\overline{p}(\\boldsymbol{u} |\\boldsymbol{y},{\\boldsymbol{\\theta}})}{\\widetilde{p}(\\boldsymbol{u}|\\boldsymbol{y},{\\boldsymbol{\\theta}})}\\right] = E_{\\boldsymbol{\\theta}\\sim \\overline{p}(\\boldsymbol{\\theta}|\\boldsymbol{y})} \\left\\{ E_{\\boldsymbol{u}\\sim \\overline{p}(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta})} \\left[\\ln \\frac{\\overline{p}(\\boldsymbol{u} |\\boldsymbol{y},{\\boldsymbol{\\theta}})}{\\widetilde{p}(\\boldsymbol{u}|\\boldsymbol{y},{\\boldsymbol{\\theta}})}\\right] \\right\\} \\] Kullback–Leibler divergence conditional posterior densities, \\(\\mathsf{KL}\\left(\\overline{p}\\,\\middle\\|\\,\\widetilde{p}\\right)\\), integrated approximate posterior distribution \\(\\boldsymbol{\\theta}\\). Implementing require access likelihood prior distribution details. next section explores detail.","code":""},{"path":"/articles/method.html","id":"accuracy","dir":"Articles","previous_headings":"Posterior non-linearity checks","what":"Accuracy","title":"Iterative linearised INLA method","text":"wish assess accurate approximation . Thus, compare \\(\\widetilde{p}(\\boldsymbol{u} | \\boldsymbol{y}, \\boldsymbol{\\theta} )\\) \\(\\overline{p}(\\boldsymbol{u} |\\boldsymbol{y},\\boldsymbol{\\theta})\\). Bayes’ theorem, \\[ \\begin{aligned}     p(\\boldsymbol{u}|\\boldsymbol{y},{\\boldsymbol{\\theta}}) &= \\frac{p(\\boldsymbol{u},\\boldsymbol{y}|{\\boldsymbol{\\theta}})}{p(\\boldsymbol{y}|{\\boldsymbol{\\theta}})} \\\\     &= \\frac{p(\\boldsymbol{y}|\\boldsymbol{u},{\\boldsymbol{\\theta}}) p(\\boldsymbol{u}|{\\boldsymbol{\\theta}})}{p(\\boldsymbol{y}|{\\boldsymbol{\\theta}})}, \\end{aligned} \\] \\(p(\\boldsymbol{u}|\\boldsymbol{\\theta})\\) Gaussian density \\(p(\\boldsymbol{y}|\\boldsymbol{\\theta})\\) scaling factor doesn’t depend \\(\\boldsymbol{u}\\). can therefore focus behaviour \\(\\ln p(\\boldsymbol{y}|\\boldsymbol{\\theta},\\boldsymbol{u})\\) exact linearised observation models. Recall observation likelihood depends \\(\\boldsymbol{u}\\) \\(\\boldsymbol{\\eta}\\). Using Taylor expansion respect \\(\\boldsymbol{\\eta}\\) \\(\\boldsymbol{\\eta}^*=\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}_*)\\), \\[ \\begin{aligned}     \\ln p(\\boldsymbol{y}|\\boldsymbol{\\eta},\\boldsymbol{\\theta}) &=     \\ln p (\\boldsymbol{y}|{\\boldsymbol{\\theta}},\\boldsymbol{\\eta}^*))  \\\\      &\\qquad + \\sum_i \\left.\\frac{\\partial}{\\partial\\eta_i} \\ln p (\\boldsymbol{y} | {\\boldsymbol{\\theta}}, \\boldsymbol{\\eta}) \\right|_{\\boldsymbol{\\eta}^*}\\cdot (\\eta_i - \\eta^*_i) \\\\     &\\qquad + \\frac{1}{2}\\sum_{,j} \\left.\\frac{\\partial^2}{\\partial\\eta_i\\partial\\eta_j} \\ln p (\\boldsymbol{y} | {\\boldsymbol{\\theta}}, \\boldsymbol{\\eta}) \\right|_{\\boldsymbol{\\eta}^*}\\cdot (\\eta_i - \\eta^*_i) (\\eta_j - \\eta^*_j) + \\mathcal{O}(\\|\\boldsymbol{\\eta}-\\boldsymbol{\\eta}^*\\|^3), \\end{aligned} \\] Similarly, component \\(\\widetilde{\\boldsymbol{\\eta}}\\), \\[ \\begin{aligned} \\widetilde{\\eta}_i(\\boldsymbol{u}) &= \\eta^*_i  +\\left[\\left.\\nabla_{u}\\widetilde{\\eta}_i(\\boldsymbol{u})\\right|_{\\boldsymbol{u}_*}\\right]^\\top (\\boldsymbol{u} - \\boldsymbol{u}_*) \\\\&\\quad +\\frac{1}{2}(\\boldsymbol{u} - \\boldsymbol{u}_*)^\\top\\left[\\left.\\nabla_{u}\\nabla_{u}^\\top\\widetilde{\\eta}_i(\\boldsymbol{u})\\right|_{\\boldsymbol{u}_*}\\right] (\\boldsymbol{u} - \\boldsymbol{u}_*) + \\mathcal{O}(\\|\\boldsymbol{u}-\\boldsymbol{u}^*\\|^3) \\\\&= \\eta_i^* + b_i(\\boldsymbol{u}) + h_i(\\boldsymbol{u}) + \\mathcal{O}(\\|\\boldsymbol{u}-\\boldsymbol{u}_*\\|^3) \\\\&= \\overline{\\eta}_i(\\boldsymbol{u}) + h_i(\\boldsymbol{u}) + \\mathcal{O}(\\|\\boldsymbol{u}-\\boldsymbol{u}_*\\|^3) \\end{aligned} \\] \\(\\nabla_u\\nabla_u^\\top\\) Hessian respect \\(\\boldsymbol{u}\\), \\(b_i\\) linear \\(\\boldsymbol{u}\\), \\(h_i\\) quadratic \\(\\boldsymbol{u}\\). Combining two expansions taking difference full linearised log-likelihoods, get \\[ \\begin{aligned}     \\ln \\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta}) -     \\ln \\overline{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})     &=     \\sum_i \\left.\\frac{\\partial}{\\partial\\eta_i} \\ln p (\\boldsymbol{y} | {\\boldsymbol{\\theta}}, \\boldsymbol{\\eta}) \\right|_{\\boldsymbol{\\eta}^*}\\cdot h_i(\\boldsymbol{u}) + \\mathcal{O}(\\|\\boldsymbol{u}-\\boldsymbol{u}_*\\|^3) \\end{aligned} \\] Note log-likelihood Hessian difference contribution involves third order \\(\\boldsymbol{u}\\) terms higher, expression includes terms second order. Let \\[ g_i^*=\\left.\\frac{\\partial}{\\partial\\eta_i} \\ln p (\\boldsymbol{y} | {\\boldsymbol{\\theta}}, \\boldsymbol{\\eta}) \\right|_{\\boldsymbol{\\eta}^*} \\] \\[ \\boldsymbol{H}^*_i = \\left.\\nabla_{u}\\nabla_{u}^\\top\\widetilde{\\eta}_i(\\boldsymbol{u})\\right|_{\\boldsymbol{u}_*} . \\] form sum products, \\(\\boldsymbol{G}=\\sum_i g_i^*\\boldsymbol{H}_i^*\\). \\[ \\begin{aligned}     \\ln \\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta}) -     \\ln \\overline{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})     &=     \\frac{1}{2}     \\sum_i g_i^* (\\boldsymbol{u}-\\boldsymbol{u}_*)^\\top \\boldsymbol{H}_i^* (\\boldsymbol{u}-\\boldsymbol{u}_*) + \\mathcal{O}(\\|\\boldsymbol{u}-\\boldsymbol{u}_*\\|^3)     \\\\&=     \\frac{1}{2}     (\\boldsymbol{u}-\\boldsymbol{u}_*)^\\top \\boldsymbol{G} (\\boldsymbol{u}-\\boldsymbol{u}_*) + \\mathcal{O}(\\|\\boldsymbol{u}-\\boldsymbol{u}_*\\|^3). \\end{aligned} \\] \\(\\boldsymbol{m}=\\mathsf{E}_\\overline{p}(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta})\\) \\(\\boldsymbol{Q}^{-1}=\\mathsf{Cov}_\\overline{p}(\\boldsymbol{u},\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta})\\), obtain \\[ \\begin{aligned} \\mathsf{E}_{\\overline{p}}\\left[ \\nabla_{\\boldsymbol{u}}  \\left\\{\\ln \\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta}) -     \\ln \\overline{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})\\right\\}\\right]  &\\approx     \\boldsymbol{G}(\\boldsymbol{m}-\\boldsymbol{u}_*) ,     \\\\ \\mathsf{E}_{\\overline{p}}\\left[ \\nabla_{\\boldsymbol{u}}\\nabla_{\\boldsymbol{u}}^\\top  \\left\\{\\ln \\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta}) -     \\ln \\overline{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})\\right\\}\\right]  &\\approx     \\boldsymbol{G} ,     \\\\ \\mathsf{E}_{\\overline{p}}\\left[    \\ln \\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta}) -     \\ln \\overline{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})\\right]  &\\approx     \\frac{1}{2}     \\mathop{\\mathrm{tr}}(\\boldsymbol{G}\\boldsymbol{Q}^{-1}) + \\frac{1}{2} (\\boldsymbol{m}-\\boldsymbol{u}_*)\\boldsymbol{G}(\\boldsymbol{m}-\\boldsymbol{u}_*)^\\top . \\end{aligned} \\] \\(\\boldsymbol{\\theta}\\) configuration INLA output, can extract \\(\\boldsymbol{m}\\) sparse precision matrix \\(\\boldsymbol{Q}\\) Gaussian approximation. non-sparsity structure \\(\\boldsymbol{G}\\) contained non-sparsity \\(\\boldsymbol{Q}\\), allows use Takahashi recursion (inla.qinv(Q)) compute corresponding \\(\\boldsymbol{Q}^{-1}\\) values needed evaluate trace \\(\\mathop{\\mathrm{tr}}(\\boldsymbol{G}\\boldsymbol{Q}^{-1})\\). Thus, implement numerical approximation error analysis needs special access log-likelihood derivatives \\(g_i^*\\), \\(H_i^*\\) can principle evaluated numerically. given \\(\\boldsymbol{\\theta}\\), \\[ \\begin{aligned} \\mathsf{KL}\\left(\\overline{p}\\,\\middle\\|\\,\\widetilde{p}\\right) &= E_{\\overline{p}}\\left[\\ln\\frac{\\overline{p}(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta})}{\\widetilde{p}(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta})}\\right] \\\\&= E_{\\overline{p}}\\left[ \\ln\\frac{\\overline{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})}{\\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})} \\right] - \\ln\\frac{\\overline{p}(\\boldsymbol{y}|\\boldsymbol{\\theta})}{\\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{\\theta})} . \\end{aligned} \\] first term approximated . second term can also approximated using derived quantities (continued…). Summary: form observation likelihood discrepancy shows , given linearised posterior \\(\\mathsf{N}(\\boldsymbol{m},\\boldsymbol{Q}^{-1})\\), Gaussian approximation nonlinear model posterior, \\(\\mathsf{N}(\\widetilde{\\boldsymbol{m}},\\widetilde{\\boldsymbol{Q}}^{-1})\\), can obtained \\(\\widetilde{\\boldsymbol{Q}}=\\boldsymbol{Q}-\\boldsymbol{G}\\) \\(\\widetilde{\\boldsymbol{Q}}\\widetilde{\\boldsymbol{m}}=\\boldsymbol{Q}\\boldsymbol{m}-\\boldsymbol{G}\\boldsymbol{u}_*\\). K-L divergence becomes \\[ \\begin{aligned} \\mathsf{KL}\\left(\\overline{p}\\,\\middle\\|\\,\\widetilde{p}\\right) &\\approx \\frac{1}{2} \\left[ \\ln\\det(\\boldsymbol{Q})- \\ln\\det(\\boldsymbol{Q}-\\boldsymbol{G}) -\\mathop{\\mathrm{tr}}\\left(\\boldsymbol{G}\\boldsymbol{Q}^{-1}\\right) + (\\boldsymbol{m}-\\boldsymbol{u}_*)^\\top\\boldsymbol{G}(\\boldsymbol{Q}-\\boldsymbol{G})^{-1}\\boldsymbol{G}(\\boldsymbol{m}-\\boldsymbol{u}_*) \\right] . \\end{aligned} \\] INLA posterior mean \\(\\boldsymbol{m}=\\boldsymbol{u}_*\\), e.g. models additive Gaussian observation noise, \\(\\boldsymbol{\\theta}=\\widehat{\\boldsymbol{\\theta}}_{\\boldsymbol{u}_*}\\), last term vanishes. Note: implementing K-L divergence accuracy metric, -product improved posterior estimates based \\(\\widetilde{\\boldsymbol{m}}\\) \\(\\widetilde{\\boldsymbol{Q}}\\).","code":""},{"path":"/articles/method.html","id":"well-posedness-and-initialisation","dir":"Articles","previous_headings":"Posterior non-linearity checks","what":"Well-posedness and initialisation","title":"Iterative linearised INLA method","text":"side note, one might concerned initialisation , convergence , saddle point. Although implemented inlabru, want talk technicality define initial linearisation point \\(u_0\\). Generally speaking, values \\(\\boldsymbol{u}_0\\) work except case gradient evaluated \\(\\boldsymbol{u}_0\\) \\(\\boldsymbol{0}\\) linearisation point never move away prior mean also \\(\\boldsymbol{0}\\). general, tends saddle point problem. cases problem can handled changing predictor parameterisation just changing initialisation point using bru_initial option. However, true saddle point problems, indicates predictor parameterisation may lead multimodal posterior distribution ill-posed way. fundamental problem fixed changing initialisation point. examples, \\(\\beta\\) \\(\\boldsymbol{u}\\) latent Gaussian components, predictors 1, 3, 4 typically safe, predictor 2 fundamentally non-identifiable. \\[  \\begin{aligned} \\boldsymbol{\\eta}_1 &= \\boldsymbol{u}, \\\\ \\boldsymbol{\\eta}_2 &= \\beta \\boldsymbol{u}, \\\\ \\boldsymbol{\\eta}_3 &= e^\\beta \\boldsymbol{u}, \\\\ \\boldsymbol{\\eta}_4 &= F_\\beta^{-1} ( \\Phi(z_\\beta)) \\boldsymbol{u}, \\quad z_{\\beta} \\sim \\mathsf{N}(0,1) . \\end{aligned} \\] Note \\(\\boldsymbol{\\eta}_3\\) \\(\\boldsymbol{\\eta}_4\\), partial derivatives respect \\(\\beta\\) zero \\(\\boldsymbol{u}=\\boldsymbol{0}\\). However, first inlabru iteration give non-zero estimate \\(\\boldsymbol{u}\\), subsequent iteration involve \\(\\beta\\) \\(\\boldsymbol{u}\\).","code":""},{"path":"/articles/web/1d_lgcp.html","id":"introduction","dir":"Articles > Web","previous_headings":"","what":"Introduction","title":"LGCPs - An example in one dimension","text":"vignette going see fit SPDE one-dimensional point data, .e. data consist points things located, number points area.","code":""},{"path":"/articles/web/1d_lgcp.html","id":"setting-things-up","dir":"Articles > Web","previous_headings":"","what":"Setting things up","title":"LGCPs - An example in one dimension","text":"Load libraries","code":"library(inlabru) library(INLA) library(mgcv) library(ggplot2)"},{"path":"/articles/web/1d_lgcp.html","id":"get-the-data","dir":"Articles > Web","previous_headings":"","what":"Get the data","title":"LGCPs - An example in one dimension","text":"Take look point (frequency) data","code":"data(Poisson2_1D) ggplot(pts2) +   geom_histogram(aes(x = x), binwidth = 55 / 20, boundary = 0, fill = NA, color = \"black\") +   geom_point(aes(x), y = 0, pch = \"|\", cex = 4) +   coord_fixed(ratio = 1)"},{"path":"/articles/web/1d_lgcp.html","id":"fiting-the-model","dir":"Articles > Web","previous_headings":"","what":"Fiting the model","title":"LGCPs - An example in one dimension","text":"Build 1D mesh: Make 1D SPDE model: want fit actual points, inlabru function called lgcp (‘Log Gaussian Cox Process’). ips domain parameters optional, one can used. two ways thing:","code":"x <- seq(0, 55, length.out = 50) mesh1D <- inla.mesh.1d(x, boundary = \"free\") matern <- inla.spde2.pcmatern(mesh1D, prior.range = c(150, 0.75), prior.sigma = c(0.1, 0.75)) mdl <- x ~ spde1D(x, model = matern) + Intercept(1) fit.spde <- lgcp(mdl, pts2, ips = ipoints(c(0, 55), 50, name = \"x\")) fita.spde <- lgcp(mdl, pts2, domain = list(x = mesh1D))"},{"path":"/articles/web/1d_lgcp.html","id":"spde-parameters","dir":"Articles > Web","previous_headings":"","what":"SPDE parameters","title":"LGCPs - An example in one dimension","text":"can look posterior distributions parameters SPDE using function spde.posterior. returns x y values plot posterior PDF data frame, can printed using plot function. see PDF range parameter, example:  Look help file spde.posterior plot posterior log SPDE range parameter, SPDE variance /log variance, Matern covariance function. Make sure understand difference plotted range variance parameters, covariance function (involves parameters). can get feel sensitivity priors specifying different priors looking posterior plots.","code":"post.range <- spde.posterior(fit.spde, name = \"spde1D\", what = \"range\") plot(post.range) post.log.range <- spde.posterior(fit.spde, name = \"spde1D\", what = \"log.range\") plot(post.log.range) # SOLUTION post.variance <- spde.posterior(fit.spde, name = \"spde1D\", what = \"variance\") plot(post.variance) # SOLUTION post.log.variance <- spde.posterior(fit.spde, name = \"spde1D\", what = \"log.variance\") plot(post.log.variance) # SOLUTION post.matcorr <- spde.posterior(fit.spde, name = \"spde1D\", what = \"matern.correlation\") plot(post.matcorr) # SOLUTION"},{"path":"/articles/web/1d_lgcp.html","id":"predicting-intensity","dir":"Articles > Web","previous_headings":"","what":"Predicting intensity","title":"LGCPs - An example in one dimension","text":"can also now predict scale want. example, predict ‘response’ scale (.e. intensity function \\(\\lambda(s)\\)), call predict thus: predict linear predictor scale (.e. log intensity, \\(\\log(\\lambda(s))\\)), call predict thus: ’s plot prediction 95% credible interval:  compare underlying intensity function generated data? function lambda2_1D( ) dataset Poission2_1D calculates true intensity used simulating data. order plot , make data frame x- y-coordinates giving true intensity function, \\(\\lambda(s)\\). use lots x-values get nice smooth plot (150 values). Plot fitted true intensity functions:","code":"predf <- data.frame(x = seq(0, 55, by = 1)) # Set up a data frame of explanatory values at which to predict pred_spde <- predict(fit.spde, predf, ~ exp(spde1D + Intercept)) pred_spde_lp <- predict(fit.spde, predf, ~ spde1D + Intercept) plot(pred_spde, color = \"red\") +   geom_point(data = pts2, aes(x = x), y = 0, pch = \"|\", cex = 2) +   xlab(\"x\") + ylab(\"Intensity\") xs <- seq(0, 55, length = 150) true.lambda <- data.frame(x = xs, y = lambda2_1D(xs)) plot(pred_spde, color = \"red\") +   geom_point(data = pts2, aes(x = x), y = 0, pch = \"|\", cex = 2) +   geom_line(data = true.lambda, aes(x, y)) +   xlab(\"x\") + ylab(\"Intensity\")"},{"path":"/articles/web/1d_lgcp.html","id":"goodness-of-fit","dir":"Articles > Web","previous_headings":"","what":"Goodness-of-Fit","title":"LGCPs - An example in one dimension","text":"can look goodness--fit mode using inlabru function bincount( ), plots 95% credible intervals specified set bins along x-axis together observed count bin: credible intervals shown red rectangles, mean fitted value short horizontal blue line, observed data black points:","code":"bc <- bincount(   result = fit.spde,   observations = pts2,   breaks = seq(0, max(pts2), length = 12),   predictor = x ~ exp(spde1D + Intercept) )  attributes(bc)$ggp"},{"path":"/articles/web/1d_lgcp.html","id":"estimating-abundance","dir":"Articles > Web","previous_headings":"","what":"Estimating Abundance","title":"LGCPs - An example in one dimension","text":"Abundance integral intensity space. estimate integrating predicted intensity x. Integration done adding intensity locations x weighted particular weight. locations x weights constructed using ipoints function can look abundance estimate typing mean posterior mean abundance. sd estimated standard error posterior abundance. cv estimated coefficient variation (stander error divided mean). q0.025 q0.975 95% credible interval bounds. q0.5 posterior median abundance quite simple! posterior abundance takes account variance due us knowing parameters intensity function. neglects variance number point locations, given intensity function. include need modify predict( ) follows: calculates statistics calculated Lambda, evey value N 50 250, rather posterior mean N alone: compute 95% prediction interval median follows Compare Lambda Nest plotting: First calculate posterior conditional mean Lambda plot unconditional posterior  differences make sense ?","code":"ips <- ipoints(c(0, 55), 100, name = \"x\") head(ips) #>       x weight group #> 1 0.275   0.55     1 #> 2 0.825   0.55     1 #> 3 1.375   0.55     1 #> 4 1.925   0.55     1 #> 5 2.475   0.55     1 #> 6 3.025   0.55     1 Lambda <- predict(fit.spde, ips, ~ sum(weight * exp(spde1D + Intercept))) Lambda #>      mean       sd   q0.025     q0.5   q0.975   median mean.mc_std_err sd.mc_std_err #> 1 132.975 11.58182 113.6532 133.5982 156.9114 133.5982        1.158182       1.07407 Nest <- predict(   fit.spde, ips,   ~ data.frame(     N = 50:250,     dpois = dpois(50:250,       lambda = sum(weight * exp(spde1D + Intercept))     )   ) ) head(Nest) #>    N         mean           sd       q0.025         q0.5       q0.975       median mean.mc_std_err #> 1 50 5.023536e-11 2.933180e-10 1.991673e-21 2.727496e-16 3.257096e-10 2.727496e-16    2.933180e-11 #> 2 51 1.027668e-10 5.954722e-10 5.837733e-21 7.015199e-16 6.829012e-10 7.015199e-16    5.954722e-11 #> 3 52 2.062587e-10 1.185729e-09 1.678195e-20 1.769638e-15 1.404312e-09 1.769638e-15    1.185729e-10 #> 4 53 4.063080e-10 2.316720e-09 4.733402e-20 4.379837e-15 2.833401e-09 4.379837e-15    2.316720e-10 #> 5 54 7.858583e-10 4.443063e-09 1.310363e-19 1.063935e-14 5.611079e-09 1.063935e-14    4.443063e-10 #> 6 55 1.492917e-09 8.366888e-09 3.561607e-19 2.537495e-14 1.091007e-08 2.537495e-14    8.366888e-10 #>   sd.mc_std_err #> 1  1.036186e-10 #> 2  2.095937e-10 #> 3  4.157812e-10 #> 4  8.092004e-10 #> 5  1.545626e-09 #> 6  2.898384e-09 inla.qmarginal(c(0.025, 0.5, 0.975), marginal = list(x = Nest$N, y = Nest$mean)) #> [1]  98.94895 130.05444 162.59332 Nest$plugin_estimate <- dpois(Nest$N, lambda = Lambda$mean) ggplot(data = Nest) +   geom_line(aes(x = N, y = mean, colour = \"Posterior\")) +   geom_line(aes(x = N, y = plugin_estimate, colour = \"Plugin\"))"},{"path":"/articles/web/1d_lgcp.html","id":"comparison-to-gam-fit","dir":"Articles > Web","previous_headings":"","what":"Comparison to GAM fit","title":"LGCPs - An example in one dimension","text":"Now refit GAM count data Poisson2_1D plot estimated intensity function GAM fit, together LGCP fitted true intensity. get plot like (thick line true intensity, thin solid line inlabru fit, dashed line GAM fit:","code":"cd2 <- countdata2 fit2.gam <- gam(count ~ s(x, k = 10) + offset(log(exposure)), family = poisson(), data = cd2) dat4pred <- data.frame(x = seq(0, 55, length = 100), exposure = rep(cd2$exposure[1], 100)) pred2.gam <- predict(fit2.gam, newdata = dat4pred, type = \"response\") dat4pred2 <- cbind(dat4pred, gam = pred2.gam) # SOLUTION plot(pred_spde) +   geom_point(data = pts2, aes(x = x), y = 0, pch = \"|\", cex = 2) +   geom_line(data = dat4pred2, aes(x, gam / exposure), lty = 2) +   geom_line(data = true.lambda, aes(x, y), lwd = 1.5) +   geom_point(data = cd2, aes(x, y = count / exposure)) +   ylab(\"Intensity\") + xlab(\"x\") # SOLUTION"},{"path":"/articles/web/2d_lgcp.html","id":"introduction","dir":"Articles > Web","previous_headings":"","what":"Introduction","title":"LGCPs - An example in two dimensions","text":"vignette going working dataset obtained R package spatstat. set two-dimensional LGCP estimate Gorilla abundance.","code":""},{"path":"/articles/web/2d_lgcp.html","id":"setting-things-up","dir":"Articles > Web","previous_headings":"","what":"Setting things up","title":"LGCPs - An example in two dimensions","text":"Load libraries","code":"library(inlabru) library(INLA) library(mgcv) library(ggplot2)"},{"path":"/articles/web/2d_lgcp.html","id":"get-the-data","dir":"Articles > Web","previous_headings":"","what":"Get the data","title":"LGCPs - An example in two dimensions","text":"next practicals going working dataset obtained R package spatstat, contains locations 647 gorilla nests. load dataset like : dataset list containing number R objects, including locations nests, boundary survey area INLA mesh - see help(gorillas) details. Extract objects need list, objects, don’t keep typing ‘gorillas$’: Plot points (nests(. (ggplot2 function coord_fixed() sets aspect ratio, defaults 1.)","code":"data(gorillas, package = \"inlabru\") nests <- gorillas$nests mesh <- gorillas$mesh boundary <- gorillas$boundary ggplot() +   gg(mesh) +   gg(nests) +   gg(boundary) +   coord_fixed() +   ggtitle(\"Points\")"},{"path":"/articles/web/2d_lgcp.html","id":"fiting-the-model","dir":"Articles > Web","previous_headings":"","what":"Fiting the model","title":"LGCPs - An example in two dimensions","text":"Fit LGCP model locations gorilla nests, predict survey region, produce plot estimated density - look like plot shown . Recall steps specifying, fitting predicting : Specify model, comprising (2D models) coordinates left ~ SPDE + Intercept(1) right. Please use SPDE prior specification stated . Call lgcp( ), passing (2D models) model components, SpatialPointsDataFrame containing observed points SpatialPolygonsDataFrame defining survey boundary using samplers argument. Call predict( ), passing fitted model 2., locations predict appropriate predictor spcification. locations predict SpatialPixelsDataFrame covering mesh obtained calling pixels(mesh).","code":"matern <- inla.spde2.pcmatern(mesh,   prior.sigma = c(0.1, 0.01),   prior.range = c(5, 0.01) )  cmp <- coordinates ~ mySmooth(coordinates,   model = matern ) +   Intercept(1)  fit <- lgcp(cmp, nests, samplers = boundary, domain = list(coordinates = mesh))"},{"path":"/articles/web/2d_lgcp.html","id":"predicting-intensity","dir":"Articles > Web","previous_headings":"","what":"Predicting intensity","title":"LGCPs - An example in two dimensions","text":"get plot like (command assumes prediction object called lambda):  can plot median, lower 95% upper 95% density surfaces follows (assuming predicted intensity object lambda).","code":"pred <- predict(   fit,   pixels(mesh, mask = gorillas$boundary),   ~ data.frame(     lambda = exp(mySmooth + Intercept),     loglambda = mySmooth + Intercept   ) )  pl1 <- ggplot() +   gg(pred$lambda) +   gg(boundary) +   ggtitle(\"LGCP fit to Points\", subtitle = \"(Response Scale)\") +   coord_fixed()  pl2 <- ggplot() +   gg(pred$loglambda) +   gg(boundary) +   ggtitle(\"LGCP fit to Points\", subtitle = \"(Linear Predictor Scale)\") +   coord_fixed()  multiplot(pl1, pl2, cols = 2) ggplot() +   gg(cbind(pred$lambda, data.frame(property = \"q0.500\")), aes(fill = median)) +   gg(cbind(pred$lambda, data.frame(property = \"q0.025\")), aes(fill = q0.025)) +   gg(cbind(pred$lambda, data.frame(property = \"q0.975\")), aes(fill = q0.975)) +   coord_equal() +   facet_wrap(~property)"},{"path":"/articles/web/2d_lgcp.html","id":"spde-parameters","dir":"Articles > Web","previous_headings":"","what":"SPDE parameters","title":"LGCPs - An example in two dimensions","text":"Plot SPDE parameter fixed effect parameter posteriors.  Look correlation function want :","code":"int.plot <- plot(fit, \"Intercept\") spde.range <- spde.posterior(fit, \"mySmooth\", what = \"range\") spde.logvar <- spde.posterior(fit, \"mySmooth\", what = \"log.variance\") range.plot <- plot(spde.range) var.plot <- plot(spde.logvar)  multiplot(range.plot, var.plot, int.plot) corplot <- plot(spde.posterior(fit, \"mySmooth\", what = \"matern.correlation\")) covplot <- plot(spde.posterior(fit, \"mySmooth\", what = \"matern.covariance\")) multiplot(covplot, corplot)"},{"path":"/articles/web/2d_lgcp.html","id":"estimating-abundance","dir":"Articles > Web","previous_headings":"","what":"Estimating Abundance","title":"LGCPs - An example in two dimensions","text":"Finally, estimate abundance using predict function. first step need estimate integrated lambda. integration weight values contained ipoints output. Given generous interval boundaries (500, 800) lambda can estimate posterior abundance distribution via Get quantiles via … mean via plot posteriors:  true number nests 647; mean median posterior distribution abundance close done anything wrong!","code":"Lambda <- predict(   fit,   ipoints(boundary, mesh),   ~ sum(weight * exp(mySmooth + Intercept)) ) Lambda #>       mean       sd   q0.025     q0.5   q0.975   median mean.mc_std_err #> 1 647.9797 24.21988 608.8845 645.7979 696.2195 645.7979        2.421988 #>   sd.mc_std_err #> 1       1.64469 Nest <- predict(   fit, ipoints(boundary, mesh),   ~ data.frame(     N = 500:800,     dpois(500:800,       lambda = sum(weight * exp(mySmooth + Intercept))     )   ) ) inla.qmarginal(c(0.025, 0.5, 0.975), marginal = list(x = Nest$N, y = Nest$mean)) #> [1] 584.2599 649.1397 733.6439 inla.emarginal(identity, marginal = list(x = Nest$N, y = Nest$mean)) #> [1] 651.644 Nest$plugin_estimate <- dpois(Nest$N, lambda = Lambda$mean) ggplot(data = Nest) +   geom_line(aes(x = N, y = mean, colour = \"Posterior\")) +   geom_line(aes(x = N, y = plugin_estimate, colour = \"Plugin\"))"},{"path":"/articles/web/2d_lgcp_covars.html","id":"introduction","dir":"Articles > Web","previous_headings":"","what":"Introduction","title":"LGCPs - Spatial covariates","text":"going fit spatial models gorilla data, using factor continuous explanatory variables practical. fit one using factor variable vegetation, using continuous covariate elevation (Jump bottom practical want start gently 1D example!)","code":""},{"path":"/articles/web/2d_lgcp_covars.html","id":"get-the-data","dir":"Articles > Web","previous_headings":"","what":"Get the data","title":"LGCPs - Spatial covariates","text":"dataset list (see help(gorillas) details. Extract objects need list, convenience:","code":"data(gorillas, package = \"inlabru\") nests <- gorillas$nests mesh <- gorillas$mesh boundary <- gorillas$boundary gcov <- gorillas$gcov"},{"path":"/articles/web/2d_lgcp_covars.html","id":"factor-covariates","dir":"Articles > Web","previous_headings":"","what":"Factor covariates","title":"LGCPs - Spatial covariates","text":"Look vegetation type, nests boundary:  , mesh:","code":"ggplot() +   gg(gcov$vegetation) +   gg(boundary) +   gg(nests, color = \"white\", cex = 0.5) +   coord_equal() ggplot() +   gg(gcov$vegetation) +   gg(mesh) +   gg(boundary) +   gg(nests, color = \"white\", cex = 0.5) +   coord_equal()"},{"path":"/articles/web/2d_lgcp_covars.html","id":"a-model-with-vegetation-type-only","dir":"Articles > Web","previous_headings":"Factor covariates","what":"A model with vegetation type only","title":"LGCPs - Spatial covariates","text":"seems vegetation type might good predictor nearly nests fall vegetation type Primary. construct model vegetation type fixed effect. , need tell ‘lgcp’ find vegetation type point space, creating model components fixed effect call vegetation (call anything), follows: Notes: * need tell ‘lgcp’ factor fixed effect, model=\"factor_full\", giving one coefficient factor level. * need careful overparameterisation using factors. Unlike regression models like ‘lm()’, ‘glm()’ ‘gam()’, ‘lgcp()’, inlabru automatically remove first level absorb intercept. Instead, can either use model=\"factor_full\" without intercept, model=\"factor_contrast\", remove first level. Fit model usual: Predict intensity, plot median intensity surface. (older versions, predicting takes time vegetation values outside mesh ‘inlabru’ needed predict first. Since v2.0.0, vegetation pre-extended.) predidct function inlabru takes data argument SpatialPointsDataFrame, SpatialPixelsDataFrame data.frame. can use inlabru function pixels generate SpatialPixelsDataFrame within boundary, using mask argument, shown .  surprisingly, given nests Primary vegetation, high density vegetation. substantial patches predicted high density nests, areas predicted low density nests. estimated abundance (really 647 nests ):","code":"comp1 <- coordinates ~ vegetation(gcov$vegetation, model = \"factor_full\") - 1 comp1alt <- coordinates ~ vegetation(gcov$vegetation, model = \"factor_contrast\") + Intercept(1) fit1 <- lgcp(comp1, nests, samplers = boundary, domain = list(coordinates = mesh)) df <- pixels(mesh, mask = boundary) int1 <- predict(fit1, data = df, ~ exp(vegetation))  ggplot() +   gg(int1) +   gg(boundary, alpha = 0, lwd = 2) +   gg(nests, color = \"DarkGreen\") +   coord_equal() ips <- ipoints(boundary, mesh) Lambda1 <- predict(fit1, ips, ~ sum(weight * exp(vegetation))) Lambda1 #>       mean       sd   q0.025     q0.5   q0.975   median mean.mc_std_err #> 1 646.2626 24.70438 596.2294 645.3074 694.2591 645.3074        2.470438 #>   sd.mc_std_err #> 1      1.591755"},{"path":"/articles/web/2d_lgcp_covars.html","id":"a-model-with-vegetation-type-and-a-spde-type-smoother","dir":"Articles > Web","previous_headings":"Factor covariates","what":"A model with vegetation type and a SPDE type smoother","title":"LGCPs - Spatial covariates","text":"Lets try explain pattern nest distribution captured vegetation covariate, using SPDE: plot median intensity surface  … expected integrated intensity (mean abundance) Look contributions linear predictor SPDE vegetation: function scale_fill_gradientn sets scale plot legend. set span range three linear predictor components plotted (medians plotted default).","code":"pcmatern <- inla.spde2.pcmatern(mesh,   prior.sigma = c(0.1, 0.01),   prior.range = c(5, 0.01) )  comp2 <- coordinates ~ -1 +   vegetation(gcov$vegetation, model = \"factor_full\") +   mySmooth(coordinates, model = pcmatern) fit2 <- lgcp(comp2, nests, samplers = boundary, domain = list(coordinates = mesh)) df <- pixels(mesh, mask = boundary) int2 <- predict(fit2, df, ~ exp(mySmooth + vegetation), n.samples = 1000)  ggplot() +   gg(int2, aes(fill = q0.025)) +   gg(boundary, alpha = 0, lwd = 2) +   gg(nests) +   coord_equal() Lambda2 <- predict(   fit2,   ipoints(boundary, mesh),   ~ sum(weight * exp(mySmooth + vegetation)) ) Lambda2 #>       mean       sd   q0.025     q0.5   q0.975   median mean.mc_std_err #> 1 682.2617 27.78401 637.4045 681.8654 741.0794 681.8654        2.778401 #>   sd.mc_std_err #> 1      1.861332 lp2 <- predict(fit2, df, ~ list(   smooth_veg = mySmooth + vegetation,   smooth = mySmooth,   veg = vegetation )) lprange <- range(lp2$smooth_veg$median, lp2$smooth$median, lp2$veg$median) csc <- scale_fill_gradientn(colours = brewer.pal(9, \"YlOrRd\"), limits = lprange)  plot.lp2 <- ggplot() +   gg(lp2$smooth_veg) +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"mySmooth + vegetation\") +   coord_equal()  plot.lp2.spde <- ggplot() +   gg(lp2$smooth) +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"mySmooth\") +   coord_equal()  plot.lp2.veg <- ggplot() +   gg(lp2$veg) +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"vegetation\") +   coord_equal()  multiplot(plot.lp2, plot.lp2.spde, plot.lp2.veg, cols = 3)"},{"path":"/articles/web/2d_lgcp_covars.html","id":"a-model-with-spde-only","dir":"Articles > Web","previous_headings":"Factor covariates","what":"A model with SPDE only","title":"LGCPs - Spatial covariates","text":"need vegetation ? Fit model SPDE + Intercept, choose models basis DIC, using ‘deltaIC()’.  NOTE: behaviour DIC WAIC currently bit unclear, particular experimental mode, investigated. Classic mode: Experimental mode:","code":"comp3 <- coordinates ~ mySmooth(coordinates, model = pcmatern) + Intercept(1) fit3 <- lgcp(comp3,   data = nests,   samplers = boundary,   domain = list(coordinates = mesh) ) int3 <- predict(fit3, df, ~ exp(mySmooth + Intercept))  ggplot() +   gg(int3) +   gg(boundary, alpha = 0) +   gg(nests) +   coord_equal() Lambda3 <- predict(   fit3,   ipoints(boundary, mesh),   ~ sum(weight * exp(mySmooth + Intercept)) ) Lambda3 #>       mean       sd   q0.025     q0.5   q0.975   median mean.mc_std_err #> 1 673.0225 25.14512 631.2072 672.7358 722.7682 672.7358        2.514512 #>   sd.mc_std_err #> 1       1.47214 knitr::kable(cbind(   deltaIC(fit1, fit2, fit3, criterion = c(\"DIC\")),   deltaIC(fit1, fit2, fit3, criterion = c(\"WAIC\"))))"},{"path":"/articles/web/2d_lgcp_covars.html","id":"cv-and-spde-parameters-for-model-2","dir":"Articles > Web","previous_headings":"Factor covariates","what":"CV and SPDE parameters for Model 2","title":"LGCPs - Spatial covariates","text":"going Model fit2. Lets look spatial distribution coefficient variation  Plot vegetation “fixed effect” posteriors. First get names - $marginals.random$vegetation fitted object, contains fixed effect marginal distribution data  Use spde.posterior( ) obtain plot SPDE parameter posteriors Matern correlation covariance functions model.","code":"ggplot() +   gg(int2, aes(fill = sd / mean)) +   gg(boundary, alpha = 0) +   gg(nests) +   coord_fixed() flist <- vector(\"list\", NROW(fit2$summary.random$vegetation)) for (i in seq_along(flist)) flist[[i]] <- plot(fit2, \"vegetation\", index = i) multiplot(plotlist = flist, cols = 3) spde.range <- spde.posterior(fit2, \"mySmooth\", what = \"range\") spde.logvar <- spde.posterior(fit2, \"mySmooth\", what = \"log.variance\") range.plot <- plot(spde.range) var.plot <- plot(spde.logvar)  multiplot(range.plot, var.plot) corplot <- plot(spde.posterior(fit2, \"mySmooth\", what = \"matern.correlation\")) covplot <- plot(spde.posterior(fit2, \"mySmooth\", what = \"matern.covariance\")) multiplot(covplot, corplot)"},{"path":"/articles/web/2d_lgcp_covars.html","id":"continuous-covariates","dir":"Articles > Web","previous_headings":"","what":"Continuous covariates","title":"LGCPs - Spatial covariates","text":"Now lets try model elevation (continuous) explanatory variable. (First centre elevations stable fitting.)  elevation variable class ‘SpatialGridDataFrame’, can handled way vegetation covariate. However, since cases data may stored differently, methods needed access stored values. cases, can define function knows evaluate covariate arbitrary points survey region, call function component definition. case, can use powerful method ‘sp’ package . use create needed function. brevity going consider models elevation , elevation SPDE, SPDE . just fit one elevation SPDE. create model pass lgcp thus: Note elevation effect defined. used Spatial grid object directly specified like whereas function method specify covariate like : also now include intercept term. model fitted usual way: Summary model selection Predict plot density  Now look elevation SPDE effects space. Leave Intercept swamps spatial effects elevation SPDE plots interested comparing effects elevation SPDE. First need predict linear predictor scale. code , similar used vegetation factor variable, produces plots want.  might also want look posteriors fixed effects SPDE. Adapt code used vegetation factor .  Plot SPDE parameter posteriors Matern correlation covariance functions model.   Also estimate abundance. data.frame second call leads inclusion N prediction object, easier plotting. Plot way previous practicals","code":"elev <- gcov$elevation elev$elevation <- elev$elevation - mean(elev$elevation, na.rm = TRUE)  ggplot() +   gg(elev) +   gg(boundary, alpha = 0) +   coord_fixed() f.elev <- function(x, y) {   # turn coordinates into SpatialPoints object:   # with the appropriate coordinate reference system (CRS)   spp <- SpatialPoints(data.frame(x = x, y = y), proj4string = fm_sp_get_crs(elev))   proj4string(spp) <- fm_sp_get_crs(elev)   # Extract elevation values at spp coords, from our elev SpatialGridDataFrame   v <- over(spp, elev)   if (any(is.na(v$elevation))) {     v$elevation <- inlabru:::bru_fill_missing(elev, spp, v$elevation)   }   return(v$elevation) } matern <- inla.spde2.pcmatern(mesh,   prior.sigma = c(0.1, 0.01),   prior.range = c(5, 0.01) )  ecomp <- coordinates ~ elev(f.elev(x, y), model = \"linear\") +   mySmooth(coordinates, model = matern) + Intercept(1) vegetation(gcov$vegetation, model = \"factor_full\") elev(f.elev(x, y), model = \"linear\") efit <- lgcp(ecomp, nests, samplers = boundary, domain = list(coordinates = mesh)) summary(efit) #> inlabru version: 2.5.3.9003 #> INLA version: 22.10.06-2 #> Components: #>   elev: Model types main='linear', group='exchangeable', replicate='iid' #>   mySmooth: Model types main='spde', group='exchangeable', replicate='iid' #>   Intercept: Model types main='linear', group='exchangeable', replicate='iid' #> Likelihoods: #>   Family: 'cp' #>     Data class: 'SpatialPointsDataFrame' #>     Predictor: coordinates ~ . #> Time used: #>     Pre = 0.662, Running = 10.9, Post = 0.49, Total = 12.1  #> Fixed effects: #>            mean    sd 0.025quant 0.5quant 0.975quant  mode kld #> elev      0.004 0.001      0.002    0.004      0.006 0.004   0 #> Intercept 1.066 0.570     -0.088    1.076      2.162 1.097   0 #>  #> Random effects: #>   Name     Model #>     mySmooth SPDE2 model #>  #> Model hyperparameters: #>                    mean    sd 0.025quant 0.5quant 0.975quant mode #> Range for mySmooth 2.10 0.250      1.656     2.08       2.64 2.04 #> Stdev for mySmooth 1.04 0.094      0.868     1.04       1.24 1.03 #>  #> Deviance Information Criterion (DIC) ...............: 490.56 #> Deviance Information Criterion (DIC, saturated) ....: -16286.48 #> Effective number of parameters .....................: -848.87 #>  #> Watanabe-Akaike information criterion (WAIC) ...: 1568.80 #> Effective number of parameters .................: 132.53 #>  #> Marginal log-Likelihood:  -1263.40  #>  is computed  #> Posterior summaries for the linear predictor and the fitted values are computed #> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)') deltaIC(fit1, fit2, fit3, efit) #>   Model       DIC Delta.DIC #> 1  fit1 -563.3583     0.000 #> 2  efit  490.5617  1053.920 #> 3  fit3  498.5739  1061.932 #> 4  fit2  612.5524  1175.911 e.int <- predict(efit, pixels(mesh, mask = boundary), ~ exp(mySmooth + elev + Intercept))  ggplot() +   gg(e.int) +   gg(boundary, alpha = 0) +   gg(nests, shape = \"+\") +   coord_equal() e.lp <- predict(   efit, pixels(mesh, mask = boundary),   ~ list(     smooth_elev = mySmooth + elev,     elev = elev,     smooth = mySmooth   ) ) lprange <- range(e.lp$smooth_elev$mean, e.lp$elev$mean, e.lp$smooth$mean)  library(RColorBrewer) csc <- scale_fill_gradientn(colours = brewer.pal(9, \"YlOrRd\"), limits = lprange)  plot.e.lp <- ggplot() +   gg(e.lp$smooth_elev, mask = boundary) +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"SPDE + elevation\") +   coord_equal()  plot.e.lp.spde <- ggplot() +   gg(e.lp$smooth, mask = boundary) +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"SPDE\") +   coord_equal()  plot.e.lp.elev <- ggplot() +   gg(e.lp$elev, mask = boundary) +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"elevation\") +   coord_equal()  multiplot(plot.e.lp,   plot.e.lp.spde,   plot.e.lp.elev,   cols = 3 ) flist <- vector(\"list\", NROW(efit$summary.fixed)) for (i in seq_along(flist)) {   flist[[i]] <- plot(efit, rownames(efit$summary.fixed)[i]) } multiplot(plotlist = flist, cols = 2) spde.range <- spde.posterior(efit, \"mySmooth\", what = \"range\") spde.logvar <- spde.posterior(efit, \"mySmooth\", what = \"log.variance\") range.plot <- plot(spde.range) var.plot <- plot(spde.logvar)  multiplot(range.plot, var.plot) corplot <- plot(spde.posterior(efit, \"mySmooth\", what = \"matern.correlation\")) covplot <- plot(spde.posterior(efit, \"mySmooth\", what = \"matern.covariance\")) multiplot(covplot, corplot) Lambda <- predict(   efit, ipoints(boundary, mesh),   ~ sum(weight * exp(mySmooth + elev + Intercept)) ) Lambda #>       mean       sd   q0.025     q0.5   q0.975   median mean.mc_std_err #> 1 664.3052 27.12373 614.4287 662.9311 709.8173 662.9311        2.712373 #>   sd.mc_std_err #> 1      2.195993  Nest.e <- predict(   efit,   ipoints(boundary, mesh),   ~ data.frame(     N = 200:1000,     density = dpois(200:1000,       lambda = sum(weight * exp(mySmooth + elev + Intercept))     )   ),   n.samples = 2000 ) Nest.e$plugin_estimate <- dpois(Nest.e$N, lambda = Lambda$median) ggplot(data = Nest.e) +   geom_line(aes(x = N, y = mean, colour = \"Posterior\")) +   geom_line(aes(x = N, y = plugin_estimate, colour = \"Plugin\"))"},{"path":"/articles/web/2d_lgcp_covars.html","id":"non-spatial-evaluation-of-the-covariate-effect","dir":"Articles > Web","previous_headings":"Continuous covariates","what":"Non-spatial evaluation of the covariate effect","title":"LGCPs - Spatial covariates","text":"previous examples posterior prediction focused spatial prediction. inlabru version 2.2.8, feauture available overriding component input value specification component definition. model component can evaluated directly, arbitrary values functions named adding suffix _eval end component name predictor expression. Since elevation effect model linear, resulting plot isn’t interesting, method can applied non-linear effects well, combined general R expressions:","code":"elev.pred <- predict(   efit,   data = data.frame(elevation = seq(0, 100, length.out = 1000)),   formula = ~ elev_eval(elevation) )  ggplot(elev.pred) +   geom_line(aes(elevation, mean)) +   geom_ribbon(aes(elevation,                   ymin = q0.025,                   ymax = q0.975),               alpha = 0.2) +   geom_ribbon(aes(elevation,                   ymin = mean - 1 * sd,                   ymax = mean + 1 * sd),               alpha = 0.2)"},{"path":"/articles/web/2d_lgcp_covars.html","id":"a-1d-example","dir":"Articles > Web","previous_headings":"","what":"A 1D Example","title":"LGCPs - Spatial covariates","text":"Try fitting 1-dimensional model point data inlabru dataset Poisson2_1D. comes covariate function called cov2_1D. Try reproduce plot (used lectures) showing effects Intercept + z SPDE. (may find helpful build model fitted previous practical, adding covariate model specification.)","code":"data(Poisson2_1D) ss <- seq(0, 55, length = 200) z <- cov2_1D(ss) x <- seq(1, 55, length = 100) mesh <- inla.mesh.1d(x, degree = 1)  comp <- x ~   beta_z(cov2_1D(x), model = \"linear\") +   spde1D(x, model = inla.spde2.matern(mesh)) +   Intercept(1)  fitcov1D <- lgcp(comp, pts2, domain = list(x = mesh)) pr.df <- data.frame(x = x) prcov1D <- predict(   fitcov1D, pr.df,   ~ list(     total = exp(beta_z + spde1D + Intercept),     fx = exp(beta_z + Intercept),     spde = exp(spde1D)   ) )  ggplot() +   gg(prcov1D$total, color = \"red\") +   geom_line(aes(x = prcov1D$spde$x, y = prcov1D$spde$median), col = \"blue\", lwd = 1.25) +   geom_line(aes(x = prcov1D$fx$x, y = prcov1D$fx$median), col = \"green\", lwd = 1.25) +   geom_point(data = pts2, aes(x = x), y = 0.2, shape = \"|\", cex = 4) +   xlab(expression(bold(s))) +   ylab(expression(hat(lambda)(bold(s)) ~ ~\"and its components\")) +   annotate(geom = \"text\", x = 40, y = 6, label = \"Intensity\", color = \"red\") +   annotate(geom = \"text\", x = 40, y = 5.5, label = \"z-effect\", color = \"green\") +   annotate(geom = \"text\", x = 40, y = 5, label = \"SPDE\", color = \"blue\")"},{"path":"/articles/web/2d_lgcp_distancesampling.html","id":"introduction","dir":"Articles > Web","previous_headings":"","what":"Introduction","title":"LGCPs - Distance sampling","text":"’re going estimate distribution abundance line transect survey dolphins Gulf Mexico. data also available R package dsm (go name mexdolphins). inlabru data called mexdolphin.","code":""},{"path":"/articles/web/2d_lgcp_distancesampling.html","id":"setting-things-up","dir":"Articles > Web","previous_headings":"","what":"Setting things up","title":"LGCPs - Distance sampling","text":"Load libraries","code":"library(inlabru) library(INLA) library(ggplot2) bru_options_set(inla.mode = \"experimental\")"},{"path":"/articles/web/2d_lgcp_distancesampling.html","id":"get-the-data","dir":"Articles > Web","previous_headings":"","what":"Get the data","title":"LGCPs - Distance sampling","text":"’ll start loading data extracting mesh (convenience). Plot data (initial code just get rid tick marks)","code":"data(mexdolphin, package = \"inlabru\") mesh <- mexdolphin$mesh noyticks <- theme(   axis.text.y = element_blank(),   axis.ticks = element_blank() )  noxticks <- theme(   axis.text.x = element_blank(),   axis.ticks = element_blank() )  ggplot() +   gg(mexdolphin$ppoly) +   gg(mexdolphin$samplers, color = \"grey\") +   gg(mexdolphin$points, size = 0.2, alpha = 1) +   noyticks +   noxticks +   theme(legend.key.width = unit(x = 0.2, \"cm\"), legend.key.height = unit(x = 0.3, \"cm\")) +   theme(legend.text = element_text(size = 6)) +   guides(fill = FALSE) +   coord_equal()"},{"path":"/articles/web/2d_lgcp_distancesampling.html","id":"spatial-model-with-a-half-normal-detection-function","dir":"Articles > Web","previous_headings":"","what":"Spatial model with a half-normal detection function","title":"LGCPs - Distance sampling","text":"samplers dataset lines, polygons, need tell inlabru strip half-width, W, case data 8. start plotting distances histogram frequencies distance intervals:  need define half-normal detection probability function. must take distance first arguent linear predictor sigma parameter (call lsig) second: Specify fit SPDE model data using half-normal detection function form. need define (Matern) covariance function SPDE need now separately define components model (SPDE, Intercept detection function parameter lsig) … formula, describes components combined form linear predictor (remembering need offset due unknown direction detections!): fit model, passing components formula (previously formula constructed invisibly inlabru), specify integration domains spatial distance dimensions: Look SPDE parameter posteriors   Predict spatial intensity, plot :  Predict detection function plot , generate plot like one . , make sure doesn’t try evaluate effects components can’t evaluated using given input data. , ’re providing distances spatial coordinates, evaluate spatial random field predict() call. can specify providing vector component names include prediction calculations, “lsig”, include = \"lsig\". See ?predict.bru information.  can look posterior expected number dolphins usual: including randomness expected number. case, turns need lots posterior samples, e.g. 2,000 smooth Monte Carlo error posterior, takes little compute:","code":"W <- 8 ggplot(data.frame(mexdolphin$points)) +   geom_histogram(aes(x = distance),     breaks = seq(0, W, length = 9),     boundary = 0, fill = NA, color = \"black\"   ) +   geom_point(aes(x = distance), y = 0, pch = \"|\", cex = 4) hn <- function(distance, lsig) {   exp(-0.5 * (distance / exp(lsig))^2) } matern <- inla.spde2.pcmatern(mexdolphin$mesh,   prior.sigma = c(2, 0.01),   prior.range = c(50, 0.01) ) cmp <- ~ mySPDE(main = coordinates, model = matern) +   lsig(1) + Intercept(1) form <- coordinates + distance ~ mySPDE +   log(hn(distance, lsig)) +   Intercept + log(2) fit <- lgcp(   components = cmp,   mexdolphin$points,   samplers = mexdolphin$samplers,   domain = list(     coordinates = mesh,     distance = INLA::inla.mesh.1d(seq(0, 8, length.out = 30))   ),   formula = form ) spde.range <- spde.posterior(fit, \"mySPDE\", what = \"range\") plot(spde.range) spde.logvar <- spde.posterior(fit, \"mySPDE\", what = \"log.variance\") plot(spde.logvar) pxl <- pixels(mesh, nx = 100, ny = 50, mask = mexdolphin$ppoly) pr.int <- predict(fit, pxl, ~ exp(mySPDE + Intercept))  ggplot() +   gg(pr.int) +   gg(mexdolphin$ppoly) +   gg(mexdolphin$samplers, color = \"grey\") +   gg(mexdolphin$points, size = 0.2, alpha = 1) +   noyticks +   noxticks +   theme(legend.key.width = unit(x = 0.2, \"cm\"), legend.key.height = unit(x = 0.3, \"cm\")) +   theme(legend.text = element_text(size = 6)) +   guides(fill = FALSE) +   coord_equal() distdf <- data.frame(distance = seq(0, 8, length = 100)) dfun <- predict(fit, distdf, ~ hn(distance, lsig), include = \"lsig\") plot(dfun) predpts <- ipoints(mexdolphin$ppoly, mexdolphin$mesh) Lambda <- predict(fit, predpts, ~ sum(weight * exp(mySPDE + Intercept))) Lambda #>       mean       sd   q0.025     q0.5   q0.975   median mean.mc_std_err #> 1 249.2585 53.96815 164.5745 237.8657 369.0972 237.8657        5.396815 #>   sd.mc_std_err #> 1      3.593729 Ns <- seq(50, 450, by = 1) Nest <- predict(fit, predpts,   ~ data.frame(     N = Ns,     density = dpois(Ns,       lambda = sum(weight * exp(mySPDE + Intercept))     )   ),   n.samples = 2000 )  Nest$plugin_estimate <- dpois(Nest$N, lambda = Lambda$mean) ggplot(data = Nest) +   geom_line(aes(x = N, y = mean, colour = \"Posterior\")) +   geom_line(aes(x = N, y = plugin_estimate, colour = \"Plugin\"))"},{"path":"/articles/web/2d_lgcp_distancesampling.html","id":"hazard-rate-detection-function","dir":"Articles > Web","previous_headings":"","what":"Hazard-rate Detection Function","title":"LGCPs - Distance sampling","text":"Try , use hazard-rate detection function model: Solution: Plots:","code":"hr <- function(distance, lsig) {   1 - exp(-(distance / exp(lsig))^-1) } formula1 <- coordinates + distance ~ mySPDE +   log(hr(distance, lsig)) +   Intercept + log(2)  fit1 <- lgcp(   components = cmp,   mexdolphin$points,   samplers = mexdolphin$samplers,   domain = list(     coordinates = mesh,     distance = INLA::inla.mesh.1d(seq(0, 8, length.out = 30))   ),   formula = formula1 ) spde.range <- spde.posterior(fit1, \"mySPDE\", what = \"range\") plot(spde.range) spde.logvar <- spde.posterior(fit1, \"mySPDE\", what = \"log.variance\") plot(spde.logvar) pxl <- pixels(mesh, nx = 100, ny = 50, mask = mexdolphin$ppoly) pr.int1 <- predict(fit1, pxl, ~ exp(mySPDE + Intercept))  ggplot() +   gg(pr.int1) +   gg(mexdolphin$ppoly) +   gg(mexdolphin$samplers, color = \"grey\") +   gg(mexdolphin$points, size = 0.2, alpha = 1) +   noyticks +   noxticks +   theme(legend.key.width = unit(x = 0.2, \"cm\"), legend.key.height = unit(x = 0.3, \"cm\")) +   theme(legend.text = element_text(size = 6)) +   guides(fill = FALSE) +   coord_equal() distdf <- data.frame(distance = seq(0, 8, length = 100)) dfun1 <- predict(fit1, distdf, ~ hr(distance, lsig)) plot(dfun1) predpts <- ipoints(mexdolphin$ppoly, mexdolphin$mesh) Lambda1 <- predict(fit1, predpts, ~ sum(weight * exp(mySPDE + Intercept))) Lambda1 #>       mean      sd   q0.025     q0.5   q0.975   median mean.mc_std_err #> 1 326.0601 111.836 179.2284 295.9595 565.5689 295.9595         11.1836 #>   sd.mc_std_err #> 1      11.78516  Ns <- seq(50, 650, by = 1) Nest1 <- predict(   fit1,   predpts,   ~ data.frame(     N = Ns,     density = dpois(Ns,       lambda = sum(weight * exp(mySPDE + Intercept))     )   ),   n.samples = 2000 )  Nest1$plugin_estimate <- dpois(Nest1$N, lambda = Lambda1$mean) ggplot(data = Nest1) +   geom_line(aes(x = N, y = mean, colour = \"Posterior\")) +   geom_line(aes(x = N, y = plugin_estimate, colour = \"Plugin\"))"},{"path":"/articles/web/2d_lgcp_distancesampling.html","id":"comparing-the-models","dir":"Articles > Web","previous_headings":"","what":"Comparing the models","title":"LGCPs - Distance sampling","text":"","code":"deltaIC(fit1, fit) #>   Model       DIC Delta.DIC #> 1   fit -801.9345  0.000000 #> 2  fit1 -799.8570  2.077578  # Look at the goodness-of-fit of the two models in the distance dimension bc <- bincount(   result = fit,   observations = mexdolphin$points$distance,   breaks = seq(0, max(mexdolphin$points$distance), length = 9),   predictor = distance ~ hn(distance, lsig) ) attributes(bc)$ggp bc1 <- bincount(   result = fit1,   observations = mexdolphin$points$distance,   breaks = seq(0, max(mexdolphin$points$distance), length = 9),   predictor = distance ~ hn(distance, lsig) ) attributes(bc1)$ggp"},{"path":"/articles/web/2d_lgcp_distancesampling.html","id":"fit-models-only-to-the-distance-sampling-data","dir":"Articles > Web","previous_headings":"","what":"Fit Models only to the distance sampling data","title":"LGCPs - Distance sampling","text":"Half-normal first Half-normal next Compare detection function models DIC: Plot lines histogram observations First scale lines area histogram Half-normal: Hazard-rate: Combine lines single object plotting Plot without 95% credible intervals  Plot 95% credible intervals (without taking count rescaling account)","code":"formula <- distance ~ log(hn(distance, lsig)) + Intercept cmp <- ~ lsig(1) + Intercept(1) dfit <- lgcp(   components = cmp,   mexdolphin$points,   domain = list(distance = INLA::inla.mesh.1d(seq(0, 8, length.out = 30))),   formula = formula,   options = list(bru_initial = list(lsig = 1, Intercept = 3)) ) detfun <- predict(dfit, distdf, ~ hn(distance, lsig)) formula1 <- distance ~ log(hr(distance, lsig)) + Intercept cmp <- ~ lsig(1) + Intercept(1) dfit1 <- lgcp(   components = cmp,   mexdolphin$points,   domain = list(distance = INLA::inla.mesh.1d(seq(0, 8, length.out = 30))),   formula = formula1 ) detfun1 <- predict(dfit1, distdf, ~ hr(distance, lsig)) deltaIC(dfit1, dfit) #>   Model       DIC Delta.DIC #> 1  dfit -8.626852  0.000000 #> 2 dfit1 -6.512819  2.114033 hnline <- data.frame(distance = detfun$distance, p = detfun$mean, lower = detfun$q0.025, upper = detfun$q0.975) wts <- diff(hnline$distance) wts[1] <- wts[1] / 2 wts <- c(wts, wts[1]) hnarea <- sum(wts * hnline$p) n <- length(mexdolphin$points$distance) scale <- n / hnarea hnline$En <- hnline$p * scale hnline$En.lower <- hnline$lower * scale hnline$En.upper <- hnline$upper * scale hrline <- data.frame(distance = detfun1$distance, p = detfun1$mean, lower = detfun1$q0.025, upper = detfun1$q0.975) wts <- diff(hrline$distance) wts[1] <- wts[1] / 2 wts <- c(wts, wts[1]) hrarea <- sum(wts * hrline$p) n <- length(mexdolphin$points$distance) scale <- n / hrarea hrline$En <- hrline$p * scale hrline$En.lower <- hrline$lower * scale hrline$En.upper <- hrline$upper * scale dlines <- rbind(   cbind(hnline, model = \"Half-normal\"),   cbind(hrline, model = \"Hazard-rate\") ) ggplot(data.frame(mexdolphin$points)) +   geom_histogram(aes(x = distance), breaks = seq(0, 8, length = 9), alpha = 0.3) +   geom_point(aes(x = distance), y = 0.2, shape = \"|\", size = 3) +   geom_line(data = dlines, aes(x = distance, y = En, group = model, col = model)) ggplot(data.frame(mexdolphin$points)) +   geom_histogram(aes(x = distance), breaks = seq(0, 8, length = 9), alpha = 0.3) +   geom_point(aes(x = distance), y = 0.2, shape = \"|\", size = 3) +   geom_line(data = dlines, aes(x = distance, y = En, group = model, col = model)) +   geom_ribbon(data = dlines, aes(x = distance, ymin = En.lower, ymax = En.upper, group = model, col = model, fill = model),               alpha = 0.2, lty = 2)"},{"path":"/articles/web/2d_lgcp_multilikelihood.html","id":"introduction","dir":"Articles > Web","previous_headings":"","what":"Introduction","title":"LGCPs - Multiple Likelihoods","text":"vignette going working inlabru’s ´gorillas´ dataset originally obtained R package spatstat. data set contains two types gorillas nests marked either major minor. set multi-likelihood model nests creates two spatial LGCPs share common intercept employ different spatial smoothers.","code":""},{"path":"/articles/web/2d_lgcp_multilikelihood.html","id":"setting-things-up","dir":"Articles > Web","previous_headings":"","what":"Setting things up","title":"LGCPs - Multiple Likelihoods","text":"Load libraries","code":"library(inlabru) library(INLA) library(ggplot2)"},{"path":"/articles/web/2d_lgcp_multilikelihood.html","id":"get-the-data","dir":"Articles > Web","previous_headings":"","what":"Get the data","title":"LGCPs - Multiple Likelihoods","text":"next practicals going working dataset obtained R package spatstat, contains locations 647 gorilla nests. load dataset like : Plot nests visualize group membership (major/minor) color:","code":"data(gorillas, package = \"inlabru\") ggplot() +   gg(gorillas$mesh) +   gg(gorillas$nests, aes(color = group)) +   gg(gorillas$boundary) +   coord_fixed() +   ggtitle(\"Gorillas nests and group membership\")"},{"path":"/articles/web/2d_lgcp_multilikelihood.html","id":"fiting-the-model","dir":"Articles > Web","previous_headings":"","what":"Fiting the model","title":"LGCPs - Multiple Likelihoods","text":"First, define components enter joint model. , intercept common LGCPs two different spatial smoothers, one nest group. Given components define linear predictor likelihoods. (Using “.” indicates pure additive model, one can use include/exclude options like() indicate components actively involved model.) Setting cox process integration points easy example. nest types observed within window. Lastly, define two likelihoods… … provide ´bru´ function.","code":"matern <- inla.spde2.pcmatern(gorillas$mesh,   prior.range = c(0.1, 0.01),   prior.sigma = c(1, 0.01) )  cmp <- ~   Common(coordinates, model = matern) +   Difference(coordinates, model = matern) +   Intercept(1) fml.major <- coordinates ~ Intercept + Common + Difference / 2 fml.minor <- coordinates ~ Intercept + Common - Difference / 2 ips <- ipoints(gorillas$boundary, gorillas$mesh) lik_minor <- like(\"cp\",   formula = fml.major,   data = gorillas$nests[gorillas$nests$group == \"major\", ],   ips = ips ) lik_major <- like(\"cp\",   formula = fml.minor,   data = gorillas$nests[gorillas$nests$group == \"minor\", ],   ips = ips ) jfit <- bru(cmp, lik_major, lik_minor,   options = list(     control.inla = list(int.strategy = \"eb\"),     bru_max_iter = 1   ) ) library(patchwork) pl.major <- ggplot() +   gg(gorillas$mesh,     mask = gorillas$boundary,     col = exp(jfit$summary.random$Common$mean)   ) pl.minor <- ggplot() +   gg(gorillas$mesh,     mask = gorillas$boundary,     col = exp(jfit$summary.random$Difference$mean)   ) (pl.major + scale_fill_continuous(trans = \"log\")) +   (pl.minor + scale_fill_continuous(trans = \"log\")) &   theme(legend.position = \"right\") jfit0 <- jfit jfit <- bru_rerun(jfit) library(patchwork) pl.major <- ggplot() +   gg(gorillas$mesh,     mask = gorillas$boundary,     col = exp(jfit$summary.random$Common$mean)   ) pl.minor <- ggplot() +   gg(gorillas$mesh,     mask = gorillas$boundary,     col = exp(jfit$summary.random$Difference$mean)   ) (pl.major + scale_fill_continuous(trans = \"log\")) +   (pl.minor + scale_fill_continuous(trans = \"log\")) &   theme(legend.position = \"right\") summary(jfit0) #> inlabru version: 2.5.3.9003 #> INLA version: 22.10.06-2 #> Components: #>   Common: Model types main='spde', group='exchangeable', replicate='iid' #>   Difference: Model types main='spde', group='exchangeable', replicate='iid' #>   Intercept: Model types main='linear', group='exchangeable', replicate='iid' #> Likelihoods: #>   Family: 'cp' #>     Data class: 'SpatialPointsDataFrame' #>     Predictor: coordinates ~ Intercept + Common - Difference/2 #>   Family: 'cp' #>     Data class: 'SpatialPointsDataFrame' #>     Predictor: coordinates ~ Intercept + Common + Difference/2 #> Time used: #>     Pre = 1.26, Running = 351, Post = 0.126, Total = 352  #> Fixed effects: #>             mean    sd 0.025quant 0.5quant 0.975quant mode   kld #> Intercept -0.289 1.348     -2.935   -0.287      2.356   NA 0.046 #>  #> Random effects: #>   Name     Model #>     Common SPDE2 model #>    Difference SPDE2 model #>  #> Model hyperparameters: #>                       mean    sd 0.025quant 0.5quant 0.975quant  mode #> Range for Common     3.045 0.663      2.029    2.946      4.620 2.728 #> Stdev for Common     2.105 0.385      1.501    2.052      3.008 1.926 #> Range for Difference 1.076 1.330      0.167    0.685      4.460 0.355 #> Stdev for Difference 0.165 0.111      0.051    0.135      0.461 0.096 #>  #> Deviance Information Criterion (DIC) ...............: 615.76 #> Deviance Information Criterion (DIC, saturated) ....: -32938.33 #> Effective number of parameters .....................: -765.64 #>  #> Watanabe-Akaike information criterion (WAIC) ...: 1644.12 #> Effective number of parameters .................: 103.27 #>  #> Marginal log-Likelihood:  -1205.29  #>  is computed  #> Posterior summaries for the linear predictor and the fitted values are computed #> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)') summary(jfit) #> inlabru version: 2.5.3.9003 #> INLA version: 22.10.06-2 #> Components: #>   Common: Model types main='spde', group='exchangeable', replicate='iid' #>   Difference: Model types main='spde', group='exchangeable', replicate='iid' #>   Intercept: Model types main='linear', group='exchangeable', replicate='iid' #> Likelihoods: #>   Family: 'cp' #>     Data class: 'SpatialPointsDataFrame' #>     Predictor: coordinates ~ Intercept + Common - Difference/2 #>   Family: 'cp' #>     Data class: 'SpatialPointsDataFrame' #>     Predictor: coordinates ~ Intercept + Common + Difference/2 #> Time used: #>     Pre = 1.06, Running = 279, Post = 0.109, Total = 281  #> Fixed effects: #>             mean    sd 0.025quant 0.5quant 0.975quant mode   kld #> Intercept -0.316 1.387     -3.038   -0.314      2.405   NA 0.045 #>  #> Random effects: #>   Name     Model #>     Common SPDE2 model #>    Difference SPDE2 model #>  #> Model hyperparameters: #>                       mean    sd 0.025quant 0.5quant 0.975quant  mode #> Range for Common     3.063 0.682      2.010    2.967      4.692 2.747 #> Stdev for Common     2.118 0.370      1.521    2.074      2.979 1.965 #> Range for Difference 1.362 0.693      0.412    1.227      3.085 0.968 #> Stdev for Difference 0.154 0.065      0.058    0.144      0.309 0.124 #>  #> Deviance Information Criterion (DIC) ...............: 624.13 #> Deviance Information Criterion (DIC, saturated) ....: -32929.96 #> Effective number of parameters .....................: -759.00 #>  #> Watanabe-Akaike information criterion (WAIC) ...: 1648.80 #> Effective number of parameters .................: 105.68 #>  #> Marginal log-Likelihood:  -1204.97  #>  is computed  #> Posterior summaries for the linear predictor and the fitted values are computed #> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')"},{"path":"/articles/web/2d_lgcp_plotsampling.html","id":"introduction","dir":"Articles > Web","previous_headings":"","what":"Introduction","title":"LGCPs - Plot sampling","text":"practical demonstrates use samplers argument lgcp, need use observed points sample plots survey region.","code":""},{"path":"/articles/web/2d_lgcp_plotsampling.html","id":"setting-things-up","dir":"Articles > Web","previous_headings":"","what":"Setting things up","title":"LGCPs - Plot sampling","text":"Load libraries","code":"library(inlabru) library(INLA) library(mgcv) library(ggplot2)"},{"path":"/articles/web/2d_lgcp_plotsampling.html","id":"get-the-data","dir":"Articles > Web","previous_headings":"","what":"Get the data","title":"LGCPs - Plot sampling","text":"dataset list (see help(gorillas) details. Extract objects need list, convenience: gorillas data also contains plot sample subset covers 60% survey region.  plot survey, points within rectangles detected, also informative plot points (real plot survey , seen ).","code":"data(gorillas, package = \"inlabru\") nests <- gorillas$nests mesh <- gorillas$mesh boundary <- gorillas$boundary gcov <- gorillas$gcov sample <- gorillas$plotsample plotdets <- ggplot() +   gg(boundary) +   gg(sample$plots) +   gg(sample$nests, pch = \"+\", cex = 4, color = \"red\") +   geom_text(aes(label = sample$counts$count, x = sample$counts$x, y = sample$counts$y)) +   coord_fixed() +   labs(x = \"Easting\", y = \"Northing\") plot(plotdets) plotwithall <- ggplot() +   gg(boundary) +   gg(sample$plots) +   gg(nests, pch = \"+\", cex = 4, color = \"blue\") +   geom_text(aes(label = sample$counts$count, x = sample$counts$x, y = sample$counts$y)) +   gg(sample$nests, pch = \"+\", cex = 4, color = \"red\") +   coord_fixed() +   labs(x = \"Easting\", y = \"Northing\") plot(plotwithall)"},{"path":"/articles/web/2d_lgcp_plotsampling.html","id":"inference","dir":"Articles > Web","previous_headings":"","what":"Inference","title":"LGCPs - Plot sampling","text":"observed nest locations SpatialPointsDataFrame sample$nests, plots SpatialPolygonsDataFrame sample$plots. , using following SPDE setup: Fit LGCP model SPDE data using samplers= argument function lgcp( ): Plot density surface fitted model  Estimate integrated intensity lambda. compute overall integrated intensity, representative imagined new realisation point process, conditional expectation takes actually observed nests account, recognising complete information surveyed plots. Fit model full dataset (points gorillas$nests), get previous fit, kept . Plot intensity surface estimate integrated intensity plot look like :  values Lambda.empirical, Lambda, Lambda.close plot samples gave sufficient information overall prediction: Now, let’s compare results  understand reason differences posteriors abundance estimates?","code":"matern <- inla.spde2.pcmatern(mesh,   prior.sigma = c(0.1, 0.01),   prior.range = c(5, 0.01) ) cmp <- coordinates ~ my.spde(coordinates, model = matern)  fit <- lgcp(cmp, sample$nests, samplers = sample$plots, domain = list(coordinates = mesh)) lambda.sample <- predict(fit, pixels(mesh, mask = boundary), ~ exp(my.spde + Intercept)) lambda.sample.plot <- ggplot() +   gg(lambda.sample) +   gg(sample$plots) +   gg(boundary, col = \"yellow\") +   coord_fixed()  lambda.sample.plot Lambda <- predict(fit, ipoints(boundary, mesh), ~ sum(weight * exp(my.spde + Intercept))) Lambda.empirical <- predict(   fit,   rbind(     cbind(ipoints(boundary, mesh), data.frame(all = TRUE)),     cbind(ipoints(sample$plots, mesh), data.frame(all = FALSE))   ),   ~ (sum(weight * exp(my.spde + Intercept) * all) -     sum(weight * exp(my.spde + Intercept) * !all) +     nrow(sample$nests)) ) rbind(   Lambda,   Lambda.empirical ) fit.all <- lgcp(cmp, gorillas$nests,   samplers = gorillas$boundary,   domain = list(coordinates = mesh) ) lambda.all <- predict(fit.all, pixels(mesh, mask = boundary), ~ exp(my.spde + Intercept)) Lambda.all <- predict(fit.all, ipoints(boundary, mesh), ~ sum(weight * exp(my.spde + Intercept))) rbind(   Lambda,   Lambda.empirical,   Lambda.all,   Lambda.all.empirical =     c(nrow(gorillas$nests), 0, rep(nrow(gorillas$nests), 3), rep(NA, 4)) ) #> Warning in rbind(deparse.level, ...): number of columns of result, 8, is not a #> multiple of vector length 9 of arg 4 #>       mean      sd   q0.025     q0.5   q0.975   median mean.mc_std_err #> 1 645.5576 48.0438 555.1820 642.9890 733.7459 642.9890         4.80438 #> 2 637.8260 34.7948 574.3715 635.1465 713.9295 635.1465         3.47948 #> 3 653.9377 24.2499 608.9831 654.1472 704.4947 654.1472         2.42499 #> 4 647.0000  0.0000 647.0000 647.0000 647.0000       NA              NA #>   sd.mc_std_err #> 1      3.855809 #> 2      2.702783 #> 3      1.672805 #> 4            NA library(patchwork) lambda.sample.plot + lambda.all.plot +   plot_layout(guides = \"collect\") &   theme(legend.position = \"left\") &   scale_fill_continuous(limits = range(c(0, 340)))"},{"path":"/articles/web/2d_lgcp_spatiotemporal.html","id":"introduction","dir":"Articles > Web","previous_headings":"","what":"Introduction","title":"LGCPs - An example in space and time","text":"vignette going working dataset obtained R package MRSea. set LGCP spatio-temporal SPDE model estimate species distribution.","code":""},{"path":"/articles/web/2d_lgcp_spatiotemporal.html","id":"setting-things-up","dir":"Articles > Web","previous_headings":"","what":"Setting things up","title":"LGCPs - An example in space and time","text":"Load libraries","code":"library(inlabru) library(INLA) library(ggplot2)"},{"path":"/articles/web/2d_lgcp_spatiotemporal.html","id":"get-the-data","dir":"Articles > Web","previous_headings":"","what":"Get the data","title":"LGCPs - An example in space and time","text":"Load dataset, coordinates UTM kilometres: points (representing animals) sampling regions dataset associated season. Let’s look observed points sampling regions seasons:","code":"data(mrsea, package = \"inlabru\") ggplot() +   gg(mrsea$mesh) +   gg(mrsea$boundary) +   gg(mrsea$samplers) +   gg(mrsea$points, size = 0.5) +   coord_fixed() +   facet_wrap(~season) +   ggtitle(\"MRSea observation seasons\")"},{"path":"/articles/web/2d_lgcp_spatiotemporal.html","id":"integration-points","dir":"Articles > Web","previous_headings":"","what":"Integration points","title":"LGCPs - An example in space and time","text":"model take time (season) account construct integration points LGCP accordingly. Using ´group´ parameter can let ´ipoints´ function know like construct integration points season independently. Note omitting step simply aggregate sampling regions time. Plot integration points:","code":"ips <- ipoints(mrsea$samplers, mrsea$mesh, group = \"season\") ggplot() +   gg(ips, aes(color = season)) +   facet_wrap(~season) +   coord_equal()"},{"path":"/articles/web/2d_lgcp_spatiotemporal.html","id":"fitting-the-model","dir":"Articles > Web","previous_headings":"","what":"Fitting the model","title":"LGCPs - An example in space and time","text":"Fit LGCP model locations animals. example employ spatio-temporal SPDE. Note group ngroup parameters employed let SPDE model know name time dimension (season) total number distinct points time. Predict plot intensity seasons:","code":"matern <- inla.spde2.pcmatern(mrsea$mesh,   prior.sigma = c(0.1, 0.01),   prior.range = c(10, 0.01) )  cmp <- coordinates + season ~ mySmooth(coordinates,   model = matern, group = season, ngroup = 4 ) +   Intercept  fit <- lgcp(cmp, mrsea$points, ips = ips) ppxl <- pixels(mrsea$mesh, mask = mrsea$boundary) ppxl_all <- cprod(ppxl, data.frame(season = seq_len(4)))  lambda1 <- predict(fit, ppxl_all, ~ data.frame(season = season, lambda = exp(mySmooth + Intercept))) pl1 <- ggplot() +   gg(lambda1, aes(fill = mean)) +   gg(mrsea$points, size = 0.3) +   facet_wrap(~season) +   coord_equal() pl1"},{"path":"/articles/web/publications.html","id":"articles","dir":"Articles > Web","previous_headings":"","what":"Articles","title":"Publications","text":"Fabian E. Bachl, Finn Lindgren, David L. Borchers, Janine B. Illian (2019), inlabru: R package Bayesian spatial modelling ecological survey data, Methods Ecology Evolution, British Ecological Society, 10, 760–766, doi:10.1111/2041-210X.13168. Yuan Yuan, Fabian E. Bachl, Finn Lindgren, David L. Borchers, Janine B. Illian, Stephen T. Buckland, Håvard Rue, Tim Gerrodette (2017), Point process models spatio-temporal distance sampling data large-scale survey blue whales, Annals Applied Statistics, 11, 2270–2297, doi:10.1214/17-AOAS1078, [arXiv, PDF].","code":""},{"path":"/articles/web/publications.html","id":"presentations","dir":"Articles > Web","previous_headings":"","what":"Presentations","title":"Publications","text":"F. E. Bachl @ TIES/GRASPA 2017 Conference Climate Ecology, Bergamo, Italy, July 24-26inlabru: Bayesian modeling point procesanalysis ecological data beyond [Abstract, Slides] D. L. Borchers @ South African Statistical Association Conference, Cape Town, South Africa, 28th Nov 1st DecWildlife Survey Models: Thinned spatial point processes unknown thinning probabilities [Slides] F. E. Bachl @ Autumn meeting latent Gaussian Models, Trondheim, Norway, September 17-18Live inlabru demo [HTML, R] F. E. Bachl @ Fifth Workshop Bayesian Inference Latent Gaussian Models Applications, Bath, UK, 14-16 September 2016Approximate non-linear thinning probabilistic marks log Gaussian Cox process models INLA [Abstract, Slides] F. E. Bachl @ Smoegen Workshop, Smoegen, August 15-18 2016 Approximate non-linear thinning probabilistic marks log Gaussian Cox process models INLA [Abstract, Slides] F. E. Bachl @ NOAA San Diego, USA, August 2016Spatial point process models distance sampling surveys animals occur groups [Slides] D. L. Borchers @ International Environmetrics Society Conference 2016, Edinburgh, UK, 18-22 July 2016 Wildlife survey models: thinned spatial point processes unknown thinning probabilities Y. Yuan @ International Statistical Ecology Conference (ISEC 2016), Seattle, USA, June 28th – July 1st, 2016.Poster: Point process models spatio-temporal distance sampling data [Abstract] F. E. Bachl @ International Statistical Ecology Conference (ISEC 2016), Seattle, USA, June 28th – July 1st, 2016.Spatial point process models distance sampling surveys animals occur groups [Abstract, Slides] Y. Yuan @ National Centre Statistical Ecology Conference, Falmouth, UK, July 2015Spatial point process models distance sampling data Y. Yuan @ Spatial Statistics, Emerging Patterns, Avignon, France, June 2015Spatial point process models distance sampling data","code":""},{"path":"/articles/web/random_fields.html","id":"setting-things-up","dir":"Articles > Web","previous_headings":"","what":"Setting things up","title":"Random Fields in One Dimension","text":"Make shortcut nicer colour scale:","code":"library(INLA) library(inlabru) library(mgcv) library(ggplot2) colsc <- function(...) {   scale_fill_gradientn(     colours = rev(RColorBrewer::brewer.pal(11, \"RdYlBu\")),     limits = range(..., na.rm = TRUE)   ) }"},{"path":"/articles/web/random_fields.html","id":"get-the-data","dir":"Articles > Web","previous_headings":"","what":"Get the data","title":"Random Fields in One Dimension","text":"Put count data cd (just ‘cd’ less type ‘countdata2’.) Take look count data.  Tip: RStudio > Help > Cheatsheets > Data visualisation ggplot2 useful reference ggplot2 syntax.","code":"data(Poisson2_1D) cd <- countdata2 cd #>            x count exposure #> 1   2.319888     9 4.639776 #> 2   6.959664    13 4.639776 #> 3  11.599439    11 4.639776 #> 4  16.239215    22 4.639776 #> 5  20.878991    20 4.639776 #> 6  25.518766    19 4.639776 #> 7  30.158542    16 4.639776 #> 8  34.798318     8 4.639776 #> 9  39.438093     4 4.639776 #> 10 44.077869     4 4.639776 #> 11 48.717645     4 4.639776 ggplot(cd) +   geom_point(aes(x, y = count)) +   ylim(0, max(cd$count))"},{"path":"/articles/web/random_fields.html","id":"fitting-a-generalised-additive-model-gam","dir":"Articles > Web","previous_headings":"","what":"Fitting a Generalised Additive Model (GAM)","title":"Random Fields in One Dimension","text":"’re familiar GAMs syntax gam don’t worry, point just provide something can compare inlabru model fit. term s(x,k=10) just specifies nonparametric smooth function fitted data, 10 degrees freedom (df). (larger df, wiggly fitted curve (recall lecture effect spline methods defined, without discretisation dependent penalty); gam selects ‘best’ df.) Notice use offset=. (Refer slides explanation offset.) variable exposure data frame cd size bin count made. can look fitted model using summary( ) want , need understand output, code makes predictions immediately familiar GAMs. Make prediction data frame, get predictions add data frame First make vectors x-values associated (equal) exposures: put data frame: predict Ploting fit data using ggplot2 commands give plot shown ","code":"fit2.gam <- gam(count ~ s(x, k = 10) + offset(log(exposure)), family = poisson(), data = cd) summary(fit2.gam) xs <- seq(0, 55, length = 100) exposures <- rep(cd$exposure[1], 100) dat4pred <- data.frame(x = xs, exposure = exposures) pred2.gam <- predict(fit2.gam, newdata = dat4pred, type = \"response\") dat4pred2 <- cbind(dat4pred, gam = pred2.gam) # add column for prediction in data frame ggplot(dat4pred2) +   geom_line(aes(x = x, y = gam), lty = 2) +   ylim(0, max(dat4pred2$gam, cd$count)) +   geom_point(aes(x = x, y = count), cd)"},{"path":"/articles/web/random_fields.html","id":"fitting-an-spde-model-with-inlabru","dir":"Articles > Web","previous_headings":"","what":"Fitting an SPDE model with inlabru","title":"Random Fields in One Dimension","text":"Make mesh. avoid boundary effects region interest, let mesh extend outside data range. … see mesh points :","code":"x <- seq(-10, 65, by = 1) # this sets mesh points - try others if you like mesh1D <- inla.mesh.1d(x, boundary = \"free\") ggplot() +   gg(mesh1D)"},{"path":"/articles/web/random_fields.html","id":"using-function-bru-to-fit-to-count-data","dir":"Articles > Web","previous_headings":"Fitting an SPDE model with inlabru","what":"Using function bru( ) to fit to count data","title":"Random Fields in One Dimension","text":"need specify model components model formula order fit . can done inside call bru( ) bit messy, ’ll store comp first pass bru( ). response variable data frame cd called count model specification needs left ~. add intercept component + Intercept(1) right hand side (models use intercepts), want fit Gaussian random field (GRF), must GRF specification. inlabru GRF specification function, allows GRF calculated point space inlabru calculations. user gets name GRF function. syntax ‘myname(input, model= …)’, : ‘myname’ whatever want call GRF (called field ); input specifies coordinates GRF SPDE ‘lives’. working one dimension, called dimension x set data set. model= designates type effect, SPDE model object INLA function inla.spde2.pcmatern( ), requires mesh passed , pass 1D mesh created , `mesh1D. models adds model components, don’t need specify full predictor formula. Instead, can provide name output left ~ component specification, “.” right hand side, cause add components (unless subset selected via include/exclude arguments like()). Predict values x points used mesh (data argument must data frame, see ?predict.bru): Let’s plot compare fitted model true model. expected counts true model stored variable E_nc2 comes dataset Poisson2_1D. ease use plotting ggplot2 (needs data frame), create data frame call true.lambda, containing x- y variables shown . Given inlabru predictions always intensity function scale, understand divide count cd$exposure? (due course allow predictions count scale well.) ggplot2 commands generate plot shown . shows true intensities short horizontal blue lines, observed intensities black dots, fitted intensity function red curve, 95% credible intervals shown light red band curve.  Compare inlabru fit gam fit:","code":"the_spde <- inla.spde2.pcmatern(mesh1D,   prior.range = c(1, 0.01),   prior.sigma = c(1, 0.01) )  comp <- ~ field(x, model = the_spde) + Intercept(1, prec.linear = 1/2^2)  fit2.bru <- bru(comp,                 like(count ~ .,                      data = cd,                      family = \"poisson\",                      E = exposure))  summary(fit2.bru) #> inlabru version: 2.5.3.9003 #> INLA version: 22.10.06-2 #> Components: #>   field: Model types main='spde', group='exchangeable', replicate='iid' #>   Intercept: Model types main='linear', group='exchangeable', replicate='iid' #> Likelihoods: #>   Family: 'poisson' #>     Data class: 'data.frame' #>     Predictor: count ~ . #> Time used: #>     Pre = 0.891, Running = 0.17, Post = 0.16, Total = 1.22  #> Fixed effects: #>            mean    sd 0.025quant 0.5quant 0.975quant mode kld #> Intercept 1.125 0.766      0.017    0.947      3.071  0.8   0 #>  #> Random effects: #>   Name     Model #>     field SPDE2 model #>  #> Model hyperparameters: #>                   mean     sd 0.025quant 0.5quant 0.975quant  mode #> Range for field 31.903 19.992      9.073   26.935     84.324 19.48 #> Stdev for field  0.518  0.164      0.267    0.494      0.907  0.45 #>  #> Deviance Information Criterion (DIC) ...............: 60.26 #> Deviance Information Criterion (DIC, saturated) ....: 76.90 #> Effective number of parameters .....................: 5.43 #>  #> Watanabe-Akaike information criterion (WAIC) ...: 58.33 #> Effective number of parameters .................: 2.76 #>  #> Marginal log-Likelihood:  -36.82  #>  is computed  #> Posterior summaries for the linear predictor and the fitted values are computed #> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)') x4pred <- data.frame(x = xs) pred2.bru <- predict(fit2.bru, x4pred, x ~ exp(field + Intercept), n.samples = 1000) true.lambda <- data.frame(x = cd$x, y = E_nc2 / cd$exposure) ggplot() +   gg(pred2.bru) +   geom_point(data = cd, aes(x = x, y = count / exposure), cex = 2) +   geom_point(data = true.lambda, aes(x, y), pch = \"_\", cex = 9, col = \"blue\") +   coord_cartesian(xlim = c(0, 55), ylim = c(0, 6)) +   xlab(\"x\") +   ylab(\"Intensity\") ggplot() +   gg(pred2.bru) +   geom_point(data = cd, aes(x = x, y = count / exposure), cex = 2) +   geom_line(data = dat4pred2, aes(x, gam / exposure), lty = 2) +   coord_cartesian(xlim = c(0, 55), ylim = c(0, 6)) +   xlab(\"x\") +   ylab(\"Intensity\")"},{"path":"/articles/web/random_fields.html","id":"looking-at-the-posterior-distributions","dir":"Articles > Web","previous_headings":"Fitting an SPDE model with inlabru","what":"Looking at the posterior distributions","title":"Random Fields in One Dimension","text":"can look Intercept posterior using function plot( ), .  know variable called Intercept order use function. see fixed effect parameters’ posterior distributions available plotted, can type tell SPDE parameters, type just tells SPDE fit2.bru called ‘field’, tell associated parameter names . parameters used estimation cryptic – interested range variance Matern covariance funcion, functions internal parameters. can look posterior distributions range parameter log variance parameters follows. (look posterior log variance variance posterior skewed easier view log variance)  can look posterior distributions Matern correlatioin covariance funcitons follows:","code":"plot(fit2.bru, \"Intercept\") names(fit2.bru$marginals.fixed) names(fit2.bru$marginals.random) #> [1] \"field\" spde.range <- spde.posterior(fit2.bru, \"field\", what = \"range\") spde.logvar <- spde.posterior(fit2.bru, \"field\", what = \"log.variance\")  range.plot <- plot(spde.range) var.plot <- plot(spde.logvar) multiplot(range.plot, var.plot) plot(spde.posterior(fit2.bru, \"field\", what = \"matern.correlation\")) plot(spde.posterior(fit2.bru, \"field\", what = \"matern.covariance\"))"},{"path":"/articles/web/random_fields_2d.html","id":"setting-things-up","dir":"Articles > Web","previous_headings":"","what":"Setting things up","title":"Random Fields in 2D","text":"Make shortcut nicer colour scale:","code":"library(INLA) library(inlabru) library(mgcv) library(ggplot2) colsc <- function(...) {   scale_fill_gradientn(     colours = rev(RColorBrewer::brewer.pal(11, \"RdYlBu\")),     limits = range(..., na.rm = TRUE)   ) }"},{"path":"/articles/web/random_fields_2d.html","id":"modelling-on-2d-domains","dir":"Articles > Web","previous_headings":"","what":"Modelling on 2D domains","title":"Random Fields in 2D","text":"now construct 2D model, generate sample random field, attempt recover field observations locations. Tomorrow, look general mesh constructions adapt irregular domains. First, build high resolution mesh true field, using low level INLA functions  pointwise standard deviation field? Along straight boundaries, variance twice target variance. corners variance 4 times large.  Generate sample model:   Extract observations random locations:","code":"bnd <- spoly(data.frame(lon = c(0, 10, 10, 0), lat = c(0, 0, 10, 10)),   crs = inla.CRS(\"longlat\") ) #> Warning in inla.CRS(\"longlat\"): Use of old predefined projection 'longlat' is #> deprecated. Converting to 'longlat_norm' #> Warning in showSRID(SRS_string, format = \"PROJ\", multiline = \"NO\", prefer_proj #> = prefer_proj): Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 #> +no_defs +type=crs #> Warning in showSRID(SRS_string, format = \"PROJ\", multiline = \"NO\", prefer_proj = #> prefer_proj): Discarded datum unknown in Proj4 definition mesh_fine <- inla.mesh.2d(boundary = bnd, max.edge = 0.2) ggplot() +   gg(mesh_fine) +   coord_equal() # Note: the priors here will not be used in estimation matern_fine <-   inla.spde2.pcmatern(mesh_fine,     prior.sigma = c(1, 0.01),     prior.range = c(1, 0.01)   ) true_range <- 4 true_sigma <- 1 true_Q <- inla.spde.precision(matern_fine, theta = log(c(true_range, true_sigma))) true_sd <- diag(inla.qinv(true_Q))^0.5 ggplot() +   gg(mesh_fine, col = true_sd) +   coord_equal() true_field <- inla.qsample(1, true_Q)[, 1]  truth <- expand.grid(   lon = seq(0, 10, length = 100),   lat = seq(0, 10, length = 100) ) truth$field <- inla.mesh.project(mesh_fine,   loc = as.matrix(truth),   field = true_field ) coordinates(truth) <- c(\"lon\", \"lat\") truth <- as(truth, \"SpatialPixelsDataFrame\")  pl_truth <- ggplot() +   gg(truth, mapping = aes_string(\"lon\", \"lat\", fill = \"field\")) +   coord_equal() +   ggtitle(\"True field\") pl_truth ## Or with another colour scale: csc <- colsc(truth$field) multiplot(pl_truth, pl_truth + csc, cols = 2) n <- 200 mydata <- data.frame(lon = runif(n, 0, 10), lat = runif(n, 0, 10)) mydata$observed <-   inla.mesh.project(     mesh_fine,     loc = as.matrix(mydata),     field = true_field   ) +   rnorm(n, sd = 0.4) coordinates(mydata) <- c(\"lon\", \"lat\") ggplot() +   gg(mydata, aes(col = observed))"},{"path":"/articles/web/random_fields_2d.html","id":"estimating-the-field","dir":"Articles > Web","previous_headings":"","what":"Estimating the field","title":"Random Fields in 2D","text":"Construct mesh covering data:  Construct SPDE model object Matern model: Specify model components: Fit model inspect results: Predict field lattice, generate single realisation posterior distribution: Compare truth estimated field (posterior mean sample posterior distribution):  Plot SPDE parameter fixed effect parameter posteriors.  Look correlation function want :  can plot median, lower 95% upper 95% density surfaces follows (assuming predicted intensity object pred).","code":"mesh <- inla.mesh.2d(boundary = bnd, max.edge = 0.5) ggplot() +   gg(mesh) +   coord_equal() matern <-   inla.spde2.pcmatern(mesh,     prior.sigma = c(10, 0.01),     prior.range = c(1, 0.01)   ) cmp <- observed ~ field(coordinates, model = matern) + Intercept(1) fit <- bru(cmp, mydata, family = \"gaussian\") summary(fit) pix <- pixels(mesh, nx = 200, ny = 200) pred <- predict(   fit, pix,   ~ field + Intercept ) samp <- generate(fit, pix,   ~ field + Intercept,   n.samples = 1 ) pred$sample <- samp[, 1] pl_posterior_mean <- ggplot() +   gg(pred) +   gg(bnd) +   ggtitle(\"Posterior mean\") +   coord_fixed() pl_posterior_sample <- ggplot() +   gg(pred, mapping = aes_string(x = \"x\", y = \"y\", fill = \"sample\")) +   gg(bnd) +   ggtitle(\"Posterior sample\") +   coord_fixed()  # Common colour scale for the truth and estimate: csc <- colsc(truth$field, pred$mean, pred$sample) multiplot(pl_truth + csc,   pl_posterior_mean + csc,   pl_posterior_sample + csc,   cols = 3 ) int.plot <- plot(fit, \"Intercept\") spde.range <- spde.posterior(fit, \"field\", what = \"range\") spde.logvar <- spde.posterior(fit, \"field\", what = \"log.variance\") range.plot <- plot(spde.range) var.plot <- plot(spde.logvar)  multiplot(range.plot, var.plot, int.plot) corplot <- plot(spde.posterior(fit, \"field\", what = \"matern.correlation\")) covplot <- plot(spde.posterior(fit, \"field\", what = \"matern.covariance\")) multiplot(covplot, corplot) csc <- colsc(   pred@data[\"median\"],   pred@data[\"q0.025\"],   pred@data[\"q0.975\"] ) ## Common colour scale from SpatialPixelsDataFrame  gmedian <- ggplot() +   gg(pred[\"median\"]) +   coord_equal() +   csc glower95 <- ggplot() +   gg(pred[\"q0.025\"]) +   coord_equal() +   csc +   theme(legend.position = \"none\") gupper95 <- ggplot() +   gg(pred[\"q0.975\"]) +   coord_equal() +   csc +   theme(legend.position = \"none\")  multiplot(gmedian, glower95, gupper95,   layout = matrix(c(1, 1, 2, 3), byrow = TRUE, ncol = 2) )"},{"path":"/articles/web/svc.html","id":"introduction","dir":"Articles > Web","previous_headings":"","what":"Introduction","title":"Spatially Varying Coefficient Models with inlabru","text":"Spatially varying coefficient models (SVCs, Gelfand et al. 2003) often used model data relationships dependent independent variables uniform across space, common situation exploring phenomena across large spatial extents (Finley 2011). Meehan et al. (2019) described SVC model evaluate continent-scaled variation bird abundance trends. SVC model used analysis employed discrete aerial units (100 km grid cells), spatial structure described neighborhood matrices spatial relationships described intrinsic conditional autoregressive model (Besag 1974). online supplement paper included code building model using R-INLA package (Rue et al. 2009) R statistical programming language (R Core Team 2021). manuscript code can accessed https://github.com/tmeeha/inlaSVCBC. vignette, describe build SVC model similar described Meehan et al. (2019), within continuous-space framework. model computed using stochastic partial differential equation (SPDE) approach Lindgren et al. (2011, 2022), implemented inlabru interface R-INLA package R. SPDE approach employs computationally efficient approximation Gaussian random field parameters directly comparable Matérn covariance function. benefits continuous-space versus discrete-space SVC include potential finer resolution estimation prediction, better understanding range spatial correlation, reduction boundary effects associated discrete-space analyses. build model using subset data described Meehan et al. (2019). Specifically, use counts American Robin (Turdus migratorius) south central North America collected 1987 2016 Audubon Christmas Bird Count (CBC). overall goal analysis produce spatially explicit estimates annual relative abundance well long-term relative abundance trends robins account spatial temporal variation count effort.","code":""},{"path":"/articles/web/svc.html","id":"model","dir":"Articles > Web","previous_headings":"","what":"Model","title":"Spatially Varying Coefficient Models with inlabru","text":"model used analyze data assumes counts come negative binomial distribution expected count dispersion parameter. expected count log-linear predictor: \\[\\log(\\lambda_{st}) = \\kappa_{s} + \\alpha_s + \\epsilon_{s} \\log[\\text{Effort}_{st}] + \\tau_{s} \\text{Year}_{st}\\] natural log expected count, \\(\\log(\\lambda_{st})\\), site \\(s\\) year \\(t\\), modeled zero-centered, normally distributed intercept per site, \\(\\kappa_s\\), spatially varying intercept, \\(\\alpha_s\\), spatially varying effect log count effort hours, \\(\\epsilon_s\\), spatially varying linear effect year, \\(\\tau_s\\). spatially structured effects modeled Gaussian random fields Matérn covariance functions range variance parameters. Model parameters \\(\\kappa_s\\), \\(\\alpha_s\\), \\(\\epsilon_s\\) \\(\\tau_s\\) analogous Meehan et al. (2019). example, \\(\\kappa_s\\) included account site-level differences counts, possibly due habitat availability observer experience. \\(\\alpha_s\\) can interpreted effort-corrected abundance index year zero. \\(\\epsilon_s\\) exponent power-law effort-correction function. \\(\\tau_s\\) long-term temporal trend given site.","code":""},{"path":"/articles/web/svc.html","id":"environment","dir":"Articles > Web","previous_headings":"","what":"Environment","title":"Spatially Varying Coefficient Models with inlabru","text":"get started data analysis, set environment, loading packages, setting options. Next define coordinate reference system (CRS) spatial analysis create base map later use. CRS uses USA Contiguous Albers Equal-Area Conic projection, identified EPSG code 6703. modify CRS slightly units kilometers, distances widespread count sites especially large numbers (Krainski et al. 2018).","code":"# libraries library(maps) library(ggplot2) library(sf) library(raster) library(tidyr) library(scales) library(inlabru) library(INLA) library(dplyr) # Note: the 'splancs' package also needs to be installed, # but doesn't need to be loaded  # set option select <- dplyr::select options(scipen = 99999) options(max.print = 99999) options(stringsAsFactors = FALSE) # define a crs epsg6703km <- paste(   \"+proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5\",   \"+lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83\",   \"+units=km +no_defs\" )  # make a base map states <- st_as_sf(maps::map(\"state\", plot = FALSE, fill = TRUE)) %>%   filter(ID %in% c(     \"texas\", \"oklahoma\", \"kansas\", \"missouri\",     \"arkansas\", \"louisiana\"   )) %>%   st_transform(epsg6703km)"},{"path":"/articles/web/svc.html","id":"import-data","dir":"Articles > Web","previous_headings":"","what":"Import data","title":"Spatially Varying Coefficient Models with inlabru","text":"Next import bird count data GitHub repository associated Meehan et al. (2019), turn data set spatially referenced points. use subset data (30 years, 6 US states) analysis reduce computing time (~ 1 min). Note site selection zero filling, important components trend analyses, already conducted resulting data set. inlabru package contains pregenerated version data subset, called robins_subset, can accessed data(robins_subset), avoid accessing full data online. following code used generate subset: load data, filter observation sites less 20 years data, add index variables uniquely index site year information, transform coordinates epsg6703km CRS: rough view changes robin relative abundance, account variation count effort, can seen plotting raw counts per site year.","code":"robins_subset <- read.csv(paste0(   \"https://raw.github.com/tmeeha/inlaSVCBC\",   \"/master/code/modeling_data.csv\" )) %>%   select(     circle, bcr, state, year, std_yr, count, log_hrs,     lon, lat, obs   ) %>%   mutate(year = year + 1899) %>%   filter(     state %in% c(       \"TEXAS\", \"OKLAHOMA\", \"KANSAS\", \"MISSOURI\",       \"ARKANSAS\", \"LOUISIANA\"     ),     year >= 1987   ) data(robins_subset) count_dat <- robins_subset %>%   mutate(site_idx = as.numeric(factor(paste(circle, lon, lat)))) %>%   group_by(site_idx) %>%   mutate(n_years = n()) %>%   filter(n_years >= 20) %>%   ungroup() %>%   mutate(     std_yr = year - max(year),     obs = 1:nrow(.),     site_idx = as.numeric(factor(paste(circle, lon, lat))),     year_idx = as.numeric(factor(year)),     site_year_idx = as.numeric(factor(paste(circle, lon, lat, year)))   ) %>%   st_as_sf(coords = c(\"lon\", \"lat\"), crs = 4326, remove = FALSE) %>%   st_transform(epsg6703km) %>%   mutate(easting = st_coordinates(.)[, 1],          northing = st_coordinates(.)[, 2]) %>%   arrange(circle, year) # map it ggplot() +   geom_sf(     data = count_dat %>% filter(year_idx %in% seq(1, 30, 3)),     aes(col = log(count + 1))   ) +   geom_sf(data = states, fill = NA) +   coord_sf(datum = NA) +   facet_wrap(~year) +   scale_color_distiller(palette = \"Spectral\") +   theme_bw()"},{"path":"/articles/web/svc.html","id":"make-spatial-data","dir":"Articles > Web","previous_headings":"","what":"Make spatial data","title":"Spatially Varying Coefficient Models with inlabru","text":"Next use count data make map distinct count sites save coordinates sites, unique across years, later spatial modeling plotting.","code":"# make a set of distinct study sites for mapping site_map <- count_dat %>%   select(circle, easting, northing) %>%   distinct() %>%   select(circle, easting, northing)"},{"path":"/articles/web/svc.html","id":"spde-components","dir":"Articles > Web","previous_headings":"","what":"SPDE components","title":"Spatially Varying Coefficient Models with inlabru","text":"Computing continuous-space model R-INLA using SPDE approach requires construction four distinct sets data model objects (Blangiardo Cameletti 2015, Krainski et al. 2018). First, create modeling mesh, used provide piecewise linear representation continuous spatial surface, based triangulation modeled region. , mesh get reused spatial terms model. Second, construct SPDE model object specifies properties spatial model. , use SPDE object spatial terms model. plain R-INLA, also need create index vectors projector matrices (matrices often called). However, inlabru, objects created automatically, user need deal directly. qorks automatic creation bru_mapper object knows map mesh nodes spatial data locations. Thus, two R-INLA functions needed user code SPDE modelling steps inla.mesh.2D() inla.spde2.pcmatern(), inla.spde.make.index() inla.spde.make.() called internally inlabru code .","code":""},{"path":"/articles/web/svc.html","id":"modeling-mesh","dir":"Articles > Web","previous_headings":"","what":"Modeling mesh","title":"Spatially Varying Coefficient Models with inlabru","text":"various things consider constructing mesh (Lindgren Rue 2015, Blangiardo Cameletti 2015, Krainski et al. 2018, Bakka et al. 2018). constructing one, balance trade-capturing fine-scaled features Gaussian random field computing times. , create non-convex hull around count sites, build triangular mesh specifying minimum maximum edge lengths within slightly outside hull.","code":"# make a hull and mesh for spatial model hull <- inla.nonconvex.hull(   points = as.matrix(st_coordinates(count_dat)),   convex = 200, concave = 350 ) mesh <- inla.mesh.2d(   boundary = hull, max.edge = c(100, 600), # km inside and outside   cutoff = 50, offset = c(100, 300) ) # cutoff is min edge  # plot it ggplot() +   gg(data = mesh) +   geom_sf(data = site_map, col = \"darkgreen\", size = 1) +   geom_sf(data = states, fill = NA) +   theme_bw() +   labs(x = \"\", y = \"\")"},{"path":"/articles/web/svc.html","id":"spde-model-object","dir":"Articles > Web","previous_headings":"","what":"SPDE model object","title":"Spatially Varying Coefficient Models with inlabru","text":"Next create SPDE object define model smoothness, prior distributions variance range parameters, mesh. assume Gaussian random field characterized Matérn covariance function penalized complexity priors (Simpson et al. 2017) practical range (distance spatial correlation approaches 0.1) variation explained function (Fuglstad et al. 2019). prior spatial range set probability range exceeding 500 km 0.5. prior variance explained spatial effect set probability standard deviation exceeding 1 0.5 (Krainski et al. 2018). one wants constrain kind spatial effect integrate zero, constr=TRUE added stage.","code":"# make spde spde <- inla.spde2.pcmatern(   mesh = mesh,   prior.range = c(500, 0.5),   prior.sigma = c(1, 0.5) )"},{"path":"/articles/web/svc.html","id":"weighted-spatial-effects-in-inlabru","dir":"Articles > Web","previous_headings":"","what":"Weighted spatial effects in inlabru","title":"Spatially Varying Coefficient Models with inlabru","text":"ordinary R-INLA, necessary construct projector matrices model component, include different covariate weightings spatial model component. inlabru, can instead handled either explicitly multiplying spatial random fields spatial covariates model formula expression, specifying weights argument model component specification. use latter approach, since easiest. model, \\(\\epsilon_s\\) spatially varying effect log count effort. Similarly, \\(\\tau_s\\) spatially varying effect year, standardized year (1987 = 0) also specified weights argument. \\(\\alpha_s\\) also SVC, spatially varying intercept. intercepts necessary specify constant weight 1. model component \\(\\kappa_{s}\\) linked observation site modeled mesh. Note current use term ‘weights’ different often encountered defining mixed effect models R. used define covariate value multiplication, opposed importance values likelihoods contexts.","code":""},{"path":"/articles/web/svc.html","id":"data-stack-for-model-fitting","dir":"Articles > Web","previous_headings":"Weighted spatial effects in inlabru","what":"Data stack for model fitting","title":"Spatially Varying Coefficient Models with inlabru","text":"plain R-INLA, need bundle model data component projector matrix information using inla.stack() function. inlabru, done automatically, skip step.","code":""},{"path":"/articles/web/svc.html","id":"model-formula","dir":"Articles > Web","previous_headings":"","what":"Model formula","title":"Spatially Varying Coefficient Models with inlabru","text":"last required input analysis model formula, includes information prior explained variation unstructured random intercept. define prior \\(\\kappa_s\\) penalized complexity prior (Simpson et al. 2017), set probability standard deviation associated random effect exceeding 1 0.01. Notice one wants constrain spatial spde effect integrate zero, added constr=TRUE SPDE model definition rather component definition. want constrain \\(\\kappa_s\\) non-spatial term can use constr=TRUE corresponding label() component definition , imposes sum--zero constraint. model described translated inlabru modeling syntax : Specifying function st_coordinates input causes inlabru extracts spatial coordinates observation locations internal .data. object. Alternatively, can specify explicitly input, st_coordinates(.data.), cbind(easting, northing). , define response count, remove automatic global intercept -1, specify terms model label() statements. first kappa() statement defines \\(\\kappa_s\\), site effect, normally distributed independent (model=\"iid\"), globally zero-centered (sum zero constr=TRUE), deviation \\(\\alpha_s\\). second alpha() statement defines \\(\\alpha_s\\) spatially varying intercept spatial structure described SPDE object called ‘spde’. Remember one wants constrain kind spatial effect integrate zero, constr=TRUE added SPDE model definition rather label() arguments. third eps() statement defines \\(\\epsilon_s\\) SVC effect count effort, spatial structure also described SPDE object. weights spatially structured random slope specified weights=log_hrs argument. fourth tau() statement defines \\(\\tau_s\\) SVC year effect, spatial structure described SPDE object. weights spatially structured random slope specified weights=std_yr argument.","code":"# iid prior pc_prec <- list(prior = \"pcprec\", param = c(1, 0.1)) # components svc_components <- ~ -1 +   kappa(site_idx, model = \"iid\", constr = TRUE, hyper = list(prec = pc_prec)) +   alpha(st_coordinates, model = spde) +   eps(st_coordinates, weights = log_hrs, model = spde) +   tau(st_coordinates, weights = std_yr, model = spde) # formula, with \".\" meaning \"add all the model components\": svc_formula <- count ~ ."},{"path":"/articles/web/svc.html","id":"run-model","dir":"Articles > Web","previous_headings":"","what":"Run model","title":"Spatially Varying Coefficient Models with inlabru","text":"estimate model call bru(). First set option use (new) experimental way internal computations, see Van Niekerk et. al. (2022), sake computing speed better numerics. call bru(), give model components, specify observation likelihood model formula negative binomial distribution counts, define estimation data. ask inla() compute WAIC CPO evaluate model fit, save information necessary posterior sampling (config=TRUE, otherwise set default bru(), inlabru::predict() relies posterior sampling prediction). computing speed, choose use simplified laplace approximation strategy Empirical Bayes estimation. inla() run model takes 1 minutes standard laptop computer. Another option use Variational Bayes approximation detailed Van Niekerk Rue (2021) Van Niekerk et. al. (2022).","code":"res <- bru(svc_components,   like(     formula = svc_formula,     family = \"nbinomial\",     data = count_dat   ),   options = list(     inla.mode = \"experimental\",     control.compute = list(waic = TRUE, cpo = TRUE, config = TRUE),     control.inla = list(strategy = \"simplified.laplace\", int.strategy = \"eb\"),     verbose = FALSE   ) )"},{"path":"/articles/web/svc.html","id":"model-summaries","dir":"Articles > Web","previous_headings":"","what":"Model summaries","title":"Spatially Varying Coefficient Models with inlabru","text":"computation complete, look initial results see things went. First check posterior means hyperparameters model, mainly variance components spatial ranges spatially structured parameters. Next examine summaries random effect estimates, starting \\(\\exp(\\alpha_s)\\), effort-corrected relative abundance year = 0 (1987), given 1 hour count effort (.e., log[1]=0). Note avoid issues due \\(E[\\exp(x)|y]\\neq\\exp[E(x|y)]\\), use posterior median instead posterior mean. summary \\(\\epsilon_s\\) shows variation exponent effort correction function across space. \\(\\tau_s\\) summary shows long-term, log-linear trends robin relative abundance varied across space, annual decreases around 10% annual increases around 10%.","code":"# view results res$summary.hyperpar[-1, c(1, 2)] #>                              mean            sd #> Precision for kappa    2.21768778    0.43873027 #> Range for alpha      942.73875937  291.74427908 #> Stdev for alpha        1.94084678    0.37867018 #> Range for eps       8349.06791902 6013.19779598 #> Stdev for eps          0.42005014    0.26036091 #> Range for tau        789.63215914  323.92075506 #> Stdev for tau          0.06245474    0.01178493 summary(exp(res$summary.random$alp$\"0.5quant\")) # exp(alpha) posterior median #>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.  #>  0.06566  1.17563  3.37427  6.89193  8.45713 51.05585 summary(res$summary.random$eps$mean) # epsilon #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.8180  0.9017  0.9716  0.9608  1.0227  1.0634 summary((exp(res$summary.random$tau$\"0.5quant\") - 1) * 100) # (exp(tau)-1)*100 #>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.  #> -12.6064  -4.7108  -1.4436  -0.9444   2.6886  10.7825"},{"path":"/articles/web/svc.html","id":"svc-maps","dir":"Articles > Web","previous_headings":"","what":"SVC maps","title":"Spatially Varying Coefficient Models with inlabru","text":"Next create maps \\(\\alpha_s\\), \\(\\epsilon_s\\), \\(\\tau_s\\) inspect spatial structure parameter estimates. start creating 25-km mapping grid, projecting mapping grid modeling mesh. populate mapping grids parameter estimates (posterior median range95), turn raster stack, mask raster stack study area. Finally, plot SVCs following code. plot posterior median 95% uncertainty width (“range95”) \\(\\exp(\\kappa_s)\\), \\(\\exp(\\alpha_s)\\), \\(\\epsilon_s\\), \\(100(\\exp(\\tau_s)-1)\\). map posterior mean \\(\\tau_s\\) shows robins decreased southern part study area increased northern part. demonstrates wintering range robins shifting northward winters become warmer due climate change.","code":"# get easting and northing limits xlim <- range(hull$loc[, 1]) ylim <- range(hull$loc[, 2]) grd_dims <- round(c(x = diff(range(xlim)), y = diff(range(ylim))) / 25)  # make mesh projector to get model summaries from the mesh to the mapping grid mesh_proj <- inla.mesh.projector(   mesh,   xlim = xlim, ylim = ylim, dims = grd_dims ) # pull data kappa <- data.frame(   median = exp(res$summary.random$kappa$\"0.5quant\"),   range95 = exp(res$summary.random$kappa$\"0.975quant\") -     exp(res$summary.random$kappa$\"0.025quant\") ) alph <- data.frame(   median = exp(res$summary.random$alpha$\"0.5quant\"),   range95 = exp(res$summary.random$alpha$\"0.975quant\") -     exp(res$summary.random$alpha$\"0.025quant\") ) epsi <- data.frame(   median = res$summary.random$eps$\"0.5quant\",   range95 = (res$summary.random$eps$\"0.975quant\" -     res$summary.random$eps$\"0.025quant\") ) taus <- data.frame(   median = (exp(res$summary.random$tau$\"0.5quant\") - 1) * 100,   range95 = (exp(res$summary.random$tau$\"0.975quant\") -     exp(res$summary.random$tau$\"0.025quant\")) * 100 )  # loop to get estimates on a mapping grid pred_grids <- lapply(   list(alpha = alph, epsilon = epsi, tau = taus),   function(x) as.matrix(inla.mesh.project(mesh_proj, x)) )  # make a raster stack with the posterior median and range95 out_stk <- stack() for (j in 1:3) {   mean_j <- cbind(expand.grid(X = mesh_proj$x, Y = mesh_proj$y),     Z = c(matrix(pred_grids[[j]][, 1], grd_dims[1]))   )   mean_j <- rasterFromXYZ(mean_j, crs = epsg6703km)   range95_j <- cbind(expand.grid(X = mesh_proj$x, Y = mesh_proj$y),     Z = c(matrix(pred_grids[[j]][, 2], grd_dims[1]))   )   range95_j <- rasterFromXYZ(range95_j, crs = epsg6703km)   out_j <- stack(mean_j, range95_j)   out_stk <- addLayer(out_stk, out_j) } names(out_stk) <- c(   \"alpha_median\", \"alpha_range95\", \"epsilon_median\",   \"epsilon_range95\", \"tau_median\", \"tau_range95\" ) out_stk <- mask(out_stk, as(states, \"Spatial\")) make_plot_field <- function(data_stk, scale_label) {   spdf <- as(data_stk, \"SpatialPixelsDataFrame\")   df <- as.data.frame(spdf)   colnames(df) <- c(\"value\", \"x\", \"y\")   ggplot(states) +     geom_sf(fill = NA) +     coord_sf(datum = NA) +     geom_tile(data = df, aes(x = x, y = y, fill = value)) +     labs(x = \"\", y = \"\") +     scale_fill_distiller(scale_label, palette = \"Spectral\") +     theme_bw() +     geom_sf(fill = NA) } make_plot_site <- function(data, scale_label) {   ggplot(states) +     geom_sf() +     coord_sf(datum = NA) +     geom_sf(data = data, size = 1, mapping = aes(colour = value)) +     scale_colour_distiller(scale_label, palette = \"Spectral\") +     labs(x = \"\", y = \"\") +     theme_bw() +     geom_sf(fill = NA) }  # medians # fields alpha_s, epsilon_s, tau_s pa <- make_plot_field(   data_stk = out_stk[[\"alpha_median\"]],   scale_label = \"posterior\\nmedian\\nexp(alpha_s)\" ) pe <- make_plot_field(   data_stk = out_stk[[\"epsilon_median\"]],   scale_label = \"posterior\\nmedian\\nepsilon_s\" ) pt <- make_plot_field(   data_stk = out_stk[[\"tau_median\"]],   scale_label = \"posterior\\nmedian\\n100(exp(tau_s)-1)\" ) # sites kappa_s ps <- make_plot_site(   data = cbind(site_map, data.frame(value = kappa$median)),   scale_label = \"posterior\\nmedian\\nexp(kappa_s)\" ) # range95 # fields alpha_s, epsilon_s, tau_s pa_range95 <- make_plot_field(   data_stk = out_stk[[\"alpha_range95\"]],   scale_label = \"posterior\\nrange95\\nexp(alpha_s)\" ) pe_range95 <- make_plot_field(   data_stk = out_stk[[\"epsilon_range95\"]],   scale_label = \"posterior\\nrange95\\nepsilon_s\" ) pt_range95 <- make_plot_field(   data_stk = out_stk[[\"tau_range95\"]],   scale_label = \"posterior\\nrange95\\n100(exp(tau_s)-1)\" ) # sites kappa_s ps_range95 <- make_plot_site(   data = cbind(site_map, data.frame(value = kappa$range95)),   scale_label = \"posterior\\nrange95\\nexp(kappa_s)\" ) # plot together multiplot(ps, pa, pe, pt, cols = 2) # plot together multiplot(ps_range95, pa_range95, pe_range95, pt_range95, cols = 2)"},{"path":"/articles/web/svc.html","id":"more-information","dir":"Articles > Web","previous_headings":"","what":"More information","title":"Spatially Varying Coefficient Models with inlabru","text":"information building spatial models using SPDE approach R-INLA can found Lindgren Rue (2015), Blangiardo Camaletti (2015), Bakka et al. (2018), Krainski et al. (2018), Moraga (2019).","code":""},{"path":"/articles/web/svc.html","id":"citations","dir":"Articles > Web","previous_headings":"","what":"Citations","title":"Spatially Varying Coefficient Models with inlabru","text":"Bakka, H., Rue, H., Fuglstad, G.., Riebler, ., Bolin, D., Illian, J., Krainski, E., Simpson, D. Lindgren, F., 2018. Spatial modeling R‐INLA: review. Wiley Interdisciplinary Reviews: Computational Statistics, 10(6), p.e1443. Besag, J., 1974. Spatial interaction statistical analysis lattice systems. Journal Royal Statistical Society: Series B (Methodological), 36(2), pp.192-225. Blangiardo, M., Cameletti, M., Baio, G. Rue, H., 2013. Spatial spatio-temporal models R-INLA. Spatial spatio-temporal epidemiology, 4, pp.33-49. Finley, .O., 2011. Comparing spatially‐varying coefficients models analysis ecological data non‐stationary anisotropic residual dependence. Methods Ecology Evolution, 2(2), pp.143-154. Fuglstad, G.., Simpson, D., Lindgren, F. Rue, H., 2019. Constructing priors penalize complexity Gaussian random fields. Journal American Statistical Association, 114(525), pp.445-452. Gelfand, .E., Kim, H.J., Sirmans, C.F. Banerjee, S., 2003. Spatial modeling spatially varying coefficient processes. Journal American Statistical Association, 98(462), pp.387-396. Gómez-Rubio, V., 2020. Bayesian inference INLA. CRC Press. Krainski, E., Gómez-Rubio, V., Bakka, H., Lenzi, ., Castro-Camilo, D., Simpson, D., Lindgren, F. Rue, H., 2018. Advanced spatial modeling stochastic partial differential equations using R INLA. Chapman Hall/CRC. Lindgren, F., Rue, H. Lindström, J., 2011. explicit link Gaussian fields Gaussian Markov random fields: stochastic partial differential equation approach. Journal Royal Statistical Society: Series B (Statistical Methodology), 73(4), pp.423-498. Lindgren, F. Rue, H., 2015. Bayesian spatial modelling R-INLA. Journal statistical software, 63, pp.1-25. Lindgren, F., Bolin, D. Rue, H., 2022. SPDE approach Gaussian non-Gaussian fields: 10 years still running. Spatial Statistics, p.100599. Link, W.., Sauer, J.R. Niven, D.K., 2006. hierarchical model regional analysis population change using Christmas Bird Count data, application American Black Duck. Condor, 108(1), pp.13-24. Meehan, T.D., Michel, N.L. Rue, H., 2019. Spatial modeling Audubon Christmas Bird Counts reveals fine‐scale patterns drivers relative abundance trends. Ecosphere, 10(4), p.e02707. Moraga, P., 2019. Geospatial health data: Modeling visualization R-INLA shiny. CRC Press. R Core Team (2021). R: language environment statistical computing. R Foundation Statistical Computing, Vienna, Austria. Rue, H., Martino, S. Chopin, N., 2009. Approximate Bayesian inference latent Gaussian models using integrated nested Laplace approximations. Journal royal statistical society: Series b (statistical methodology), 71(2), pp.319-392. Simpson, D., Rue, H., Riebler, ., Martins, T.G. Sørbye, S.H., 2017. Penalising model component complexity: principled, practical approach constructing priors. Statistical science, 32(1), pp.1-28. Soykan, C.U., Sauer, J., Schuetz, J.G., LeBaron, G.S., Dale, K. Langham, G.M., 2016. Population trends North American winter birds based hierarchical models. Ecosphere, 7(5), p.e01351. Van Niekerk, J. Rue, H., 2021. Correcting Laplace Method Variational Bayes. Journal Machine Learning Research, review. Van Niekerk, J. Krainski, E. T. Rustand, D. Rue, H., 2022. new avenue Bayesian inference INLA. Submitted.","code":""},{"path":"/articles/website_examples.html","id":"package-examples","dir":"Articles","previous_headings":"","what":"Package examples","title":"Examples on the inlabru website","text":"potentially long running examples/tutorials available (https://inlabru-org.github.io/inlabru/) LGCPs - example one dimension LGCPs - Spatial covariates LGCPs - Distance sampling LGCPs - Multiple Likelihoods LGCPs - Plot sampling LGCPs - example space time LGCPs - example two dimensions Publications Random Fields 2D Random Fields One Dimension ‘Spatially Varying Coefficient Models inlabru’","code":""},{"path":"/articles/website_examples.html","id":"package-vignettes","dir":"Articles","previous_headings":"","what":"Package vignettes","title":"Examples on the inlabru website","text":"package vignettes also available (https://inlabru-org.github.io/inlabru/) Defining model components Devel: Customised model components bru_mapper system Nonlinear model approximation Iterative linearised INLA method Examples inlabru website","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Finn Lindgren. Author, maintainer, copyright holder.            Finn Lindgren continued development main code Fabian E. Bachl. Author, copyright holder.            Fabian Bachl wrote main code David L. Borchers. Contributor, data contributor, copyright holder.            David Borchers wrote code Gorilla data import sampling, multiplot tool Daniel Simpson. Contributor, copyright holder.            Daniel Simpson wrote basic LGCP sampling method Lindesay Scott-Howard. Contributor, data contributor, copyright holder.            Lindesay Scott-Howard provided MRSea data import code Seaton Andy. Contributor.            Andy Seaton provided testing bugfixes Suen Man Ho. Contributor, copyright holder.            Man Ho Suen contributed features aggregated responses vignett updates Roudier Pierre. Contributor, copyright holder.            Pierre Roudier contributed general quantile summaries Meehan Tim. Contributor, copyright holder.            Tim Meehan contributed SVC vignette robins data","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Fabian E. Bachl, Finn Lindgren, David L. Borchers, Janine B. Illian (2019), inlabru: R package Bayesian spatial modelling ecological survey data, Methods Ecology Evolution, British Ecological Society, 10, 760--766, doi:10.1111/2041-210X.13168 Yuan Yuan, Fabian E. Bachl, Finn Lindgren, David L. Borchers, Janine B. Illian, Stephen T. Buckland, Håvard Rue, Tim Gerrodette (2017), Point process models spatio-temporal distance sampling data large-scale survey blue whalesAnnals Applied Statistics, 11, 2270--2297, doi:10.1214/17-AOAS1078","code":"@Article{,   title = {{inlabru}: an {R} package for Bayesian spatial modelling from ecological survey data},   author = {Fabian E. Bachl and Finn Lindgren and David L. Borchers and Janine B. Illian},   year = {2019},   journal = {Methods in Ecology and Evolution},   volume = {10},   pages = {760--766},   doi = {10.1111/2041-210X.13168},   publisher = {British Ecological Society}, } @Article{,   author = {{Yuan} and {Yuan} and {Bachl} and Fabian E. and {Lindgren} and {Finn} and {Borchers} and David L. and {Illian} and Janine B. and {Buckland} and Stephen T. and {Rue} and {Håvard} and {Gerrodette} and {Tim}},   doi = {10.1214/17-AOAS1078},   fjournal = {Annals of Applied Statistics},   journal = {Ann. Appl. Stat.},   month = {12},   number = {4},   pages = {2270--2297},   publisher = {The Institute of Mathematical Statistics},   title = {Point process models for spatio-temporal distance sampling data from a large-scale survey of blue whales},   doi = {10.1214/17-AOAS1078},   volume = {11},   year = {2017}, }"},{"path":"/index.html","id":"inlabru","dir":"","previous_headings":"","what":"Bayesian Latent Gaussian Modelling using INLA and Extensions","title":"Bayesian Latent Gaussian Modelling using INLA and Extensions","text":"goal inlabru facilitate spatial modeling using integrated nested Laplace approximation via R-INLA package. Additionally, extends GAM-like model class general nonlinear predictor expressions, implements log Gaussian Cox process likelihood modeling univariate spatial point processes based ecological survey data. Model components specified general inputs mapping methods latent variables, predictors specified via general R expressions, separate expressions observation likelihood model multi-likelihood models. prediction method based fast Monte Carlo sampling allows posterior prediction general expressions latent variables. See Fabian E. Bachl, Finn Lindgren, David L. Borchers, Janine B. Illian (2019), inlabru: R package Bayesian spatial modelling ecological survey data, Methods Ecology Evolution, British Ecological Society, 10, 760–766, doi:10.1111/2041-210X.13168, citation(\"inlabru\"). inlabru.org website links old tutorials code examples versions 2.1.13. later versions, updated versions tutorials, well new examples, can found https://inlabru-org.github.io/inlabru/articles/","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Bayesian Latent Gaussian Modelling using INLA and Extensions","text":"can install current CRAN version inlabru: can install latest bugfix release inlabru GitHub : can install development version inlabru GitHub track development version builds via inlabru-org.r-universe.dev:","code":"install.packages(\"inlabru\") # install.packages(\"remotes\") remotes::install_github(\"inlabru-org/inlabru\", ref=\"stable\") # install.packages(\"remotes\") remotes::install_github(\"inlabru-org/inlabru\", ref=\"devel\") # Enable universe(s) by inlabru-org options(repos = c(   inlabruorg = 'https://inlabru-org.r-universe.dev',   CRAN = 'https://cloud.r-project.org'))  # Install some packages install.packages('inlabru')"},{"path":"/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Bayesian Latent Gaussian Modelling using INLA and Extensions","text":"basic example shows fit simple spatial Log Gaussian Cox Process (LGCP) predicts intensity: R installation PROJ6/GDAL3, INLA >= 20.06.18, loading old spatial objects, may need apply rgdal::rebuild_CRS() method fully usable. data objects inlabru updated, need conversion anymore.","code":"# Load libraries options(\"rgdal_show_exportToProj4_warnings\"=\"none\") library(inlabru) #> Loading required package: sp library(INLA) #> Loading required package: Matrix #> Loading required package: foreach #> Loading required package: parallel #> This is INLA_22.09.02 built 2022-09-02 19:28:51 UTC. #>  - See www.r-inla.org/contact-us for how to get help. #>  - To enable PARDISO sparse library; see inla.pardiso() library(ggplot2)  # Load the data data(gorillas, package = \"inlabru\")  # Construct latent model components matern <- inla.spde2.pcmatern(gorillas$mesh,                                prior.sigma = c(0.1, 0.01),                                prior.range = c(0.01, 0.01)) cmp <- coordinates ~ mySmooth(coordinates, model = matern) + Intercept(1) # Fit LGCP model # This particular bru/like combination has a shortcut function lgcp() as well fit <- bru(   components = cmp,   like(     formula = coordinates ~ .,     family = \"cp\",     data = gorillas$nests,     samplers = gorillas$boundary,     domain = list(coordinates = gorillas$mesh)   ),   options = list(control.inla = list(int.strategy = \"eb\")) )  # Predict Gorilla nest intensity lambda <- predict(fit,                   pixels(gorillas$mesh, mask = gorillas$boundary),                   ~ exp(mySmooth + Intercept))  # Plot the result ggplot() +    gg(lambda) +   gg(gorillas$nests, color = \"red\", size = 0.2) +   coord_equal() +   ggtitle(\"Nest intensity per km squared\")"},{"path":"/reference/Poisson1_1D.html","id":null,"dir":"Reference","previous_headings":"","what":"1-Dimensional Homogeneous Poisson example. — Poisson1_1D","title":"1-Dimensional Homogeneous Poisson example. — Poisson1_1D","text":"Point data count data, together intensity function expected counts homogeneous 1-dimensional Poisson process example.","code":""},{"path":"/reference/Poisson1_1D.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1-Dimensional Homogeneous Poisson example. — Poisson1_1D","text":"","code":"data(Poisson1_1D)"},{"path":"/reference/Poisson1_1D.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"1-Dimensional Homogeneous Poisson example. — Poisson1_1D","text":"data contain following R objects: lambda1_1D: function defining intensity function nonhomogeneous Poisson process. Note function defined interval (0,55). E_nc1 expected counts gridded data. pts1 locations observed points (data frame one column, named x). countdata1 data frame three columns, containing count data:","code":""},{"path":"/reference/Poisson1_1D.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"1-Dimensional Homogeneous Poisson example. — Poisson1_1D","text":"","code":"# \\donttest{ if (require(\"ggplot2\", quietly = TRUE)) {   data(Poisson1_1D)   ggplot(countdata1) +     geom_point(data = countdata1, aes(x = x, y = count), col = \"blue\") +     ylim(0, max(countdata1$count)) +     geom_point(data = pts1, aes(x = x), y = 0.2, shape = \"|\", cex = 4) +     geom_point(       data = countdata1, aes(x = x), y = 0, shape = \"+\",       col = \"blue\", cex = 4     ) +     xlab(expression(bold(s))) +     ylab(\"count\") }  # }"},{"path":"/reference/Poisson2_1D.html","id":null,"dir":"Reference","previous_headings":"","what":"1-Dimensional NonHomogeneous Poisson example. — Poisson2_1D","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson2_1D","text":"Point data count data, together intensity function expected counts unimodal nonhomogeneous 1-dimensional Poisson process example.","code":""},{"path":"/reference/Poisson2_1D.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson2_1D","text":"","code":"data(Poisson2_1D)"},{"path":"/reference/Poisson2_1D.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson2_1D","text":"data contain following R objects: lambda2_1D: function defining intensity function nonhomogeneous Poisson process. Note function defined interval (0,55). cov2_1D: function gives call 'habitat suitability' covariate 1D space. E_nc2 expected counts gridded data. pts2 locations observed points (data frame one column, named x). countdata2 data frame three columns, containing count data:","code":""},{"path":"/reference/Poisson2_1D.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson2_1D","text":"","code":"# \\donttest{ if (require(\"ggplot2\", quietly = TRUE)) {   data(Poisson2_1D)   p1 <- ggplot(countdata2) +     geom_point(data = countdata2, aes(x = x, y = count), col = \"blue\") +     ylim(0, max(countdata2$count, E_nc2)) +     geom_point(       data = countdata2, aes(x = x), y = 0, shape = \"+\",       col = \"blue\", cex = 4     ) +     geom_point(       data = data.frame(x = countdata2$x, y = E_nc2), aes(x = x),       y = E_nc2, shape = \"_\", cex = 5     ) +     xlab(expression(bold(s))) +     ylab(\"count\")   ss <- seq(0, 55, length = 200)   lambda <- lambda2_1D(ss)   p2 <- ggplot() +     geom_line(       data = data.frame(x = ss, y = lambda),       aes(x = x, y = y), col = \"blue\"     ) +     ylim(0, max(lambda)) +     geom_point(data = pts2, aes(x = x), y = 0.2, shape = \"|\", cex = 4) +     xlab(expression(bold(s))) +     ylab(expression(lambda(bold(s))))   multiplot(p1, p2, cols = 1) }  # }"},{"path":"/reference/Poisson3_1D.html","id":null,"dir":"Reference","previous_headings":"","what":"1-Dimensional NonHomogeneous Poisson example. — Poisson3_1D","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson3_1D","text":"Point data count data, together intensity function expected counts multimodal nonhomogeneous 1-dimensional Poisson process example. Counts given two different gridded data interval widths.","code":""},{"path":"/reference/Poisson3_1D.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson3_1D","text":"","code":"data(Poisson3_1D)"},{"path":"/reference/Poisson3_1D.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson3_1D","text":"data contain following R objects: lambda3_1D: function defining intensity function nonhomogeneous Poisson process. Note function defined interval (0,55). E_nc3a expected counts gridded data wider bins (10 bins). E_nc3b expected counts gridded data wider bins (20 bins). pts3 locations observed points (data frame one column, named x). countdata3a data frame three columns, containing count data 10-interval case: countdata3b data frame three columns, containing count data 20-interval case:","code":""},{"path":"/reference/Poisson3_1D.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson3_1D","text":"","code":"# \\donttest{ if (require(\"ggplot2\", quietly = TRUE)) {   data(Poisson3_1D)   # first the plots for the 10-bin case:   p1a <- ggplot(countdata3a) +     geom_point(data = countdata3a, aes(x = x, y = count), col = \"blue\") +     ylim(0, max(countdata3a$count, E_nc3a)) +     geom_point(       data = countdata3a, aes(x = x), y = 0, shape = \"+\",       col = \"blue\", cex = 4     ) +     geom_point(       data = data.frame(x = countdata3a$x, y = E_nc3a),       aes(x = x), y = E_nc3a, shape = \"_\", cex = 5     ) +     xlab(expression(bold(s))) +     ylab(\"count\")   ss <- seq(0, 55, length = 200)   lambda <- lambda3_1D(ss)   p2a <- ggplot() +     geom_line(       data = data.frame(x = ss, y = lambda), aes(x = x, y = y),       col = \"blue\"     ) +     ylim(0, max(lambda)) +     geom_point(data = pts3, aes(x = x), y = 0.2, shape = \"|\", cex = 4) +     xlab(expression(bold(s))) +     ylab(expression(lambda(bold(s))))   multiplot(p1a, p2a, cols = 1)    # Then the plots for the 20-bin case:   p1a <- ggplot(countdata3b) +     geom_point(data = countdata3b, aes(x = x, y = count), col = \"blue\") +     ylim(0, max(countdata3b$count, E_nc3b)) +     geom_point(       data = countdata3b, aes(x = x), y = 0, shape = \"+\",       col = \"blue\", cex = 4     ) +     geom_point(       data = data.frame(x = countdata3b$x, y = E_nc3b),       aes(x = x), y = E_nc3b, shape = \"_\", cex = 5     ) +     xlab(expression(bold(s))) +     ylab(\"count\")   ss <- seq(0, 55, length = 200)   lambda <- lambda3_1D(ss)   p2a <- ggplot() +     geom_line(       data = data.frame(x = ss, y = lambda), aes(x = x, y = y),       col = \"blue\"     ) +     ylim(0, max(lambda)) +     geom_point(data = pts3, aes(x = x), y = 0.2, shape = \"|\", cex = 4) +     xlab(expression(bold(s))) +     ylab(expression(lambda(bold(s))))   multiplot(p1a, p2a, cols = 1) }   # }"},{"path":"/reference/add_mappers.html","id":null,"dir":"Reference","previous_headings":"","what":"Add component input/latent mappers — add_mappers","title":"Add component input/latent mappers — add_mappers","text":"Add missing mappers input data latent variables, based likelihood data FUNCTION_DESCRIPTION","code":""},{"path":"/reference/add_mappers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add component input/latent mappers — add_mappers","text":"","code":"add_mappers(...)  # S3 method for component add_mappers(component, lhoods, ...)  # S3 method for component_list add_mappers(components, lhoods, ...)"},{"path":"/reference/add_mappers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add component input/latent mappers — add_mappers","text":"... Parameters passed methods component PARAM_DESCRIPTION lhoods PARAM_DESCRIPTION","code":""},{"path":"/reference/add_mappers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add component input/latent mappers — add_mappers","text":"OUTPUT_DESCRIPTION","code":""},{"path":"/reference/add_mappers.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add component input/latent mappers — add_mappers","text":"DETAILS","code":""},{"path":"/reference/add_mappers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add component input/latent mappers — add_mappers","text":"","code":"if (FALSE) { if (interactive()) {   # EXAMPLE1 } }"},{"path":"/reference/amatrix_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct A-matrix — amatrix_eval","title":"Construct A-matrix — amatrix_eval","text":"Constructs -matrix components data","code":""},{"path":"/reference/amatrix_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct A-matrix — amatrix_eval","text":"","code":"amatrix_eval(...)  # S3 method for component amatrix_eval(component, data, ...)  # S3 method for component_list amatrix_eval(components, data, ...)"},{"path":"/reference/amatrix_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct A-matrix — amatrix_eval","text":"... Unused. component component. data data.frame Spatial* object covariates /point locations.","code":""},{"path":"/reference/amatrix_eval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct A-matrix — amatrix_eval","text":"-matrix.","code":""},{"path":"/reference/amatrix_eval.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Construct A-matrix — amatrix_eval","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"/reference/bincount.html","id":null,"dir":"Reference","previous_headings":"","what":"1D LGCP bin count simulation and comparison with data — bincount","title":"1D LGCP bin count simulation and comparison with data — bincount","text":"common procedure analyzing distribution 1D points chose binning plot data's histogram respect binning. function compares counts histogram calculates simulations 1D log Gaussian Cox process conditioned number data samples. bin results median number counts well confidence interval. LGCP plausible model observed points histrogram counts (number points within bin) within confidence intervals. Note proper comparison  multiple testing problem function solve .","code":""},{"path":"/reference/bincount.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1D LGCP bin count simulation and comparison with data — bincount","text":"","code":"bincount(   result,   predictor,   observations,   breaks,   nint = 20,   probs = c(0.025, 0.5, 0.975),   ... )"},{"path":"/reference/bincount.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"1D LGCP bin count simulation and comparison with data — bincount","text":"result result object bru() lgcp() call predictor formula describing prediction 1D LGCP via predict(). observations vector observed values breaks vector bin boundaries nint Number integration points per bin. Increase bins wide probs numeric vector probabilities values [0,1] ... arguments passed predict.bru()","code":""},{"path":"/reference/bincount.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"1D LGCP bin count simulation and comparison with data — bincount","text":"data.frame ggplot attribute ggp","code":""},{"path":"/reference/bincount.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"1D LGCP bin count simulation and comparison with data — bincount","text":"","code":"if (FALSE) { if (require(ggplot2)) {   # Load a point pattern   data(Poisson2_1D)    # Take a look at the point (and frequency) data    ggplot(pts2) +     geom_histogram(aes(x = x), binwidth = 55 / 20, boundary = 0, fill = NA, color = \"black\") +     geom_point(aes(x), y = 0, pch = \"|\", cex = 4) +     coord_fixed(ratio = 1)    # Fit an LGCP model   x <- seq(0, 55, length = 50)   mesh1D <- inla.mesh.1d(x, boundary = \"free\")   mdl <- x ~ spde1D(x, model = inla.spde2.matern(mesh1D)) + Intercept(1)   fit.spde <- lgcp(mdl, pts2, domain = list(x = c(0, 55)))    # Calculate bin statistics   bc <- bincount(     result = fit.spde,     observations = pts2,     breaks = seq(0, max(pts2), length = 12),     predictor = x ~ exp(spde1D + Intercept)   )     # Plot them!   attributes(bc)$ggp } }"},{"path":"/reference/bru.html","id":null,"dir":"Reference","previous_headings":"","what":"Convenient model fitting using (iterated) INLA — bru","title":"Convenient model fitting using (iterated) INLA — bru","text":"method wrapper INLA::inla provides multiple enhancements. Easy usage spatial covariates automatic construction inla projection matrices (spatial) SPDE models. feature accessible via components parameter. Practical examples use spatial data means components parameter can also found looking lgcp function's documentation. Constructing multiple likelihoods straight forward. See like information provide additional likelihoods bru using ... parameter list. Support non-linear predictors. See example . Log Gaussian Cox process (LGCP) inference available using cp family (even easier) using lgcp function.","code":""},{"path":"/reference/bru.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convenient model fitting using (iterated) INLA — bru","text":"","code":"bru(components = ~Intercept(1), ..., options = list(), .envir = parent.frame())  bru_rerun(result, options = list())"},{"path":"/reference/bru.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convenient model fitting using (iterated) INLA — bru","text":"components formula-like specification latent components. Also used define default linear additive predictor.  See component() details. ... Likelihoods, constructed calling like(), named parameters can passed single like() call. Note arguments evaluated calling like() order detect like objects. means special arguments need evaluated context response_data data (Ntrials) may work way direct calls like(). options bru_options options object list options passed bru_options() .envir Environment component evaluation (non-formula specification used) result previous estimation object class bru","code":""},{"path":"/reference/bru.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convenient model fitting using (iterated) INLA — bru","text":"bru returns object class \"bru\". bru object inherits INLA::inla (see inla documentation properties) adds additional information stored bru_info field.","code":""},{"path":"/reference/bru.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convenient model fitting using (iterated) INLA — bru","text":"bru_rerun Continue optimisation previously computed estimate.","code":""},{"path":"/reference/bru.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convenient model fitting using (iterated) INLA — bru","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"/reference/bru.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convenient model fitting using (iterated) INLA — bru","text":"","code":"# \\donttest{ if (bru_safe_inla(multicore = FALSE)) {    # Simulate some covariates x and observations y   input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, y <- 5 + 2 * x + rnorm(10, mean = 0, sd = 0.1))    # Fit a Gaussian likelihood model   fit <- bru(y ~ x + Intercept, family = \"gaussian\", data = input.df)    # Obtain summary   fit$summary.fixed } #> Current num.threads is '2:1'. #> Setting INLA option num.threads to '1:1'. Previous value '2:1'. #> Warning: All covariate evaluations for 'Intercept' are NULL; an intercept component was likely intended. #>   Implicit latent intercept component specification is deprecated since version 2.1.14. #>   Use explicit notation '+ Intercept(1)' instead (or '+1' for '+ Intercept(1)'). #>               mean         sd 0.025quant 0.5quant 0.975quant     mode #> x         2.087383 0.05158827   1.984236 2.087384   2.190525 2.087385 #> Intercept 4.993026 0.03648013   4.920087 4.993026   5.065960 4.993028 #>                    kld #> x         1.025314e-06 #> Intercept 1.022015e-06   if (bru_safe_inla(multicore = FALSE)) {    # Alternatively, we can use the like() function to construct the likelihood:    lik <- like(family = \"gaussian\", formula = y ~ x + Intercept, data = input.df)   fit <- bru(~ x + Intercept(1), lik)   fit$summary.fixed } #> Current num.threads is '1:1'. #> No num.threads change needed. #>               mean         sd 0.025quant 0.5quant 0.975quant     mode #> x         2.087383 0.05159186   1.984230 2.087384   2.190532 2.087385 #> Intercept 4.993026 0.03648266   4.920082 4.993026   5.065964 4.993028 #>                    kld #> x         1.040805e-06 #> Intercept 1.037465e-06  # An important addition to the INLA methodology is bru's ability to use # non-linear predictors. Such a predictor can be formulated via like()'s # \\code{formula} parameter. The z(1) notation is needed to ensure that # the z component should be interpreted as single latent variable and not # a covariate:  if (bru_safe_inla(multicore = FALSE)) {   z <- 2   input.df <- within(input.df, y <- 5 + exp(z) * x + rnorm(10, mean = 0, sd = 0.1))   lik <- like(     family = \"gaussian\", data = input.df,     formula = y ~ exp(z) * x + Intercept   )   fit <- bru(~ z(1) + Intercept(1), lik)    # Check the result (z posterior should be around 2)   fit$summary.fixed } #> Current num.threads is '1:1'. #> No num.threads change needed. #>               mean          sd 0.025quant 0.5quant 0.975quant     mode #> z         2.003187 0.007485033   1.988233 2.003187   2.018140 2.003187 #> Intercept 5.006595 0.038886540   4.928844 5.006596   5.084341 5.006597 #>                    kld #> z         8.776781e-07 #> Intercept 1.020951e-06 # }"},{"path":"/reference/bru_call_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Additional bru options — bru_call_options","title":"Additional bru options — bru_call_options","text":"Construct bru_options object including default global options, converting deprecated option names.","code":""},{"path":"/reference/bru_call_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Additional bru options — bru_call_options","text":"","code":"bru_call_options(...)"},{"path":"/reference/bru_call_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Additional bru options — bru_call_options","text":"... Options passed .bru_options()","code":""},{"path":"/reference/bru_call_options.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Additional bru options — bru_call_options","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"/reference/bru_call_options.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Additional bru options — bru_call_options","text":"","code":"# \\donttest{  opts <- bru_call_options()  # Print them: opts #> $bru_verbose #> [1] 0 #>  #> $bru_verbose_store #> [1] Inf #>  #> $bru_max_iter #> [1] 10 #>  #> $bru_run #> [1] TRUE #>  #> $bru_int_args #> $bru_int_args$method #> [1] \"stable\" #>  #> $bru_int_args$nsub1 #> [1] 30 #>  #> $bru_int_args$nsub2 #> [1] 9 #>  #>  #> $bru_method #> $bru_method$taylor #> [1] \"pandemic\" #>  #> $bru_method$search #> [1] \"all\" #>  #> $bru_method$factor #> [1] 1.618034 #>  #> $bru_method$rel_tol #> [1] 0.01 #>  #> $bru_method$max_step #> [1] 2 #>  #> $bru_method$lin_opt_method #> [1] \"onestep\" #>  #>  #> $bru_compress_cp #> [1] TRUE #>  #> $E #> [1] 1 #>  #> $Ntrials #> [1] 1 #>  #> $control.compute #> $control.compute$config #> [1] TRUE #>  #> $control.compute$dic #> [1] TRUE #>  #> $control.compute$waic #> [1] TRUE #>  #>  #> $control.inla #> $control.inla$int.strategy #> [1] \"auto\" #>  #>  #> $control.fixed #> $control.fixed$expand.factor.strategy #> [1] \"inla\" #>  #>  #> attr(,\"class\") #> [1] \"bru_options\" \"list\"        # }"},{"path":"/reference/bru_compute_linearisation.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute inlabru model linearisation information — bru_compute_linearisation","title":"Compute inlabru model linearisation information — bru_compute_linearisation","text":"Compute inlabru model linearisation information","code":""},{"path":"/reference/bru_compute_linearisation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute inlabru model linearisation information — bru_compute_linearisation","text":"","code":"bru_compute_linearisation(...)  # S3 method for component bru_compute_linearisation(   cmp,   model,   lhood_expr,   data,   state,   A,   effects,   pred0,   allow_latent,   allow_combine,   eps,   ... )  # S3 method for bru_like bru_compute_linearisation(lhood, model, data, state, A, eps, ...)  # S3 method for bru_like_list bru_compute_linearisation(lhoods, model, state, A, eps = 1e-05, ...)  # S3 method for bru_model bru_compute_linearisation(model, lhoods, state, A, ...)"},{"path":"/reference/bru_compute_linearisation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute inlabru model linearisation information — bru_compute_linearisation","text":"... Parameters passed methods cmp bru_component object model bru_model object lhood_expr predictor expression data Input data state state information, list named vectors -matrix information: bru_component: Precomputed -matrix component bru_like: list named -matrices components likelihood component bru_like_list: list, element list named -matrices. effects bru_component: Precomputed effect list components involved likelihood expression pred0 Precomputed predictor given state allow_latent logical. TRUE, latent state component directly available predictor expression, _latent suffix. allow_combine logical; TRUE, predictor expression may involve several rows input data influence row. eps finite difference step size lhood bru_like object lhoods bru_like_list object","code":""},{"path":"/reference/bru_env_get.html","id":null,"dir":"Reference","previous_headings":"","what":"Get access to the internal environment — bru_env_get","title":"Get access to the internal environment — bru_env_get","text":"Get access internal environment","code":""},{"path":"/reference/bru_env_get.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get access to the internal environment — bru_env_get","text":"","code":"bru_env_get()"},{"path":"/reference/bru_env_get.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get access to the internal environment — bru_env_get","text":"environment defined aaaaa.R loaded first.","code":""},{"path":"/reference/bru_fill_missing.html","id":null,"dir":"Reference","previous_headings":"","what":"Fill in missing values in Spatial grids — bru_fill_missing","title":"Fill in missing values in Spatial grids — bru_fill_missing","text":"Computes nearest-available-value imputation missing values space","code":""},{"path":"/reference/bru_fill_missing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fill in missing values in Spatial grids — bru_fill_missing","text":"","code":"bru_fill_missing(   data,   where,   values,   layer = NULL,   selector = NULL,   batch_size = 500 )"},{"path":"/reference/bru_fill_missing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fill in missing values in Spatial grids — bru_fill_missing","text":"data SpatialPointsDataFrame, SpatialPixelsDataFrame, SpatialGridDataFrame containg data use filling , matrix, data.frame, SpatialPoints SpatialPointsDataFrame, containing locations evaluated values values vector values filled .na(values) TRUE layer, selector Specifies data column columns extract data, see component() details. batch_size Size nearest-neighbour calculation blocks, limit memory computational complexity.","code":""},{"path":"/reference/bru_fill_missing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fill in missing values in Spatial grids — bru_fill_missing","text":"infilled vector values","code":""},{"path":"/reference/bru_fill_missing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fill in missing values in Spatial grids — bru_fill_missing","text":"","code":"if (FALSE) { if (bru_safe_inla()) {   points <-     sp::SpatialPointsDataFrame(       matrix(1:6, 3, 2),       data = data.frame(val = c(NA, NA, NA))     )   input_coord <- expand.grid(x = 0:7, y = 0:7)   input <-     sp::SpatialPixelsDataFrame(       input_coord,       data = data.frame(val = as.vector(input_coord$y))     )   points$val <- bru_fill_missing(input, points, points$val)   print(points)    # To fill in missing values in a grid:   print(input$val[c(3, 30)])   input$val[c(3, 30)] <- NA # Introduce missing values   input$val <- bru_fill_missing(input, input, input$val)   print(input$val[c(3, 30)]) } }"},{"path":"/reference/bru_get_mapper.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract mapper information from INLA model component objects — bru_get_mapper","title":"Extract mapper information from INLA model component objects — bru_get_mapper","text":"component definitions automatically attempt extract mapper information model object calling generic bru_get_mapper. class method implementation return bru_mapper object suitable given latent model.","code":""},{"path":"/reference/bru_get_mapper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract mapper information from INLA model component objects — bru_get_mapper","text":"","code":"bru_get_mapper(model, ...)  # S3 method for inla.spde bru_get_mapper(model, ...)  # S3 method for inla.rgeneric bru_get_mapper(model, ...)  bru_get_mapper_safely(model, ...)"},{"path":"/reference/bru_get_mapper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract mapper information from INLA model component objects — bru_get_mapper","text":"model model component object ... Arguments passed methods","code":""},{"path":"/reference/bru_get_mapper.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract mapper information from INLA model component objects — bru_get_mapper","text":"bru_mapper object defined model component","code":""},{"path":"/reference/bru_get_mapper.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract mapper information from INLA model component objects — bru_get_mapper","text":"bru_get_mapper.inla.spde extract indexed mapper model$mesh object contained model object. returns NULL gives warning known mesh type found model object. bru_get_mapper.inla.rgeneric returns mapper given call model$f$rgeneric$definition(\"mapper\"). support inla.rgeneric models, add \"mapper\" option cmd argument rgeneric definition function. need store mapper object well.  Alternative, define model using subclass define corresponding bru_get_mapper.subclass method return corresponding bru_mapper object. bru_get_mapper_safely tries call bru_get_mapper, returns NULL fails (e.g. due available class method). call succeeds returns non-NULL, checks object inherits bru_mapper class, gives error .","code":""},{"path":[]},{"path":"/reference/bru_get_mapper.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract mapper information from INLA model component objects — bru_get_mapper","text":"","code":"if (bru_safe_inla(quietly = TRUE)) {   library(INLA)   mesh <- inla.mesh.create(globe = 2)   spde <- inla.spde2.pcmatern(mesh,                               prior.range = c(1, 0.5),                               prior.sigma = c(1, 0.5))   mapper <- bru_get_mapper(spde)   ibm_n(mapper) } #> Loading required package: Matrix #> Loading required package: foreach #> Loading required package: parallel #> This is INLA_22.10.06-2 built 2022-10-06 11:03:14 UTC. #>  - See www.r-inla.org/contact-us for how to get help. #>  - To enable PARDISO sparse library; see inla.pardiso() #> [1] 42"},{"path":"/reference/bru_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for bru_info objects — summary.bru_info","title":"Methods for bru_info objects — summary.bru_info","text":"Methods bru_info objects Summary bru_info objects","code":""},{"path":"/reference/bru_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for bru_info objects — summary.bru_info","text":"","code":"# S3 method for bru_info summary(object, ...)  # S3 method for summary_bru_info print(x, ...)  bru_info(...)  # S3 method for character bru_info(method, ..., inlabru_version = NULL, INLA_version = NULL)  # S3 method for bru bru_info(object, ...)"},{"path":"/reference/bru_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for bru_info objects — summary.bru_info","text":"object Object operate ... Arguments passed methods x summary_bru_info object printed method character; type estimation method used inlabru_version character; inlabru package version. Default: NULL, automatically detecting version INLA_version character; INLA package version. Default: NULL, automatically detecting version","code":""},{"path":"/reference/bru_int_polygon.html","id":null,"dir":"Reference","previous_headings":"","what":"Integration points for polygons inside an inla.mesh — bru_int_polygon","title":"Integration points for polygons inside an inla.mesh — bru_int_polygon","text":"Integration points polygons inside inla.mesh","code":""},{"path":"/reference/bru_int_polygon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Integration points for polygons inside an inla.mesh — bru_int_polygon","text":"","code":"bru_int_polygon(mesh, polylist, method = NULL, samplers = NULL, ...)"},{"path":"/reference/bru_int_polygon.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Integration points for polygons inside an inla.mesh — bru_int_polygon","text":"mesh inla.mesh object polylist list inla.mesh.segment objects method integration method use (\"stable\", aggregation mesh vertices, \"direct\") samplers non-NULL, SpatialPolygons* object, used instead polylist ... Arguments passed low level integration method (make_stable_integration_points)","code":""},{"path":"/reference/bru_int_polygon.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Integration points for polygons inside an inla.mesh — bru_int_polygon","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"/reference/bru_int_polygon_old.html","id":null,"dir":"Reference","previous_headings":"","what":"Integration points for polygons inside an inla.mesh — bru_int_polygon_old","title":"Integration points for polygons inside an inla.mesh — bru_int_polygon_old","text":"Integration points polygons inside inla.mesh","code":""},{"path":"/reference/bru_int_polygon_old.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Integration points for polygons inside an inla.mesh — bru_int_polygon_old","text":"","code":"bru_int_polygon_old(mesh, polylist, method = NULL, ...)"},{"path":"/reference/bru_int_polygon_old.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Integration points for polygons inside an inla.mesh — bru_int_polygon_old","text":"mesh inla.mesh object polylist list inla.mesh.segment objects method integration method use (\"stable\", aggregation mesh vertices, \"direct\") ... Arguments passed low level integration method (make_stable_integration_points)","code":""},{"path":"/reference/bru_int_polygon_old.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Integration points for polygons inside an inla.mesh — bru_int_polygon_old","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"/reference/bru_log.html","id":null,"dir":"Reference","previous_headings":"","what":"inlabru log message methods — bru_log_reset","title":"inlabru log message methods — bru_log_reset","text":"Resets inlabru log object Retrieve, add, /print log messages","code":""},{"path":"/reference/bru_log.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"inlabru log message methods — bru_log_reset","text":"","code":"bru_log_reset()  bru_log_get(pretty = FALSE)  bru_log_message(   ...,   domain = NULL,   appendLF = TRUE,   verbosity = 1,   allow_verbose = TRUE,   verbose = NULL,   verbose_store = NULL )  bru_log(txt, verbose = NULL)  bru_log_active(activation = NULL)"},{"path":"/reference/bru_log.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"inlabru log message methods — bru_log_reset","text":"pretty logical; TRUE, return single string log messages separated terminated line feeds, suitable cat(...). FALSE, return raw log vector strings, suitable cat(..., sep = \"\\n\"). Default: FALSE ... Zero objects passed base::.makeMessage() domain Domain translations, passed base::.makeMessage() appendLF logical; whether add newline message. used verbose output. verbosity numeric value describing verbosity level message allow_verbose Whether allow verbose output. Must set FALSE options object initialised. verbose logical; TRUE, print log message screen message(txt). Default: bru_options_get(\"bru_verbose\") verbose_store verbose, controlling messages stored global log object. Can controlled via bru_verbose_store bru_options_set(). txt character; log message. activation logical; whether activate (TRUE) deactivate (FALSE) inlabru logging system. Default: NULL, keep current activation state","code":""},{"path":"/reference/bru_log.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"inlabru log message methods — bru_log_reset","text":"bru_log_get RETURN_VALUE bru_log_message OUTPUT_DESCRIPTION bru_log invisibly returns added log message. bru_log_active returns previous activation state","code":""},{"path":"/reference/bru_log.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"inlabru log message methods — bru_log_reset","text":"bru_log_reset() clears log contents. bru_log_message DETAILS log message stored log active, see bru_log_active()","code":""},{"path":"/reference/bru_log.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"inlabru log message methods — bru_log_reset","text":"Fabian E. Bachl bachlfab@gmail.com Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"/reference/bru_log.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"inlabru log message methods — bru_log_reset","text":"","code":"if (FALSE) { if (interactive()) {   # EXAMPLE1 } } if (FALSE) { if (interactive()) {   # EXAMPLE1 } } code_runner <- function() {   oa <- bru_log_active(TRUE)   on.exit(bru_log_active(oa))   bru_log(\"Test message\") } bru_log_active() #> [1] Inf code_runner() cat(bru_log_get()) #> 2022-10-06 16:53:48: inlabru loaded 2022-10-06 16:53:48: Clear override options 2022-10-06 16:53:53: iinla: Iteration 1 [max:1] 2022-10-06 16:53:54: iinla: Iteration 1 [max:10] 2022-10-06 16:53:54: iinla: |lin1-lin0| = 355.9 #>        <eta-lin1,delta>/|delta| = 0 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 0 2022-10-06 16:53:54: iinla: Iteration 2 [max:10] 2022-10-06 16:53:55: iinla: |lin1-lin0| = 7.1e-07 #>        <eta-lin1,delta>/|delta| = 2.262e-14 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 3.788e-14 2022-10-06 16:53:55: iinla: Max deviation from previous: 0.352% of SD [stop if: <1%] 2022-10-06 16:53:55: iinla: Convergence criterion met, running final INLA integration with known theta mode. 2022-10-06 16:53:55: iinla: Iteration 3 [max:10] 2022-10-06 16:53:55: iinla: Iteration 1 [max:10] 2022-10-06 16:53:55: iinla: Step rescaling: 61.8%, Contract 2022-10-06 16:53:55: iinla: Step rescaling: 38.2%, Contract 2022-10-06 16:53:55: iinla: Step rescaling: 27.12%, Optimisation 2022-10-06 16:53:55: iinla: |lin1-lin0| = 375.9 #>        <eta-lin1,delta>/|delta| = -214.7 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 115.1 2022-10-06 16:53:55: iinla: Step rescaling: 27.1% 2022-10-06 16:53:55: iinla: Iteration 2 [max:10] 2022-10-06 16:53:56: iinla: Step rescaling: 99.55%, Optimisation 2022-10-06 16:53:56: iinla: |lin1-lin0| = 243.8 #>        <eta-lin1,delta>/|delta| = -1.3 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 12.55 2022-10-06 16:53:56: iinla: Step rescaling: 99.6% 2022-10-06 16:53:56: iinla: Max deviation from previous: 50200% of SD [stop if: <1%] 2022-10-06 16:53:56: iinla: Iteration 3 [max:10] 2022-10-06 16:53:56: iinla: Step rescaling: 162%, Expand 2022-10-06 16:53:56: iinla: Step rescaling: 100%, Overstep 2022-10-06 16:53:56: iinla: Step rescaling: 101.8%, Optimisation 2022-10-06 16:53:56: iinla: |lin1-lin0| = 12.61 #>        <eta-lin1,delta>/|delta| = -3.903e-05 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 0.01954 2022-10-06 16:53:56: iinla: Step rescaling: 102% 2022-10-06 16:53:56: iinla: Max deviation from previous: 579% of SD [stop if: <1%] 2022-10-06 16:53:56: iinla: Iteration 4 [max:10] 2022-10-06 16:53:57: iinla: Step rescaling: 162%, Expand 2022-10-06 16:53:57: iinla: Step rescaling: 100%, Overstep 2022-10-06 16:53:57: iinla: Step rescaling: 100%, Optimisation 2022-10-06 16:53:57: iinla: |lin1-lin0| = 0.01955 #>        <eta-lin1,delta>/|delta| = 2.636e-10 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 1.405e-07 2022-10-06 16:53:57: iinla: Max deviation from previous: 9.99% of SD [stop if: <1%] 2022-10-06 16:53:57: iinla: Iteration 5 [max:10] 2022-10-06 16:53:57: iinla: Step rescaling: 162%, Expand 2022-10-06 16:53:57: iinla: Step rescaling: 100%, Overstep 2022-10-06 16:53:57: iinla: |lin1-lin0| = 4.373e-07 #>        <eta-lin1,delta>/|delta| = -3.448e-13 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 1.228e-12 2022-10-06 16:53:57: iinla: Max deviation from previous: 0.234% of SD [stop if: <1%] 2022-10-06 16:53:57: iinla: Convergence criterion met, running final INLA integration with known theta mode. 2022-10-06 16:53:57: iinla: Iteration 6 [max:10] 2022-10-06 16:54:00: Test message bru_log_active() #> [1] Inf"},{"path":"/reference/bru_make_stack.html","id":null,"dir":"Reference","previous_headings":"","what":"Build an inla data stack from linearisation information — bru_make_stack","title":"Build an inla data stack from linearisation information — bru_make_stack","text":"Combine linearisation multiple likelihoods","code":""},{"path":"/reference/bru_make_stack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build an inla data stack from linearisation information — bru_make_stack","text":"","code":"bru_make_stack(...)  # S3 method for bru_like bru_make_stack(lhood, lin, idx, ...)  # S3 method for bru_like_list bru_make_stack(lhoods, lin, idx, ...)"},{"path":"/reference/bru_make_stack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build an inla data stack from linearisation information — bru_make_stack","text":"... Arguments passed methods lhood bru_like object lin Linearisation information .bru_like, linearisation information list elements offset .bru_like_list, list linearisation information lists idx Output evaluate_index(...) lhoods bru_like_list object","code":""},{"path":"/reference/bru_mapper.html","id":null,"dir":"Reference","previous_headings":"","what":"Constructors for bru_mapper objects — bru_mapper","title":"Constructors for bru_mapper objects — bru_mapper","text":"Constructors bru_mapper objects","code":""},{"path":"/reference/bru_mapper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constructors for bru_mapper objects — bru_mapper","text":"","code":"bru_mapper(...)  bru_mapper_define(mapper, new_class = NULL, methods = NULL, ...)  # S3 method for default bru_mapper(...)  # S3 method for inla.mesh bru_mapper(mesh, ...)  # S3 method for inla.mesh.1d bru_mapper(mesh, indexed = NULL, ...)  bru_mapper_index(n = 1L, ...)  bru_mapper_linear(...)  bru_mapper_matrix(labels, ...)  bru_mapper_factor(values, factor_mapping, ...)  bru_mapper_offset(...)  bru_mapper_multi(mappers, ...)  bru_mapper_collect(mappers, hidden = FALSE, ...)  bru_mapper_harmonics(   order = 1,   scaling = 1,   intercept = TRUE,   interval = c(0, 1),   ... )"},{"path":"/reference/bru_mapper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Constructors for bru_mapper objects — bru_mapper","text":"... Arguments passed methods mapper bru_mapper_define method, normally list converted bru_mapper object adding class information (optional) methods. new_class non-NULL, added front class definition methods Optional list named method definitions; See Details. mesh inla.mesh.1d inla.mesh.2d object use mapper indexed logical; TRUE, ibm_values() output integer indexing sequence latent variables (needed spde models). FALSE, knot locations returned (useful interpolator rw2 models similar). Default: NULL, force user specification parameter n Size model bru_mapper_index labels Column labels matrix mappings values Input values calculated input_eval.bru_input() factor_mapping character; selects type factor mapping. 'contrast' leaving first factor level. 'full' keeping levels. mappers list bru_mapper objects hidden logical, set TRUE flag mapper used first level input mapper INLA::f() model requires making first mapper visible INLA::f() INLA::inla.stack(), \"bym2\" models, activated inla_f argument ibm_n, ibm_values, ibm_amatrix. Set FALSE always access full mapper, e.g. rgeneric models order bru_mapper_harmonics, specifies maximum cos/sin order. (Default 1) scaling bru_mapper_harmonics, specifies optional vector scaling factors length intercept + order, common single scalar. intercept logical; bru_mapper_harmonics, TRUE, first basis function constant. (Default TRUE) interval numeric length-2 vector specifying domain interval. Default c(0, 1).","code":""},{"path":"/reference/bru_mapper.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Constructors for bru_mapper objects — bru_mapper","text":"bru_mapper Generic mapper S3 constructor, used constructing mappers special objects. See details default constructor bru_mapper_define() can used define new mappers user code. bru_mapper_define adds new_class \"bru_mapper\" class names inheritance list input mapper object, unless object already inherits . provided, mapper method functions added environment .envir object.  generic methods ibm_n, ibm_n_inla, ibm_values, ibm_values_inla, ibm_amatrix, ibm_amatrix_inla, ibm_valid_input, ibm_valid_input_inla look functions first, otherwise call UseMethod().  alternative using .S3method() register methods, e.g. .S3method(\"ibm_amatrix\", \"my_mapper_class\", ibm_amatrix.my_mapper_class). bru_mapper.default calls bru_mapper_define, passing arguments along. Mapper implementations call bru_mapper_define() instead, supply least new_class class name. Use bru_mapper.default deprecated version 2.6.0. bru_mapper_multi constructs kronecker product mapping bru_mapper_collect constructs concatenated collection mapping bru_mapper_harmonics constructs mapper cos/sin functions orders 1 (intercept TRUE, otherwise 0) order. total number basis functions intercept + 2 * order. Optionally, order can given non-unit scaling, via scaling vector, length intercept + order. can used give effective spectral prior. example, let   ,   stochastic properties u1 u2 , scaling^2 determining variance frequency contribution. period first order harmonics shifted scaled match interval.","code":"scaling = 1 / (1 + (0:4)^2) A1 = bru_mapper_harmonics(order = 4) u1 <- A1 %*% rnorm(9, sd = scaling) A2 = bru_mapper_harmonics(order = 4, scaling = scaling) u2 = A2 %*% rnorm(9)"},{"path":[]},{"path":"/reference/bru_mapper.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Constructors for bru_mapper objects — bru_mapper","text":"","code":"mapper <- bru_mapper_index(5) ibm_amatrix(mapper, c(1, 3, 4, 5, 2)) #> 5 x 5 sparse Matrix of class \"dgCMatrix\" #>                #> [1,] 1 . . . . #> [2,] . . 1 . . #> [3,] . . . 1 . #> [4,] . . . . 1 #> [5,] . 1 . . ."},{"path":"/reference/bru_mapper_methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for bru_mapper objects — bru_mapper_methods","title":"Methods for bru_mapper objects — bru_mapper_methods","text":"bru_mapper sub-class implementation must provide ibm_matrix() method. model size 'n' definition values 'values' stored object , default methods available (see Details). Otherwise ibm_n() ibm_values() methods also need provided.","code":""},{"path":"/reference/bru_mapper_methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for bru_mapper objects — bru_mapper_methods","text":"","code":"ibm_n(mapper, inla_f = FALSE, ...)  ibm_values(mapper, inla_f = FALSE, ...)  ibm_amatrix(mapper, input, inla_f = FALSE, ...)  ibm_inla_subset(mapper, ...)  ibm_valid_input(mapper, input, inla_f = FALSE, ...)  # S3 method for default ibm_n(mapper, inla_f = FALSE, ...)  # S3 method for default ibm_values(mapper, inla_f = FALSE, ...)  # S3 method for default ibm_amatrix(mapper, input, inla_f = FALSE, ...)  # S3 method for default ibm_inla_subset(mapper, ...)  # S3 method for default ibm_valid_input(mapper, input, ...)  # S3 method for bru_mapper_inla_mesh_2d ibm_n(mapper, ...)  # S3 method for bru_mapper_inla_mesh_2d ibm_values(mapper, ...)  # S3 method for bru_mapper_inla_mesh_2d ibm_amatrix(mapper, input, ...)  # S3 method for bru_mapper_inla_mesh_1d ibm_n(mapper, ...)  # S3 method for bru_mapper_inla_mesh_1d ibm_values(mapper, ...)  # S3 method for bru_mapper_inla_mesh_1d ibm_amatrix(mapper, input, ...)  # S3 method for bru_mapper_index ibm_valid_input(mapper, input, ...)  # S3 method for bru_mapper_index ibm_amatrix(mapper, input, ...)  # S3 method for bru_mapper_linear ibm_n(mapper, ...)  # S3 method for bru_mapper_linear ibm_values(mapper, ...)  # S3 method for bru_mapper_linear ibm_amatrix(mapper, input, ...)  # S3 method for bru_mapper_matrix ibm_n(mapper, ...)  # S3 method for bru_mapper_matrix ibm_values(mapper, ...)  # S3 method for bru_mapper_matrix ibm_amatrix(mapper, input, ...)  # S3 method for bru_mapper_factor ibm_n(mapper, ...)  # S3 method for bru_mapper_factor ibm_values(mapper, ...)  # S3 method for bru_mapper_factor ibm_amatrix(mapper, input, ...)  # S3 method for bru_mapper_offset ibm_n(mapper, ...)  # S3 method for bru_mapper_offset ibm_values(mapper, ...)  # S3 method for bru_mapper_offset ibm_amatrix(mapper, input, ...)  # S3 method for bru_mapper_multi ibm_n(mapper, inla_f = FALSE, multi = 0L, ...)  # S3 method for bru_mapper_multi ibm_values(mapper, inla_f = FALSE, multi = 0L, ...)  # S3 method for bru_mapper_multi ibm_amatrix(mapper, input, inla_f = FALSE, multi = 0L, ...)  # S3 method for bru_mapper_multi ibm_valid_input(mapper, input, inla_f = FALSE, multi = 0L, ...)  # S3 method for bru_mapper_multi [(x, i, drop = TRUE)  # S3 method for bru_mapper_multi names(x)  # S3 method for bru_mapper_multi names(x) <- value  # S3 method for bru_mapper_collect ibm_n(mapper, inla_f = FALSE, multi = 0L, ...)  # S3 method for bru_mapper_collect ibm_values(mapper, inla_f = FALSE, multi = 0L, ...)  # S3 method for bru_mapper_collect ibm_amatrix(mapper, input, inla_f = FALSE, multi = 0L, ...)  # S3 method for bru_mapper_collect ibm_valid_input(mapper, input, inla_f = FALSE, multi = 0L, ...)  # S3 method for bru_mapper_collect [(x, i, drop = TRUE)  # S3 method for bru_mapper_collect names(x)  # S3 method for bru_mapper_collect names(x) <- value  # S3 method for bru_mapper_harmonics ibm_n(mapper, inla_f = FALSE, ...)  # S3 method for bru_mapper_harmonics ibm_amatrix(mapper, input, inla_f = FALSE, ...)"},{"path":"/reference/bru_mapper_methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for bru_mapper objects — bru_mapper_methods","text":"mapper mapper S3 object, normally inheriting bru_mapper inla_f logical; TRUE ibm_n ibm_values, must result values compatible INLA::f(...) specification corresponding INLA::inla.stack(...) constructions. ibm_amatrix methods, may influence input data interpreted. Implementations normally need anything different, except mappers type needed hidden multicomponent models \"bym2\", can handled bru_mapper_collect. ... Arguments passed methods input values produce mapping matrix multi integer logical; positive, number levels recurse bru_collect_mapper. TRUE, equivalent 1L. FALSE, equivalent 0L. x object extract element(s) indices specifying element(s) extract drop logical; [.bru_mapper_collect, whether extract individual mapper identifies single element. FALSE, list sub-mappers returned (suitable e.g. creating new bru_mapper_collect object). Default: TRUE value character vector length x","code":""},{"path":"/reference/bru_mapper_methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Methods for bru_mapper objects — bru_mapper_methods","text":"[-indexing bru_mapper_multi extracts subset bru_mapper_multi object (drop FALSE) individual sub-mapper (drop TRUE, identifies single element) names() method bru_mapper_multi returns names sub-mappers list [-indexing bru_mapper_collect extracts subset bru_mapper_collect object (drop FALSE) individual sub-mapper (drop TRUE, identifies single element) names() method bru_mapper_collect returns names sub-mappers list","code":""},{"path":"/reference/bru_mapper_methods.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Methods for bru_mapper objects — bru_mapper_methods","text":"ibm_n Generic. Implementations must return size latent vector mapped . ibm_values Generic. Implementations must return vector interpretable INLA::f(..., values = ...) specification. exception method bru_mapper_multi, returns multi-column data frame ibm_amatrix Generic. Implementations must return (sparse) matrix size NROW(input) (except bru_mapper_multi bru_mapper_collect methods, require list() inputs, input size determined combined inputs) ibm_n(mapper, inla_f = FALSE). inla_f=TRUE argument affect allowed type input format. ibm_inla_subset Generic. Implementations must return logical vector TRUE/FALSE subset , given full matrix values output, [, subset, drop = FALSE] values[subset] (values[subset, , drop = FALSE] data.frame values) equal inla_f = TRUE version values. default method uses ibm_values output construct subset indexing. ibm_valid_input Generic. Implementations must return logical vector length NROW(input) ( bru_mapper_multi bru_mapper_collect list vectors) default ibm_n() method returns non-null element 'n' mapper object, gives error exist. inla_f=TRUE, first checks 'n_inla' element. default ibm_values() method returns non-null element 'values' mapper object, seq_len(ibm_n(mapper)) exist. default ibm_amatrix() gives error message. Mapper classes must implement ibm_amatrix method. default ibm_inla_subset method uses ibm_values output construct inla subset indexing, passing extra arguments multi methods (means supports regular vector values multi=1 data.frame values). default ibm_valid_input() method returns -TRUE logical vector. ibm_amatrix bru_mapper_multi accepts list named entries, list unnamed ordered elements. names must match sub-mappers, see names.bru_mapper_multi(). list element take format accepted corresponding sub-mapper. case element vector, input can given data.frame named columns, matrix named columns, matrix unnamed ordered columns. ibm_valid_input bru_mapper_multi accepts list named entries, list unnamed ordered elements. names must match sub-mappers, see names.bru_mapper_multi(). list element take format accepted corresponding sub-mapper. case element vector, input can given data.frame named columns, matrix named columns, matrix unnamed ordered columns. ibm_amatrix bru_mapper_collect accepts list named entries, list unnamed ordered elements. names must match sub-mappers, see names.bru_mapper_collect(). list element take format accepted corresponding sub-mapper. case element vector, input can given data.frame named columns, matrix named columns, matrix unnamed ordered columns. inla_f=TRUE hidden=TRUE mapper definition, input format instead match first, non-hidden, sub-mapper. ibm_valid_input bru_mapper_collect accepts list named entries, list unnamed ordered elements. names must match sub-mappers, see names.bru_mapper_collect(). list element take format accepted corresponding sub-mapper. case element vector, input can given data.frame named columns, matrix named columns, matrix unnamed ordered columns.","code":""},{"path":[]},{"path":"/reference/bru_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an inlabru model object from model components — bru_model","title":"Create an inlabru model object from model components — bru_model","text":"inlabru syntax model formulae different INLA::inla considers valid. inla effects defined adding f(...) expression formula. inlabru f replaced arbitrary (exception: offset) string determine label effect. See Details information.","code":""},{"path":"/reference/bru_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an inlabru model object from model components — bru_model","text":"","code":"bru_model(components, lhoods)"},{"path":"/reference/bru_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an inlabru model object from model components — bru_model","text":"components component_list object lhoods list one lhood objects","code":""},{"path":"/reference/bru_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an inlabru model object from model components — bru_model","text":"bru_model object","code":""},{"path":"/reference/bru_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create an inlabru model object from model components — bru_model","text":"instance y ~ f(myspde, ...) INLA equivalent y ~ myspde(...) inlabru. disadvantage inla way clear separation name covariate label effect. Furthermore, models like SPDE much natural use spatial coordinates covariates rather index SPDE vertices. purpose inlabru provides new main agument. convenience, main argument can used like first argument f function, e.g., first argument component definition. y ~ f(temperature, model = 'linear') equivalent y ~ temperature(temperature, model = 'linear') y ~ temperature(main = temperature, model = 'linear') well y ~ temperature(model = 'linear') sets main = temperature. hand, map can also function mapping, e.g coordinates function sp package : y ~ mySPDE(coordinates, ...) exctract coordinates data object, maps latent field via information given mapper, default extracted model object, case spde model objects. Morevover, main can expression evaluates within data environment. instance, data columns '' 'b', can create fixed effect 'sin(+b)' setting map following way: y ~ myEffect(sin(+b))","code":""},{"path":"/reference/bru_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Create or update an options objects — bru_options","title":"Create or update an options objects — bru_options","text":"Create new options object, merge information several objects. _get, _set, _reset functions operate global package options override object. many cases, setting options specific calls bru() recommended instead.","code":""},{"path":"/reference/bru_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create or update an options objects — bru_options","text":"","code":"bru_options(...)  as.bru_options(x = NULL)  bru_options_default()  bru_options_check(options, ignore_null = TRUE)  bru_options_get(name = NULL, include_default = TRUE)  bru_options_set(..., .reset = FALSE)  bru_options_reset()"},{"path":"/reference/bru_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create or update an options objects — bru_options","text":"... collection named options, optionally including one bru_options objects. Options specified later override previous options. x object converted bru_options object. options bru_options object checked ignore_null Ignore missing NULL options. name Either NULL, single option name string, character vector list option names, Default: NULL include_default logical; TRUE, default options included together global override options. Default: TRUE .reset bru_options_set, logical indicating global override options list emptied setting new option(s).","code":""},{"path":"/reference/bru_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create or update an options objects — bru_options","text":"bru_options() returns bru_options object. .bru_options(), NULL input returns empty bru_options object, list converted via bru_options(...), bru_options input passed . types input generates error. bru_options_default() returns bru_options object containing default options. bru_options_check() returns logical; TRUE object contains valid options use functions bru_options_get returns either bru_options object, name == NULL, contents single option, name options name string, named list option contents, name list option name strings. bru_options_set() returns copy global override options, invisibly (bru_options_get(include_default = FALSE)).","code":""},{"path":"/reference/bru_options.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create or update an options objects — bru_options","text":"bru_options_check checks valid contents bru_options object bru_options_check() produces warnings invalid options. bru_options_set() used set global package options. bru_options_reset() clears global option overrides.","code":""},{"path":"/reference/bru_options.html","id":"valid-options","dir":"Reference","previous_headings":"","what":"Valid options","title":"Create or update an options objects — bru_options","text":"bru_options bru_options_set, recognised options : bru_verbose logical numeric; TRUE, log messages verbosity \\(\\le 1\\) printed bru_log_message(). numeric, log messages verbosity \\(\\le\\)bru_verbose printed. line search details, set bru_verbose=2 3. Default: 0, print messages bru_verbose_store logical numeric; TRUE, log messages verbosity \\(\\le 1\\) stored bru_log_message(). numeric, log messages verbosity \\(\\le\\) stored. Default: Inf, store messages. bru_run TRUE, run inference. Otherwise return configuration needed run inference. bru_max_iter maximum number inla iterations, default 10. Also see bru_method$rel_tol related options . bru_initial inla object returned previous calls INLA::inla, bru() lgcp(), list named vectors starting values latent variables. used starting point improvement approximate posterior. bru_int_args List arguments passed way integration method ipoints int.polygon 'cp' family models; method \"stable\" \"direct\". \"stable\" (default) integration points aggregated mesh vertices. nsub1 Number integration points per knot interval 1D. Default 30. nsub2 Number integration points along triangle edge 2D. Default 9. nsub Deprecated parameter overrides nsub1 nsub2 set. Default NULL. bru_method List arguments controlling iterative inlabru method: taylor 'pandemic' (default, version 2.1.15). search Either '' (default), use available line search methods, one 'finite' (reduce step size predictor finite) 'contract' (decrease step size trust hypersphere reached) 'expand' (increase step size improvement) 'optimise' (fast approximate error norm minimisation) disable line search, set empty vector. Line search available taylor=\"legacy\". factor Numeric, \\(> 1\\) determining line search step scaling multiplier. Default \\((1 + \\sqrt{5})/2\\). rel_tol Stop iterations largest change linearisation point (conditional latent state mode) relation estimated posterior standard deviation less rel_tol. Default 0.01 (one percent). max_step largest allowed line search step factor. Factor 1 full INLA step. Default 2. lin_opt_method method use line search optimisation step. Default \"onestep\", using quadratic approximation based value gradient zero, value current best step length guess. method \"full\" line optimisation full nonlinear predictor; slow intended debugging purposes . bru_compress_cp logical; TRUE, compress \\(\\sum_{=1}^n \\eta_i\\) part Poisson process likelihood (family=\"cp\") single term, \\(y=n\\), predictor mean(eta). Default: TRUE inla() options options starting bru_ passed inla(), sometimes altering according needs inlabru method. Warning: Due inlabru currently constructs inla() call, mean, prec, mean.intercept, prec.intercept settings control.fixed effect. elegant alternative implemented, use explicit mean.linear prec.linear specifications model=\"linear\" component instead.","code":""},{"path":[]},{"path":"/reference/bru_options.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create or update an options objects — bru_options","text":"","code":"if (FALSE) { if (interactive()) {   # Combine global and user options:   options1 <- bru_options(bru_options_get(), bru_verbose = TRUE)   # Create a proto-options object in two equivalent ways:   options2 <- as.bru_options(bru_verbose = TRUE)   options2 <- as.bru_options(list(bru_verbose = TRUE))   # Combine options objects:   options3 <- bru_options(options1, options2) } } if (FALSE) { if (interactive()) {   # EXAMPLE1 } } if (FALSE) { if (interactive()) {   bru_options_check(bru_options(bru_max_iter = \"text\")) } } if (FALSE) { if (interactive()) {   # EXAMPLE1 } } if (FALSE) { if (interactive()) {   bru_options_set(     bru_verbose = TRUE,     verbose = TRUE   ) } }"},{"path":"/reference/bru_safe_inla.html","id":null,"dir":"Reference","previous_headings":"","what":"Load INLA safely for examples and tests — bru_safe_inla","title":"Load INLA safely for examples and tests — bru_safe_inla","text":"Loads INLA package requireNamespace(\"INLA\", quietly = TRUE), optionally checks sets multicore num.threads INLA option.","code":""},{"path":"/reference/bru_safe_inla.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load INLA safely for examples and tests — bru_safe_inla","text":"","code":"bru_safe_inla(multicore = NULL, quietly = FALSE)"},{"path":"/reference/bru_safe_inla.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load INLA safely for examples and tests — bru_safe_inla","text":"multicore logical; TRUE, multiple cores allowed, INLA num.threads option checked altered. FALSE, forces num.threads=\"1:1\". Default: NULL, checks running testthat non-interactively, case sets multicore=FALSE, otherwise TRUE. quietly logical; TRUE, prints diagnostic messages. Default: FALSE.","code":""},{"path":"/reference/bru_safe_inla.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load INLA safely for examples and tests — bru_safe_inla","text":"logical; TRUE INLA loaded safely, otherwise FALSE","code":""},{"path":"/reference/bru_safe_inla.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load INLA safely for examples and tests — bru_safe_inla","text":"","code":"if (FALSE) { if (bru_safe_inla()) {   # Run inla dependent calculations } }"},{"path":"/reference/bru_standardise_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardise inla hyperparameter names — bru_standardise_names","title":"Standardise inla hyperparameter names — bru_standardise_names","text":"inla hyperparameter output uses parameter names can include whitespace special characters. function replaces characters underscores.","code":""},{"path":"/reference/bru_standardise_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardise inla hyperparameter names — bru_standardise_names","text":"","code":"bru_standardise_names(x)"},{"path":"/reference/bru_standardise_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardise inla hyperparameter names — bru_standardise_names","text":"x character vector; names standardised","code":""},{"path":"/reference/bru_standardise_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardise inla hyperparameter names — bru_standardise_names","text":"character vector standardised names","code":""},{"path":"/reference/bru_standardise_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standardise inla hyperparameter names — bru_standardise_names","text":"","code":"bru_standardise_names(\"Precision for the Gaussian observations\") #>   Precision for the Gaussian observations  #> \"Precision_for_the_Gaussian_observations\""},{"path":"/reference/bru_summarise.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise and annotate data — bru_summarise","title":"Summarise and annotate data — bru_summarise","text":"Summarise annotate data","code":""},{"path":"/reference/bru_summarise.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise and annotate data — bru_summarise","text":"","code":"bru_summarise(   data,   probs = c(0.025, 0.5, 0.975),   x = NULL,   cbind.only = FALSE,   max_moment = 2 )"},{"path":"/reference/bru_summarise.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise and annotate data — bru_summarise","text":"data list samples, either numeric data.frame probs numeric vector probabilities values [0, 1], passed stats::quantile x data.frame data columns added summary data frame cbind.TRUE, cbind samples return matrix column sample max_moment integer, least 2. Determines largest moment order information include output. max_moment > 2, includes \"skew\" (skewness, E[(x-m)^3/s^3]), max_moment > 3, includes \"ekurtosis\" (excess kurtosis, E[(x-m)^4/s^4] - 3). Default 2. Note Monte Carlo variability ekurtois estimate may large.","code":""},{"path":"/reference/bru_summarise.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise and annotate data — bru_summarise","text":"data.frame Spatial[Points/Pixels]DataFrame summary statistics, \"mean\", \"sd\", paste0(\"q\", probs), \"mean.mc_std_err\", \"sd.mc_std_err\"","code":""},{"path":"/reference/bru_summarise.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise and annotate data — bru_summarise","text":"","code":"bru_summarise(matrix(rexp(10000), 10, 1000), max_moment = 4, probs = NULL) #>         mean        sd     skew ekurtosis mean.mc_std_err sd.mc_std_err #> 1  1.0034342 0.9883679 1.859829  4.879600      0.03125494    0.04099524 #> 2  0.9577976 0.9634926 1.943370  5.343811      0.03046831    0.04128938 #> 3  1.0064042 0.9664212 1.845843  4.875795      0.03056092    0.04007385 #> 4  1.0041786 1.0231566 2.157017  7.225228      0.03235505    0.04914143 #> 5  1.0162232 1.0227373 1.936717  5.504279      0.03234179    0.04430437 #> 6  0.9878385 0.9960664 1.996719  5.912035      0.03149838    0.04430547 #> 7  1.0102833 1.0615298 2.063133  5.367017      0.03356852    0.04556245 #> 8  1.0395293 1.0260143 2.069870  6.548987      0.03244542    0.04743857 #> 9  0.9597980 0.9544205 1.728750  3.648781      0.03018143    0.03587270 #> 10 1.0309441 1.0406462 1.871337  4.513705      0.03290812    0.04200045"},{"path":"/reference/bru_transformation.html","id":null,"dir":"Reference","previous_headings":"","what":"Transformation tools — bru_forward_transformation","title":"Transformation tools — bru_forward_transformation","text":"Tools transforming N(0,1) variables distributions predictor expressions","code":""},{"path":"/reference/bru_transformation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transformation tools — bru_forward_transformation","text":"","code":"bru_forward_transformation(qfun, x, ..., tail.split. = 0)  bru_inverse_transformation(pfun, x, ..., tail.split. = NULL)"},{"path":"/reference/bru_transformation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transformation tools — bru_forward_transformation","text":"qfun quantile function object, qexp x Values transformed ... Distribution parameters passed qfun pfun functions tail.split. x-values larger tail.split., upper quantile calculations used internally, smaller values lower quantile calculations used. can avoid lack accuracy distribution tails. NULL, forward calculations split 0, inverse calculations use lower tails , potentially losing accuracy upper tails. pfun CDF function object, pexp","code":""},{"path":"/reference/bru_transformation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transformation tools — bru_forward_transformation","text":"bru_forward_transformation, numeric vector bru_inverse_transformation, numeric vector","code":""},{"path":"/reference/bru_transformation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transformation tools — bru_forward_transformation","text":"","code":"u <- rnorm(5, 0, 1) y <- bru_forward_transformation(qexp, u, rate = 2) v <- bru_inverse_transformation(pexp, y, rate = 2) rbind(u, y, v) #>        [,1]     [,2]      [,3]      [,4]       [,5] #> u 0.7042593 1.165166 0.3357515 0.2096356 -0.4610722 #> y 0.7122356 1.051966 0.4991178 0.4373632  0.1945795 #> v 0.7042593 1.165166 0.3357515 0.2096356 -0.4610722"},{"path":"/reference/code.components.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert components to R code — code.components","title":"Convert components to R code — code.components","text":"Convert components R code","code":""},{"path":"/reference/code.components.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert components to R code — code.components","text":"","code":"code.components(components, add = \"\")"},{"path":"/reference/code.components.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert components to R code — code.components","text":"components formula describing latent model components.","code":""},{"path":"/reference/code.components.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert components to R code — code.components","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"/reference/component.html","id":null,"dir":"Reference","previous_headings":"","what":"Latent model component construction — component","title":"Latent model component construction — component","text":"Similar glm(), gam() inla(), bru() models can constructed via formula-like syntax, latent effect specified. However, addition parts syntax compatible INLA::inla, bru components offer additional functionality facilitates modelling, predictor expression can specified separately, allowing complex non-linear predictors defined. formula syntax just way allow model components defined single line code, definitions can optionally split separate component definitions. See Details information. component methods rely component.character() method, defines model component given label/name. user usually need call methods directly, can instead supply formula expression can interpreted component_list.formula() method, called inside bru().","code":""},{"path":"/reference/component.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Latent model component construction — component","text":"","code":"component(...)  # S3 method for character component(   object,   main = NULL,   weights = NULL,   ...,   model = NULL,   mapper = NULL,   main_layer = NULL,   main_selector = NULL,   n = NULL,   values = NULL,   season.length = NULL,   copy = NULL,   weights_layer = NULL,   weights_selector = NULL,   group = NULL,   group_mapper = NULL,   group_layer = NULL,   group_selector = NULL,   ngroup = NULL,   control.group = NULL,   replicate = NULL,   replicate_mapper = NULL,   replicate_layer = NULL,   replicate_selector = NULL,   nrep = NULL,   A.msk = NULL,   .envir = parent.frame(),   envir_extra = NULL )"},{"path":"/reference/component.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Latent model component construction — component","text":"... Parameters passed methods object character label component main main takes R expression evaluates latent variables evaluated (coordinates, indices, continuous scalar (rw2 etc)). Arguments starting weights, group, replicate behave similarly main, corresponding features INLA::f(). weights, weights_layer, weights_selector Optional specification effect scaling weights. syntax main. model Either one \"offset\", \"factor_full\", \"factor_contrast\", \"linear\", \"fixed\", model name object accepted INLA's f function. set NULL, \"linear\" used vector inputs, \"fixed\" matrix input (converted internally iid model fixed precision) mapper Information mapping values evaluated main, latent variables. Auto-detects spde model objects model extracts mesh object use mapper, auto-generates mappers indexed models. (Default: NULL, auto-determination) main_layer, main_selector _layer numeric index character name layer/variable extract covariate data object given main (Default: effect component name, exists covariate object, otherwise first column covariate data frame) _selector character name variable whose contents determines layer extract covariate data point. Overrides layer. (Default: NULL) n number latent variables model. auto-detected models (Default: NULL, auto-detection). error given figure . values Specifies covariate/index values INLA build latent model. Normally generated internally based mapping details. (Default: NULL, auto-determination) season.length Passed INLA::f() model \"seasonal\" (TODO: check parameter still fully handled) copy character; label component component copy . fixed = FALSE, scaling constant estimated, via hyperparameter. fixed = TRUE, component scaling fixed, default 1; fixed scaling, efficient express scaling predictor expression instead making copy component. group, group_mapper, group_layer, group_selector, ngroup Optional specification kronecker/group model indexing. control.group list kronecker/group model parameters, currently passed directly INLA::f replicate, replicate_mapper, replicate_layer, replicate_selector, nrep Optional specification indices independent replication model. syntax main .msk TODO: check/fix/deprecate parameter. Likely work moment, found examples use . .envir Evaluation environment envir_extra TODO: check/fix parameter.","code":""},{"path":"/reference/component.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Latent model component construction — component","text":"shorthand, bru() understand basic additive formulae describing fixed effect models. instance, components specification y ~ x define linear combination effect named x intercept response y respect likelihood family stated calling bru(). Mathematically, linear predictor \\(\\eta\\) written $$\\eta = \\beta * x + c,$$ : \\(c\\) intercept \\(x \\)covariate \\(\\beta\\) random variable associated \\(x\\) \\(\\psi = \\beta * x \\) called random effect \\(x\\) problem arises using kind R formula clearly reflect mathematical formula. instance, providing formula inla, resulting object refer random effect \\(\\psi = \\beta * x \\) x. Hence, clear x refers covariate effect covariate. component.character method inlabru's equivalent INLA's f function adds functionality unique inlabru. Deprecated parameters: map: Use main instead. mesh: Use mapper instead.","code":""},{"path":"/reference/component.html","id":"naming-random-effects","dir":"Reference","previous_headings":"","what":"Naming random effects","title":"Latent model component construction — component","text":"INLA, f() notation used define complex models, simple linear effect model can also expressed formula = y ~ f(x, model = \"linear\"), f() inla specific function set random effects kinds. underlying predictor \\(\\eta = \\beta * x + c\\) result fitting model state x random effect's name. bru allows rewriting formula order explicitly state name random effect name associated covariate. achieved replacing f arbitrary name wish assign effect, e.g. components = y ~ psi(x, model = \"linear\"). able discriminate \\(x\\) \\(\\psi\\) relevant two functionalities bru offers. formula parameters bru() prediction method predict.bru interpreted mathematical sense. instance, predict may used analyze analytical combination covariate \\(x\\) intercept using predict(fit, data.frame(x=2)), ~ exp(psi + Intercept). corresponds mathematical expression e β + c. hand, predict may used look transformation latent variable \\(\\beta_\\psi\\) predict(fit, NULL, ~ exp(psi_latent)). corresponds mathematical expression e β.","code":""},{"path":[]},{"path":"/reference/component.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Latent model component construction — component","text":"Fabian E. Bachl bachlfab@gmail.com Finn Lindgren Finn.Lindgren@gmail.com","code":""},{"path":"/reference/component.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Latent model component construction — component","text":"","code":"# As an example, let us create a linear component. Here, the component is # called \"myLinearEffectOfX\" while the covariate the component acts on is # called \"x\". Note that a list of components is returned because the # formula may define multiple components  cmp <- component_list(~ myLinearEffectOfX(main = x, model = \"linear\")) summary(cmp) #> Label:\tmyLinearEffectOfX #>   Main:\tinput 'x',\ttype 'linear' #>   INLA formula:\t~. + f(myLinearEffectOfX, model = BRU_myLinearEffectOfX_main_model) #> Label:\tIntercept #>   Main:\tinput '1',\ttype 'linear' #>   INLA formula:\t~. + f(Intercept, model = BRU_Intercept_main_model) # Equivalent shortcuts: cmp <- component_list(~ myLinearEffectOfX(x, model = \"linear\")) cmp <- component_list(~ myLinearEffectOfX(x)) # Individual component cmp <- component(\"myLinearEffectOfX\", main = x, model = \"linear\") summary(cmp) #> Label:\tmyLinearEffectOfX #>   Main:\tinput 'x',\ttype 'linear' #>   INLA formula:\t~. + f(myLinearEffectOfX, model = BRU_myLinearEffectOfX_main_model) # \\donttest{ if (bru_safe_inla(quietly = TRUE)) {    # As an example, let us create a linear component. Here, the component is   # called \"myEffectOfX\" while the covariate the component acts on is called \"x\":    cmp <- component(\"myEffectOfX\", main = x, model = \"linear\")   summary(cmp)    # A more complicated component:   cmp <- component(\"myEffectOfX\",     main = x,     model = INLA::inla.spde2.matern(INLA::inla.mesh.1d(1:10))   )    # Compound fixed effect component, where x and z are in the input data.   # The formula will be passed on to MatrixModels::model.Matrix:   cmp <- component(\"eff\", ~ -1 + x:z, model = \"fixed\")   summary(cmp) } #> Label:\teff #>   Main:\tinput '~-1 + x:z',\ttype 'fixed' #>   INLA formula:\t~. + f(eff, model = BRU_eff_main_model, hyper = BRU_eff_main_fixed_hyper) # }"},{"path":"/reference/component_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate component values in predictor expressions — component_eval","title":"Evaluate component values in predictor expressions — component_eval","text":"predictor expressions, name_eval(...) can used evaluate effect component called \"name\".","code":""},{"path":"/reference/component_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate component values in predictor expressions — component_eval","text":"","code":"component_eval(main, group = NULL, replicate = NULL, .state = NULL)"},{"path":"/reference/component_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate component values in predictor expressions — component_eval","text":"main, group, replicate Specification evaluate component. three inputs passed respective bru_mapper methods. .state internal component state. Normally supplied automatically internal methods evaluating inlabru predictor expressions.","code":""},{"path":"/reference/component_eval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate component values in predictor expressions — component_eval","text":"vector values component","code":""},{"path":"/reference/component_eval.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate component values in predictor expressions — component_eval","text":"","code":"if (FALSE) { if (bru_safe_inla()) {   mesh <- INLA::inla.mesh.2d(     cbind(0, 0),     offset = 2, max.edge = 0.25   )   spde <- INLA::inla.spde2.pcmatern(mesh,     prior.range = c(0.1, 0.01),     prior.sigma = c(2, 0.01)   )   data <- sp::SpatialPointsDataFrame(     matrix(runif(10), 5, 2),     data = data.frame(z = rnorm(5))   )   fit <- bru(z ~ -1 + field(coordinates, model = spde),     family = \"gaussian\", data = data   )   pred <- predict(     fit,     data = data.frame(x = 0.5, y = 0.5),     formula = ~ field_eval(cbind(x, y))   ) } }"},{"path":"/reference/component_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for inlabru component lists — component_list","title":"Methods for inlabru component lists — component_list","text":"Constructor methods inlabru component lists. Syntax details given component().","code":""},{"path":"/reference/component_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for inlabru component lists — component_list","text":"","code":"component_list(object, lhoods = NULL, .envir = parent.frame(), ...)  # S3 method for formula component_list(object, lhoods = NULL, .envir = parent.frame(), ...)  # S3 method for list component_list(object, lhoods = NULL, .envir = parent.frame(), ...)  # S3 method for component_list c(...)  # S3 method for component_list [(x, i)"},{"path":"/reference/component_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for inlabru component lists — component_list","text":"object object operate lhoods bru_like_list object .envir evaluation environment non-formula input ... Parameters passed methods. Also see Details. x component_list object extract element(s) indices specifying elements extract","code":""},{"path":"/reference/component_list.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Methods for inlabru component lists — component_list","text":"component_list.formula: Convert component formula component_list object component_list.list: Combine list components /component formulas component_list object c.component_list: ... arguments component_list objects. environment first argument applied resulting list.","code":""},{"path":[]},{"path":"/reference/component_list.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Methods for inlabru component lists — component_list","text":"Fabian E. Bachl bachlfab@gmail.com Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"/reference/component_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Methods for inlabru component lists — component_list","text":"","code":"# As an example, let us create a linear component. Here, the component is # called \"myLinearEffectOfX\" while the covariate the component acts on is # called \"x\". Note that a list of components is returned because the # formula may define multiple components  eff <- component_list(~ myLinearEffectOfX(main = x, model = \"linear\")) summary(eff[[1]]) #> Label:\tmyLinearEffectOfX #>   Main:\tinput 'x',\ttype 'linear' #>   INLA formula:\t~. + f(myLinearEffectOfX, model = BRU_myLinearEffectOfX_main_model) # Equivalent shortcuts: eff <- component_list(~ myLinearEffectOfX(x, model = \"linear\")) eff <- component_list(~ myLinearEffectOfX(x)) # Individual component eff <- component(\"myLinearEffectOfX\", main = x, model = \"linear\")"},{"path":"/reference/cprod.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross product of integration points — cprod","title":"Cross product of integration points — cprod","text":"Calculates cross product integration points different dimensions multiplies weights accordingly. object defining points particular dimension weights attached weights assumend 1.","code":""},{"path":"/reference/cprod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross product of integration points — cprod","text":"","code":"cprod(...)"},{"path":"/reference/cprod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross product of integration points — cprod","text":"... data.frame SpatialPointsDataFrame objects, one usually obtained call ipoints function.","code":""},{"path":"/reference/cprod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross product of integration points — cprod","text":"data.frame SpatialPointsDataFrame multidimensional integration points weights","code":""},{"path":"/reference/cprod.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross product of integration points — cprod","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"/reference/cprod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross product of integration points — cprod","text":"","code":"# \\donttest{ # ipoints needs INLA if (bru_safe_inla()) {   # Create integration points in dimension 'myDim' and 'myDiscreteDim'   ips1 <- ipoints(rbind(c(0, 3), c(3, 8)), 17, name = \"myDim\")   ips2 <- ipoints(domain = c(1, 2, 4), name = \"myDiscreteDim\")    # Calculate the cross product   ips <- cprod(ips1, ips2)    # Plot the integration points   plot(ips$myDim, ips$myDiscreteDim, cex = 10 * ips$weight) }  # }"},{"path":"/reference/deltaIC.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise DIC and WAIC from lgcp objects. — deltaIC","title":"Summarise DIC and WAIC from lgcp objects. — deltaIC","text":"Calculates DIC /WAIC differences produces ordered summary.","code":""},{"path":"/reference/deltaIC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise DIC and WAIC from lgcp objects. — deltaIC","text":"","code":"deltaIC(..., criterion = \"DIC\")"},{"path":"/reference/deltaIC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise DIC and WAIC from lgcp objects. — deltaIC","text":"... Comma-separated objects inheriting class inla obtained run INLA::inla(), bru() lgcp() criterion character vector. includes 'DIC', computes DIC differences; contains 'WAIC', computes WAIC differences. Default: 'DIC'","code":""},{"path":"/reference/deltaIC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise DIC and WAIC from lgcp objects. — deltaIC","text":"data frame row containing Model name, DIC Delta.DIC, /WAIC Delta.WAIC.","code":""},{"path":"/reference/deltaIC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise DIC and WAIC from lgcp objects. — deltaIC","text":"","code":"# \\donttest{ if (bru_safe_inla(multicore = FALSE)) {   # Generate some data   input.df <- data.frame(idx = 1:10, x = cos(1:10))   input.df <- within(     input.df,     y <- rpois(10, 5 + 2 * cos(1:10) + rnorm(10, mean = 0, sd = 0.1))   )    # Fit two models   fit1 <- bru(y ~ x, family = \"poisson\", data = input.df)   fit2 <- bru(y ~ x + rand(idx, model = \"iid\"), family = \"poisson\", data = input.df)    # Compare DIC    deltaIC(fit1, fit2) } #> Current num.threads is '1:1'. #> No num.threads change needed. #>   Model      DIC  Delta.DIC #> 1  fit2 44.84202 0.00000000 #> 2  fit1 44.85240 0.01037792 # }"},{"path":"/reference/devel.cvmeasure.html","id":null,"dir":"Reference","previous_headings":"","what":"Variance and correlations measures for prediction components — devel.cvmeasure","title":"Variance and correlations measures for prediction components — devel.cvmeasure","text":"Calculates local integrated variance correlation measures introduced Yuan et al. (2017).","code":""},{"path":"/reference/devel.cvmeasure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variance and correlations measures for prediction components — devel.cvmeasure","text":"","code":"devel.cvmeasure(joint, prediction1, prediction2, samplers = NULL, mesh = NULL)"},{"path":"/reference/devel.cvmeasure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variance and correlations measures for prediction components — devel.cvmeasure","text":"joint joint prediction two latent model components. prediction1 prediction first component. prediction2 prediction second component. samplers SpatialPolygon object describing area compute cumulative variance measure. mesh inla.mesh prediction performed (required cumulative Vmeasure).","code":""},{"path":"/reference/devel.cvmeasure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variance and correlations measures for prediction components — devel.cvmeasure","text":"Variance correlations measures.","code":""},{"path":"/reference/devel.cvmeasure.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Variance and correlations measures for prediction components — devel.cvmeasure","text":"Y. Yuan, F. E. Bachl, F. Lindgren, D. L. Brochers, J. B. Illian, S. T. Buckland, H. Rue, T. Gerrodette. 2017. Point process models spatio-temporal distance sampling data large-scale survey blue whales. https://arxiv.org/abs/1604.06013","code":""},{"path":"/reference/devel.cvmeasure.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Variance and correlations measures for prediction components — devel.cvmeasure","text":"","code":"# \\donttest{ if (bru_safe_inla() && require(ggplot2, quietly = TRUE)) {    # Load Gorilla data    data(\"gorillas\", package = \"inlabru\")    # Use RColorBrewer    library(RColorBrewer)    # Fit a model with two components:   # 1) A spatial smooth SPDE   # 2) A spatial covariate effect (vegetation)    pcmatern <- INLA::inla.spde2.pcmatern(gorillas$mesh,     prior.sigma = c(0.1, 0.01),     prior.range = c(0.01, 0.01)   )    cmp <- coordinates ~ vegetation(gorillas$gcov$vegetation, model = \"factor_contrast\") +     spde(coordinates, model = pcmatern) -     Intercept(1)    fit <- lgcp(cmp, gorillas$nests,     samplers = gorillas$boundary,     domain = list(coordinates = gorillas$mesh),     options = list(control.inla = list(int.strategy = \"eb\"))   )    # Predict SPDE and vegetation at the mesh vertex locations    vrt <- vertices(gorillas$mesh)   pred <- predict(     fit,     vrt,     ~ list(       joint = spde + vegetation,       field = spde,       veg = vegetation     )   )    # Plot component mean    multiplot(ggplot() +     gg(gorillas$mesh, color = pred$joint$mean) +     coord_equal() +     theme(legend.position = \"bottom\"),   ggplot() +     gg(gorillas$mesh, color = pred$field$mean) +     coord_equal() +     theme(legend.position = \"bottom\"),   ggplot() +     gg(gorillas$mesh, color = pred$veg$mean) +     coord_equal() +     theme(legend.position = \"bottom\"),   cols = 3   )    # Plot component variance    multiplot(ggplot() +     gg(gorillas$mesh, color = pred$joint$var) +     coord_equal() +     theme(legend.position = \"bottom\"),   ggplot() +     gg(gorillas$mesh, color = pred$field$var) +     coord_equal() +     theme(legend.position = \"bottom\"),   ggplot() +     gg(gorillas$mesh, color = pred$veg$var) +     coord_equal() +     theme(legend.position = \"bottom\"),   cols = 3   )    # Calculate variance and correlation measure    vm <- devel.cvmeasure(pred$joint, pred$field, pred$veg)   lprange <- range(vm$var.joint, vm$var1, vm$var2)    # Variance contribution of the components    csc <- scale_fill_gradientn(colours = brewer.pal(9, \"YlOrRd\"), limits = lprange)   boundary <- gorillas$boundary    plot.1 <- ggplot() +     gg(gorillas$mesh, color = vm$var.joint, mask = boundary) +     csc +     coord_equal() +     ggtitle(\"joint\") +     theme(legend.position = \"bottom\")   plot.2 <- ggplot() +     gg(gorillas$mesh, color = vm$var1, mask = boundary) +     csc +     coord_equal() +     ggtitle(\"SPDE\") +     theme(legend.position = \"bottom\")   plot.3 <- ggplot() +     gg(gorillas$mesh, color = vm$var2, mask = boundary) +     csc +     coord_equal() +     ggtitle(\"vegetation\") +     theme(legend.position = \"bottom\")    multiplot(plot.1, plot.2, plot.3, cols = 3)    # Covariance of SPDE field and vegetation    ggplot() +     gg(gorillas$mesh, color = vm$cov)    # Correlation between field and vegetation    ggplot() +     gg(gorillas$mesh, color = vm$cor)    # Variance and correlation integrated over space    vm.int <- devel.cvmeasure(pred$joint, pred$field, pred$veg,     samplers = ipoints(gorillas$boundary, gorillas$mesh),     mesh = gorillas$mesh   )   vm.int } #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition  #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition  #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition  #>    var.joint         var1       var2         cor #> 1 0.01955828 0.0001045367 0.01944803 0.002003792 # }"},{"path":"/reference/evaluate_A.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute all A-matrices — evaluate_A","title":"Compute all A-matrices — evaluate_A","text":"Computes matrices included components model likelihood","code":""},{"path":"/reference/evaluate_A.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute all A-matrices — evaluate_A","text":"","code":"evaluate_A(model, lhoods, inla_f)"},{"path":"/reference/evaluate_A.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute all A-matrices — evaluate_A","text":"model bru_model object lhoods bru__like_list object inla_f logical","code":""},{"path":"/reference/evaluate_effect.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate a component effect — evaluate_effect_single","title":"Evaluate a component effect — evaluate_effect_single","text":"Calculate latent component effects given data state component's internal random variables.","code":""},{"path":"/reference/evaluate_effect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate a component effect — evaluate_effect_single","text":"","code":"evaluate_effect_single(...)  evaluate_effect_multi(...)  # S3 method for component evaluate_effect_single(component, state, data, A = NULL, ...)  # S3 method for component_list evaluate_effect_single(components, state, data, A = NULL, ...)  # S3 method for component evaluate_effect_multi(component, state, data, A = NULL, ...)  # S3 method for component_list evaluate_effect_multi(components, state, data, A = NULL, ...)"},{"path":"/reference/evaluate_effect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate a component effect — evaluate_effect_single","text":"... Unused. component bru_component. state Specification one (evaluate_effect_single) several (evaluate_effect_multi) latent variable states: evaluate_effect_single.component: vector latent component state. evaluate_effect_single.component_list: list named vectors. evaluate_effect_multi: list lists evaluate_effect_single.component_list type. evaluate_effect_multi.component, label given component needs included data data.frame Spatial* object covariates /point locations. matrix overriding default projection matrix matrices (named list matrices evaluate_effect.component_list)","code":""},{"path":"/reference/evaluate_effect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate a component effect — evaluate_effect_single","text":"evaluate_effect_single.component: numeric vector component effect values state. evaluate_effect_single.component_list: list evaluated component effect values evaluate_effect_multi.component: list numeric vectors evaluated component effects. evaluate_effect_multi.component_list: list lists evaluated component effects, one list state","code":""},{"path":"/reference/evaluate_effect.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Evaluate a component effect — evaluate_effect_single","text":"Fabian E. Bachl bachlfab@gmail.com Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"/reference/evaluate_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute all index values — evaluate_index","title":"Compute all index values — evaluate_index","text":"Computes index values matrices included components","code":""},{"path":"/reference/evaluate_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute all index values — evaluate_index","text":"","code":"evaluate_index(model, lhoods)"},{"path":"/reference/evaluate_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute all index values — evaluate_index","text":"model bru_model object lhoods bru__like_list object","code":""},{"path":"/reference/evaluate_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute all index values — evaluate_index","text":"named list idx_full idx_inla, named list indices, inla_subset, inla_subset, named list logical subset specifications extracting INLA::f() compatible index subsets.","code":""},{"path":"/reference/evaluate_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate or sample from a posterior result given a model and locations — evaluate_model","title":"Evaluate or sample from a posterior result given a model and locations — evaluate_model","text":"Evaluate sample posterior result given model locations","code":""},{"path":"/reference/evaluate_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate or sample from a posterior result given a model and locations — evaluate_model","text":"","code":"evaluate_model(   model,   state,   data = NULL,   A = NULL,   predictor = NULL,   format = NULL,   include = NULL,   exclude = NULL,   ... )  evaluate_state(   model,   result,   property = \"mode\",   n = 1,   seed = 0L,   num.threads = NULL,   internal_hyperpar = FALSE,   ... )"},{"path":"/reference/evaluate_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate or sample from a posterior result given a model and locations — evaluate_model","text":"model bru model state list lists, generated evaluate_state() data list, data.frame, Spatial*DataFrame, coordinates covariates needed evaluate predictor. Precomputed -matrices predictor formula expression evaluated given posterior sample thereof. default (NULL) returns data.frame containing sampled effects. case formula right hand side used evaluation. format character; determines storage format predictor output. Available options: \"auto\" first evaluated result vector single-column matrix, \"matrix\" format used, otherwise \"list\". \"matrix\" matrix column contains evaluated predictor expression state. \"list\" list element contains evaluated predictor expression state. include Character vector component labels needed predictor expression; Default: NULL (include components explicitly excluded) exclude Character vector component labels used predictor expression. exclusion list applied list determined include parameter; Default: NULL (remove components inclusion list) ... Additional arguments passed inla.posterior.sample result bru object bru() lgcp() property Property model components obtain value . Default: \"mode\". options \"mean\", \"0.025quant\", \"0.975quant\", \"sd\" \"sample\". case \"sample\" obtain samples posterior (see n parameter). result NULL, -zero vectors returned component. n Number samples draw. seed seed != 0L, random seed num.threads Specification desired number threads parallel computations. Default NULL, leaves INLA. seed != 0, overridden \"1:1\" internal_hyperpar logical; TRUE, return hyperparameter properties internal scale. Currently ignored property=\"sample\". Default FALSE.","code":""},{"path":"/reference/evaluate_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate or sample from a posterior result given a model and locations — evaluate_model","text":"evaluate_model wrapper evaluate model state, -matrices, effects, predictor, one call. evaluate_state evaluates model state properties samples","code":""},{"path":"/reference/evaluate_predictor.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate component effects or expressions — evaluate_predictor","title":"Evaluate component effects or expressions — evaluate_predictor","text":"Evaluate component effects expressions, based bru model one several states latent variables hyperparameters.","code":""},{"path":"/reference/evaluate_predictor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate component effects or expressions — evaluate_predictor","text":"","code":"evaluate_predictor(model, state, data, effects, predictor, format = \"auto\")"},{"path":"/reference/evaluate_predictor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate component effects or expressions — evaluate_predictor","text":"state list element list named latent state information, produced evaluate_state() data list, data.frame, Spatial*DataFrame, coordinates covariates needed evaluate model. effects list element list named evaluated effects, computed evaluate_effect_multi.component_list() predictor Either formula expression format character; determines storage format output. Available options: \"auto\" first evaluated result vector single-column matrix, \"matrix\" format used, otherwise \"list\". \"matrix\" matrix column contains evaluated predictor expression state. \"list\" list column contains evaluated predictor expression state. inla_f logical Default: \"auto\"","code":""},{"path":"/reference/evaluate_predictor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate component effects or expressions — evaluate_predictor","text":"list matrix returned, specified format","code":""},{"path":"/reference/evaluate_predictor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate component effects or expressions — evaluate_predictor","text":"component, e.g. \"name\", state values available name_latent, arbitrary evaluation can done name_eval(...), see component_eval().","code":""},{"path":"/reference/expand_labels.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand labels — expand_labels","title":"Expand labels — expand_labels","text":"Expand labels","code":""},{"path":"/reference/expand_labels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand labels — expand_labels","text":"","code":"expand_labels(labels, expand, suffix)"},{"path":"/reference/expand_labels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand labels — expand_labels","text":"labels character vector; original labels expand character vector; subset labels expand suffix character; suffix add labels selected expand","code":""},{"path":"/reference/expand_labels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand labels — expand_labels","text":"vector labels suffix appended selected labels","code":""},{"path":"/reference/extract_property.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract a summary property from all results of an inla result — extract_property","title":"Extract a summary property from all results of an inla result — extract_property","text":"Extract summary property results inla result","code":""},{"path":"/reference/extract_property.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract a summary property from all results of an inla result — extract_property","text":"","code":"extract_property(result, property, internal_hyperpar = FALSE)"},{"path":"/reference/extract_property.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract a summary property from all results of an inla result — extract_property","text":"result inla result object property character; \"mean\", \"sd\", \"mode\", column identifier inla result $summary.fixed, $summary.random$label, $summary.hyperpar, \"joint_mode\". \"joint_mode\", joint latent mode extracted, joint hyperparameter mode, internal scale. \"predictor_sd\" posterior standard deviations linear predictor returned. internal_hyperpar logical; TRUE, use internal scale hyperparamter properties. Default FALSE, except property \"joint_mode\" forces internal_hyperpar=TRUE.","code":""},{"path":"/reference/extract_property.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract a summary property from all results of an inla result — extract_property","text":"named list estimated fixed effect coefficient, random effect vector, hyperparameter. hyperparameter names standardised bru_standardise_names()","code":""},{"path":"/reference/fm_CRS.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a coordinate reference system object — fm_CRS","title":"Create a coordinate reference system object — fm_CRS","text":"Creates either CRS object inla.CRS object, describing coordinate reference system","code":""},{"path":"/reference/fm_CRS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a coordinate reference system object — fm_CRS","text":"","code":"fm_CRS(   projargs = NULL,   doCheckCRSArgs = TRUE,   args = NULL,   oblique = NULL,   SRS_string = NULL,   ... )  fm_wkt_predef()"},{"path":"/reference/fm_CRS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a coordinate reference system object — fm_CRS","text":"projargs Either 1) projection argument string suitable input sp::CRS, 2) existing CRS object, 3) shortcut reference string predefined projection; run names(fm_wkt_predef()) valid predefined projections. doCheckCRSArgs default TRUE, must set FALSE package developers including CRS S4 class definition avoid uncontrollable loading rgdal namespace. args optional list name/value pairs add /override PROJ4 arguments projargs.  name=value converted \"+name=value\", name=NA converted \"+name\". oblique Vector length 4 rotation angles (degrees) oblique projection, values defaulting zero. values indicate (longitude, latitude, orientation, orbit), explained Details section . SRS_string WKT2 string defining coordinate system; see sp::CRS. takes precedence projargs. ... Additional parameters. currently use.","code":""},{"path":"/reference/fm_CRS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a coordinate reference system object — fm_CRS","text":"Either sp::CRS object inla.CRS object, depending coordinate reference system described parameters can expressed pure sp::CRS object . S3 inla.CRS object list, usually (necessarily) containing least one element: crs basic sp::CRS object fm_wkt_predef returns WKT2 string defining projection","code":""},{"path":"/reference/fm_CRS.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a coordinate reference system object — fm_CRS","text":"first two elements oblique vector (longitude, latitude) coordinates oblique centre point. third value (orientation) counterclockwise rotation angle observer looking centre point outside sphere. fourth value quasi-longitude (orbit angle) rotation along oblique observers equator. Simple oblique: oblique=c(0, 45) Polar: oblique=c(0, 90) Quasi-transversal: oblique=c(0, 0, 90) Satellite orbit viewpoint: oblique=c(lon0-time*v1, 0, orbitangle, orbit0+time*v2), lon0 longitude satellite orbit crosses equator time=0, satellite angle orbit0 along orbit.  orbital angle relative equatorial plane orbitangle, v1 v2 angular velocities planet satellite, respectively. Note \"forward\" satellite's point view \"right\" projection. oblique[2] oblique[3] non-zero, resulting projection correct perfect spheres.","code":""},{"path":[]},{"path":"/reference/fm_CRS.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create a coordinate reference system object — fm_CRS","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"/reference/fm_CRS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a coordinate reference system object — fm_CRS","text":"","code":"if (require(rgdal)) {   if (fm_has_PROJ6()) {     crs1 <- fm_CRS(\"longlat_globe\")     crs2 <- fm_CRS(\"lambert_globe\")     crs3 <- fm_CRS(\"mollweide_norm\")     crs4 <- fm_CRS(\"hammer_globe\")     crs5 <- fm_CRS(\"sphere\")     crs6 <- fm_CRS(\"globe\")   } else {     # Old definitions for pre-PROJ6:     # Old radius-1 projections have a added \"_norm\" in the PROJ6 version of     # the fm_CRS() predefined projections. They are detected and converted     # to the new versions when RPOJ6 is available.     crs1 <- fm_CRS(\"longlat\") # PROJ6: longlat_norm     crs2 <- fm_CRS(\"lambert\") # PROJ6: lambert_norm     crs3 <- fm_CRS(\"mollweide\") # PROJ6: mollweide_norm     crs4 <- fm_CRS(\"hammer\") # PROJ6: hammer_norm     crs5 <- fm_CRS(\"sphere\")     crs6 <- fm_CRS(\"globe\")   } } #> Loading required package: rgdal #> Please note that rgdal will be retired by the end of 2023, #> plan transition to sf/stars/terra functions using GDAL and PROJ #> at your earliest convenience. #>  #> rgdal: version: 1.5-32, (SVN revision 1176) #> Geospatial Data Abstraction Library extensions to R successfully loaded #> Loaded GDAL runtime: GDAL 3.0.4, released 2020/01/28 #> Path to GDAL shared files: /usr/share/gdal #> GDAL binary built with GEOS: TRUE  #> Loaded PROJ runtime: Rel. 6.3.1, February 10th, 2020, [PJ_VERSION: 631] #> Path to PROJ shared files: /usr/share/proj #> Linking to sp version:1.5-0 #> To mute warnings of possible GDAL/OSR exportToProj4() degradation, #> use options(\"rgdal_show_exportToProj4_warnings\"=\"none\") before loading sp or rgdal. #> Warning: Discarded datum Unknown based on Normal Sphere (r=6370997) ellipsoid in Proj4 definition #> Warning: Discarded datum Unknown based on Normal Sphere (r=6370997) ellipsoid in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=moll +lon_0=0 +x_0=0 +y_0=0 +R=0.707106781186548 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded datum Unknown based on Normal Sphere (r=6370997) ellipsoid in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: export to PROJ failed: generic error of unknown origin #> Warning: Discarded ellps Normal Sphere (r=6370997) in Proj4 definition: NA #> Warning: Discarded datum Unknown based on Normal Sphere (r=6370997) ellipsoid in Proj4 definition if (FALSE) { names(fm_wkt_predef()) }"},{"path":"/reference/fm_CRSargs.html","id":null,"dir":"Reference","previous_headings":"","what":"Show expanded CRS arguments — fm_CRS_as_list","title":"Show expanded CRS arguments — fm_CRS_as_list","text":"Wrappers sp::CRS inla.CRS objects handle coordinate reference system argument string. methods longer used PROJ6/rgdal3; see fm_crs_get_wkt() new approach.","code":""},{"path":"/reference/fm_CRSargs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show expanded CRS arguments — fm_CRS_as_list","text":"","code":"fm_CRS_as_list(x, ...)  fm_list_as_CRS(x, ...)  fm_CRSargs(x, ...)  fm_list_as_CRSargs(x, ...)  fm_CRSargs_as_list(x, ...)"},{"path":"/reference/fm_CRSargs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show expanded CRS arguments — fm_CRS_as_list","text":"x sp::CRS inla.CRS object (fm_CRSargs fm_CRS_as_list), character string (fm_CRSargs_as_list), list (fm_list_as_CRS fm_list_as_CRSargs). ... Additional arguments passed methods.","code":""},{"path":"/reference/fm_CRSargs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show expanded CRS arguments — fm_CRS_as_list","text":"fm_CRSargs fm_list_as_CRSargs, character string PROJ.4 arguments. fm_CRS_as_list fm_CRSargs_as_list, list name/value pairs. fm_list_as_CRS, CRS inla.CRS object. fm_list_as_CRSargs(), CRS proj4 string name=value pair list fm_CRSargs_as_list(), list name=value pairs CRS proj4 string","code":""},{"path":[]},{"path":"/reference/fm_CRSargs.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Show expanded CRS arguments — fm_CRS_as_list","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"/reference/fm_CRSargs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show expanded CRS arguments — fm_CRS_as_list","text":"","code":"if (require(rgdal) && !fm_has_PROJ6()) {   crs0 <- fm_CRS(\"longlat\")   p4s <- fm_CRSargs(crs0)   lst <- fm_CRSargs_as_list(p4s)   crs1 <- fm_list_as_CRS(lst)   lst$a <- 2   crs2 <- fm_CRS(p4s, args = lst)   print(fm_CRSargs(crs0))   print(fm_CRSargs(crs1))   print(fm_CRSargs(crs2)) }"},{"path":"/reference/fm_crs_wkt.html","id":null,"dir":"Reference","previous_headings":"","what":"Handling CRS/WKT — fm_wkt_is_geocent","title":"Handling CRS/WKT — fm_wkt_is_geocent","text":"Get set CRS object WKT string properties.","code":""},{"path":"/reference/fm_crs_wkt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Handling CRS/WKT — fm_wkt_is_geocent","text":"","code":"fm_wkt_is_geocent(wkt)  fm_crs_is_geocent(crs)  fm_wkt_get_ellipsoid_radius(wkt)  fm_crs_get_ellipsoid_radius(crs)  fm_wkt_set_ellipsoid_radius(wkt, radius)  fm_crs_set_ellipsoid_radius(crs, radius)  fm_wkt_unit_params()  fm_wkt_get_lengthunit(wkt)  fm_wkt_set_lengthunit(wkt, unit, params = NULL)  fm_crs_get_wkt(crs)  fm_crs_get_lengthunit(crs)  fm_crs_set_lengthunit(crs, unit, params = NULL)"},{"path":"/reference/fm_crs_wkt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Handling CRS/WKT — fm_wkt_is_geocent","text":"wkt WKT2 character string crs sp::CRS inla.CRS object radius numeric; new radius value unit character, name unit. Supported names \"metre\", \"kilometre\", aliases \"meter\", \"m\", International metre\", \"kilometer\", \"km\", defined fm_wkt_unit_params params argument. (legacy PROJ4 use, \"m\" \"km\" supported) params Length unit definitions, list format produced fm_wkt_unit_params(), Default: NULL, invokes fm_wkt_unit_params()","code":""},{"path":"/reference/fm_crs_wkt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Handling CRS/WKT — fm_wkt_is_geocent","text":"fm_wkt_unit_params, list named unit definitions fm_wkt_get_lengthunit, list length units used wkt string, excluding ellipsoid radius unit. fm_wkt_set_lengthunit, WKT2 string altered length units. Note length unit ellipsoid radius unchanged. fm_crs_get_wkt, WKT2 string. fm_crs_get_lengthunit, list length units used wkt string, excluding ellipsoid radius unit. (legacy PROJ4 code, raw units proj4string returned, present.) fm_crs_set_lengthunit, sp::CRS object altered length units. Note length unit ellipsoid radius unchanged.","code":""},{"path":[]},{"path":"/reference/fm_crs_wkt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Handling CRS/WKT — fm_wkt_is_geocent","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"/reference/fm_crs_wkt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Handling CRS/WKT — fm_wkt_is_geocent","text":"","code":"if (FALSE) { if (fm_has_PROJ6()) {   c1 <- fm_CRS(\"globe\")   fm_crs_get_lengthunit(c1)   c2 <- fm_crs_set_lengthunit(c1, \"km\")   fm_crs_get_lengthunit(c2) } }"},{"path":"/reference/fm_has_PROJ6.html","id":null,"dir":"Reference","previous_headings":"","what":"PROJ6 detection — fm_has_PROJ6","title":"PROJ6 detection — fm_has_PROJ6","text":"Detect whether PROJ6 available","code":""},{"path":"/reference/fm_has_PROJ6.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PROJ6 detection — fm_has_PROJ6","text":"","code":"fm_has_PROJ6()  fm_not_for_PROJ6(fun = NULL)  fm_not_for_PROJ4(fun = NULL)  fm_fallback_PROJ6(fun = NULL)  fm_requires_PROJ6(fun = NULL)"},{"path":"/reference/fm_has_PROJ6.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PROJ6 detection — fm_has_PROJ6","text":"fun name function requires PROJ6. Default: NULL, uses name calling function.","code":""},{"path":"/reference/fm_has_PROJ6.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PROJ6 detection — fm_has_PROJ6","text":"fm_has_PROJ6, logical; TRUE PROJ6 available, FALSE otherwise","code":""},{"path":"/reference/fm_has_PROJ6.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PROJ6 detection — fm_has_PROJ6","text":"fm_not_for_PROJ6 called warn using old PROJ4 features even though PROJ6 available fm_not_for_PROJ4 called give error calling methods available PROJ6 fm_fallback_PROJ6 called warn falling back using old PROJ4 methods PROJ6 method implemented fm_requires_PROJ6 called give error PROJ6 required available","code":""},{"path":"/reference/fm_has_PROJ6.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PROJ6 detection — fm_has_PROJ6","text":"","code":"fm_has_PROJ6() #> [1] TRUE"},{"path":"/reference/fm_identical_CRS.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if two CRS objects are identical — fm_identical_CRS","title":"Check if two CRS objects are identical — fm_identical_CRS","text":"Check two CRS objects identical","code":""},{"path":"/reference/fm_identical_CRS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if two CRS objects are identical — fm_identical_CRS","text":"","code":"fm_identical_CRS(crs0, crs1, crsonly = FALSE)"},{"path":"/reference/fm_identical_CRS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if two CRS objects are identical — fm_identical_CRS","text":"crs0, crs1 Two sp::CRS inla.CRS objects compared. crsonly logical. TRUE crs0 crs1 inla.CRS objects, extract compare sp::CRS objects. Default: FALSE","code":""},{"path":"/reference/fm_spTransform.html","id":null,"dir":"Reference","previous_headings":"","what":"Handle transformation of various inla objects according to coordinate\nreference systems of sp::CRS or INLA::inla.CRS class. — fm_spTransform","title":"Handle transformation of various inla objects according to coordinate\nreference systems of sp::CRS or INLA::inla.CRS class. — fm_spTransform","text":"Handle transformation various inla objects according coordinate reference systems sp::CRS INLA::inla.CRS class.","code":""},{"path":"/reference/fm_spTransform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Handle transformation of various inla objects according to coordinate\nreference systems of sp::CRS or INLA::inla.CRS class. — fm_spTransform","text":"","code":"fm_spTransform(x, ...)  # S3 method for default fm_spTransform(x, crs0, crs1, passthrough = FALSE, ...)  # S3 method for SpatialPoints fm_spTransform(x, CRSobj, passthrough = FALSE, ...)  # S3 method for SpatialPointsDataFrame fm_spTransform(x, CRSobj, passthrough = FALSE, ...)  # S3 method for inla.mesh.lattice fm_spTransform(x, CRSobj, passthrough = FALSE, ...)  # S3 method for inla.mesh.segment fm_spTransform(x, CRSobj, passthrough = FALSE, ...)  # S3 method for inla.mesh fm_spTransform(x, CRSobj, passthrough = FALSE, ...)"},{"path":"/reference/fm_spTransform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Handle transformation of various inla objects according to coordinate\nreference systems of sp::CRS or INLA::inla.CRS class. — fm_spTransform","text":"x object transformed current CRS new CRS ... Potential additional arguments crs0 source sp::CRS inla.CRS object crs1 target sp::CRS inla.CRS object passthrough Default FALSE. Setting TRUE allows objects CRS information passed without transformation. CRSobj target sp::CRS inla.CRS object","code":""},{"path":"/reference/fm_spTransform.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Handle transformation of various inla objects according to coordinate\nreference systems of sp::CRS or INLA::inla.CRS class. — fm_spTransform","text":"default method handles low level transformation raw coordinates.","code":""},{"path":[]},{"path":"/reference/fm_sp_get_crs.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract CRS information — fm_sp_get_crs","title":"Extract CRS information — fm_sp_get_crs","text":"Wrapper CRS(projargs) (PROJ4) CRS(wkt) sp::Spatial objects.","code":""},{"path":"/reference/fm_sp_get_crs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract CRS information — fm_sp_get_crs","text":"","code":"fm_sp_get_crs(x)"},{"path":"/reference/fm_sp_get_crs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract CRS information — fm_sp_get_crs","text":"x sp::Spatial object","code":""},{"path":"/reference/fm_sp_get_crs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract CRS information — fm_sp_get_crs","text":"CRS object, NULL valid CRS identified","code":""},{"path":"/reference/fm_sp_get_crs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract CRS information — fm_sp_get_crs","text":"function convenience method workaround PROJ4/PROJ6 differences, lack crs extraction method Spatial objects.","code":""},{"path":"/reference/fm_sp_get_crs.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract CRS information — fm_sp_get_crs","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"/reference/fm_sp_get_crs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract CRS information — fm_sp_get_crs","text":"","code":"if (FALSE) { if (interactive()) {   s <- sp::SpatialPoints(matrix(1:6, 3, 2), proj4string = fm_CRS(\"sphere\"))   fm_sp_get_crs(s) } }"},{"path":"/reference/generate.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate samples from fitted bru models — generate","title":"Generate samples from fitted bru models — generate","text":"Generic function sampling fitted models. function invokes particular methods depend class first argument. Takes fitted bru object produced function bru() produces samples given new set values model covariates original values used model fit. samples can based R expression valid given values/covariates joint posterior estimated random effects.","code":""},{"path":"/reference/generate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate samples from fitted bru models — generate","text":"","code":"generate(object, ...)  # S3 method for bru generate(   object,   data = NULL,   formula = NULL,   n.samples = 100,   seed = 0L,   num.threads = NULL,   include = NULL,   exclude = NULL,   ... )"},{"path":"/reference/generate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate samples from fitted bru models — generate","text":"object bru object obtained calling bru(). ... additional, unused arguments. data data.frame SpatialPointsDataFrame covariates needed sampling. formula formula right hand side defines R expression evaluate generated sample. NULL, latent hyperparameter states returned named list elements. See Details information. n.samples Integer setting number samples draw order calculate posterior statistics. default, 100, rather low provides quick approximate result. seed Random number generator seed passed INLA::inla.posterior.sample num.threads Specification desired number threads parallel computations. Default NULL, leaves INLA. seed != 0, overridden \"1:1\" include Character vector component labels needed predictor expression; Default: NULL (include components explicitly excluded) exclude Character vector component labels used predictor expression. exclusion list applied list determined include parameter; Default: NULL (remove components inclusion list)","code":""},{"path":"/reference/generate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate samples from fitted bru models — generate","text":"form value returned gg depends class argument. See documentation particular methods details produced method. List generated samples","code":""},{"path":"/reference/generate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate samples from fitted bru models — generate","text":"addition component names (give effect component evaluated input data), suffix _latent variable name can used directly access latent state component, suffix function _eval can used evaluate component input values expressions defined component definition , e.g. field_eval(cbind(x, y)) component defined field(coordinates, ...) (see also component_eval()). \"iid\" models mapper = bru_mapper_index(n), rnorm() used generate new realisations indices greater n.","code":""},{"path":[]},{"path":"/reference/generate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate samples from fitted bru models — generate","text":"","code":"# \\donttest{ if (bru_safe_inla(multicore = FALSE)) {    # Generate data for a simple linear model    input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, y <- 5 + 2 * cos(1:10) + rnorm(10, mean = 0, sd = 0.1))    # Fit the model    fit <- bru(y ~ xeff(main = x, model = \"linear\"),     family = \"gaussian\", data = input.df   )   summary(fit)    # Generate samples for some predefined x    df <- data.frame(x = seq(-4, 4, by = 0.1))   smp <- generate(fit, df, ~ xeff + Intercept, n.samples = 10)    # Plot the resulting realizations    plot(df$x, smp[, 1], type = \"l\")   for (k in 2:ncol(smp)) points(df$x, smp[, k], type = \"l\")    # We can also draw samples form the joint posterior    df <- data.frame(x = 1)   smp <- generate(fit, df, ~ data.frame(xeff, Intercept), n.samples = 10)   smp[[1]]    # ... and plot them   if (require(ggplot2, quietly = TRUE)) {     plot(do.call(rbind, smp))   } } #> Current num.threads is '1:1'. #> No num.threads change needed.   # } # \\donttest{ if (bru_safe_inla(multicore = FALSE)) {    # Generate data for a simple linear model    input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, y <- 5 + 2 * cos(1:10) + rnorm(10, mean = 0, sd = 0.1))    # Fit the model    fit <- bru(y ~ xeff(main = x, model = \"linear\"),     family = \"gaussian\", data = input.df   )   summary(fit)    # Generate samples for some predefined x    df <- data.frame(x = seq(-4, 4, by = 0.1))   smp <- generate(fit, df, ~ xeff + Intercept, n.samples = 10)    # Plot the resulting realizations    plot(df$x, smp[, 1], type = \"l\")   for (k in 2:ncol(smp)) points(df$x, smp[, k], type = \"l\")    # We can also draw samples form the joint posterior    df <- data.frame(x = 1)   smp <- generate(fit, df, ~ data.frame(xeff, Intercept), n.samples = 10)   smp[[1]]    # ... and plot them   if (require(ggplot2, quietly = TRUE)) {     plot(do.call(rbind, smp))   } } #> Current num.threads is '1:1'. #> No num.threads change needed.   # }"},{"path":"/reference/gg.RasterLayer.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for RasterLayer objects — gg.RasterLayer","title":"Geom for RasterLayer objects — gg.RasterLayer","text":"function takes RasterLayer object, converts SpatialPixelsDataFrame uses geom_tile plot data.","code":""},{"path":"/reference/gg.RasterLayer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for RasterLayer objects — gg.RasterLayer","text":"","code":"# S3 method for RasterLayer gg(   data,   mapping = ggplot2::aes(x = .data[[\"x\"]], y = .data[[\"y\"]], fill = .data[[\"layer\"]]),   ... )"},{"path":"/reference/gg.RasterLayer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for RasterLayer objects — gg.RasterLayer","text":"data RasterLayer object. mapping aesthetic mappings created aes. passed geom_tile. ... Arguments passed geom_tile.","code":""},{"path":"/reference/gg.RasterLayer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for RasterLayer objects — gg.RasterLayer","text":"object returned geom_tile","code":""},{"path":"/reference/gg.RasterLayer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Geom for RasterLayer objects — gg.RasterLayer","text":"function requires raster ggplot2 packages.","code":""},{"path":[]},{"path":"/reference/gg.RasterLayer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for RasterLayer objects — gg.RasterLayer","text":"","code":"if (FALSE) { # Some features require the raster and spatstat.data packages. if (require(\"spatstat.data\", quietly = TRUE) &&   require(\"raster\", quietly = TRUE) &&   require(\"ggplot2\", quietly = TRUE)) {    # Load Gorilla data   data(\"gorillas\", package = \"spatstat.data\")    # Convert elevation covariate to RasterLayer    elev <- as(gorillas.extra$elevation, \"RasterLayer\")    # Plot the elevation    ggplot() +     gg(elev) } }"},{"path":"/reference/gg.SpatialGridDataFrame.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for SpatialGridDataFrame objects — gg.SpatialGridDataFrame","title":"Geom for SpatialGridDataFrame objects — gg.SpatialGridDataFrame","text":"Coerces input SpatialGridDataFrame SpatialPixelsDataFrame calls gg.SpatialPixelsDataFrame() plot . Requires ggplot2 package.","code":""},{"path":"/reference/gg.SpatialGridDataFrame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for SpatialGridDataFrame objects — gg.SpatialGridDataFrame","text":"","code":"# S3 method for SpatialGridDataFrame gg(data, ...)"},{"path":"/reference/gg.SpatialGridDataFrame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for SpatialGridDataFrame objects — gg.SpatialGridDataFrame","text":"data SpatialGridDataFrame object. ... Arguments passed gg.SpatialPixelsDataFrame().","code":""},{"path":"/reference/gg.SpatialGridDataFrame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for SpatialGridDataFrame objects — gg.SpatialGridDataFrame","text":"geom_tile value.","code":""},{"path":[]},{"path":"/reference/gg.SpatialGridDataFrame.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for SpatialGridDataFrame objects — gg.SpatialGridDataFrame","text":"","code":"# \\donttest{   if (require(ggplot2, quietly = TRUE) &&       require(ggpolypath, quietly = TRUE)) {     # Load Gorilla data      data(\"gorillas\", package = \"inlabru\")      # Plot Gorilla elevation covariate provided as SpatialPixelsDataFrame.     # The same syntax applies to SpatialGridDataFrame objects.      ggplot() +       gg(gorillas$gcov$elevation)      # Add Gorilla survey boundary and nest sightings      ggplot() +       gg(gorillas$gcov$elevation) +       gg(gorillas$boundary) +       gg(gorillas$nests)      # Load pantropical dolphin data      data(\"mexdolphin\")      # Plot the pantropiical survey boundary, ship transects and dolphin sightings      ggplot() +       gg(mexdolphin$ppoly) + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers) + # ship transects as SpatialLines       gg(mexdolphin$points) # dolphin sightings as SpatialPoints      # Change color      ggplot() +       gg(mexdolphin$ppoly, color = \"green\") + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers, color = \"red\") + # ship transects as SpatialLines       gg(mexdolphin$points, color = \"blue\") # dolphin sightings as SpatialPoints       # Visualize data annotations: line width by segment number      names(mexdolphin$samplers) # 'seg' holds the segment number     ggplot() +       gg(mexdolphin$samplers, aes(color = seg))      # Visualize data annotations: point size by dolphin group size      names(mexdolphin$points) # 'size' holds the group size     ggplot() +       gg(mexdolphin$points, aes(size = size))   } #> Regions defined for each Polygons #> Regions defined for each Polygons #> Regions defined for each Polygons  # }"},{"path":"/reference/gg.SpatialLines.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for SpatialLines objects — gg.SpatialLines","title":"Geom for SpatialLines objects — gg.SpatialLines","text":"Extracts start end points lines calls geom_segment plot lines . Requires ggplot2 package.","code":""},{"path":"/reference/gg.SpatialLines.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for SpatialLines objects — gg.SpatialLines","text":"","code":"# S3 method for SpatialLines gg(data, mapping = NULL, crs = NULL, ...)"},{"path":"/reference/gg.SpatialLines.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for SpatialLines objects — gg.SpatialLines","text":"data SpatialLines SpatialLinesDataFrame object. mapping Aesthetic mappings created ggplot2::aes ggplot2::aes_ used update default mapping. default mapping ggplot2::aes(x = .data[[coordnames(data)[1]]], y = .data[[coordnames(data)[2]]], xend = .data[[paste0(\"end.\", coordnames(data)[1])]], yend = .data[[paste0(\"end.\", coordnames(data)[2])]]). crs CRS object defining coordinate system project data plotting. ... Arguments passed ggplot2::geom_segment.","code":""},{"path":"/reference/gg.SpatialLines.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for SpatialLines objects — gg.SpatialLines","text":"`geom_segment`` return value.","code":""},{"path":[]},{"path":"/reference/gg.SpatialLines.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for SpatialLines objects — gg.SpatialLines","text":"","code":"# \\donttest{   if (require(ggplot2, quietly = TRUE) &&       require(ggpolypath, quietly = TRUE)) {     # Load Gorilla data      data(\"gorillas\", package = \"inlabru\")      # Plot Gorilla elevation covariate provided as SpatialPixelsDataFrame.     # The same syntax applies to SpatialGridDataFrame objects.      ggplot() +       gg(gorillas$gcov$elevation)      # Add Gorilla survey boundary and nest sightings      ggplot() +       gg(gorillas$gcov$elevation) +       gg(gorillas$boundary) +       gg(gorillas$nests)      # Load pantropical dolphin data      data(\"mexdolphin\")      # Plot the pantropiical survey boundary, ship transects and dolphin sightings      ggplot() +       gg(mexdolphin$ppoly) + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers) + # ship transects as SpatialLines       gg(mexdolphin$points) # dolphin sightings as SpatialPoints      # Change color      ggplot() +       gg(mexdolphin$ppoly, color = \"green\") + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers, color = \"red\") + # ship transects as SpatialLines       gg(mexdolphin$points, color = \"blue\") # dolphin sightings as SpatialPoints       # Visualize data annotations: line width by segment number      names(mexdolphin$samplers) # 'seg' holds the segment number     ggplot() +       gg(mexdolphin$samplers, aes(color = seg))      # Visualize data annotations: point size by dolphin group size      names(mexdolphin$points) # 'size' holds the group size     ggplot() +       gg(mexdolphin$points, aes(size = size))   } #> Regions defined for each Polygons #> Regions defined for each Polygons #> Regions defined for each Polygons  # }"},{"path":"/reference/gg.SpatialPixels.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for SpatialPixels objects — gg.SpatialPixels","title":"Geom for SpatialPixels objects — gg.SpatialPixels","text":"Uses geom_point plot pixel centers. Requires ggplot2 package.","code":""},{"path":"/reference/gg.SpatialPixels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for SpatialPixels objects — gg.SpatialPixels","text":"","code":"# S3 method for SpatialPixels gg(data, ...)"},{"path":"/reference/gg.SpatialPixels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for SpatialPixels objects — gg.SpatialPixels","text":"data SpatialPixels object. ... Arguments passed geom_tile.","code":""},{"path":"/reference/gg.SpatialPixels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for SpatialPixels objects — gg.SpatialPixels","text":"geom_tile return value.","code":""},{"path":[]},{"path":"/reference/gg.SpatialPixels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for SpatialPixels objects — gg.SpatialPixels","text":"","code":"if (require(\"ggplot2\", quietly = TRUE)) {   # Load Gorilla data    data(gorillas, package = \"inlabru\")    # Turn elevation covariate into SpatialPixels   pxl <- SpatialPixels(SpatialPoints(gorillas$gcov$elevation))    # Plot the pixel centers   ggplot() +     gg(pxl, size = 0.1) }"},{"path":"/reference/gg.SpatialPixelsDataFrame.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for SpatialPixelsDataFrame objects — gg.SpatialPixelsDataFrame","title":"Geom for SpatialPixelsDataFrame objects — gg.SpatialPixelsDataFrame","text":"Coerces input SpatialPixelsDataFrame data.frame uses geom_tile plot . Requires ggplot2 package.","code":""},{"path":"/reference/gg.SpatialPixelsDataFrame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for SpatialPixelsDataFrame objects — gg.SpatialPixelsDataFrame","text":"","code":"# S3 method for SpatialPixelsDataFrame gg(data, mapping = NULL, crs = NULL, mask = NULL, ...)"},{"path":"/reference/gg.SpatialPixelsDataFrame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for SpatialPixelsDataFrame objects — gg.SpatialPixelsDataFrame","text":"data SpatialPixelsDataFrame object. mapping Aesthetic mappings created aes used update default mapping. default mapping ggplot2::aes(x = .data[[coordnames(data)[1]]], y = .data[[coordnames(data)[2]]], fill = .data[[names(data)[[1]]]]). crs CRS object defining coordinate system project data plotting. mask SpatialPolygon defining region plotted. ... Arguments passed geom_tile.","code":""},{"path":"/reference/gg.SpatialPixelsDataFrame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for SpatialPixelsDataFrame objects — gg.SpatialPixelsDataFrame","text":"geom_tile return value.","code":""},{"path":[]},{"path":"/reference/gg.SpatialPixelsDataFrame.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for SpatialPixelsDataFrame objects — gg.SpatialPixelsDataFrame","text":"","code":"# \\donttest{   if (require(ggplot2, quietly = TRUE) &&       require(ggpolypath, quietly = TRUE)) {     # Load Gorilla data      data(\"gorillas\", package = \"inlabru\")      # Plot Gorilla elevation covariate provided as SpatialPixelsDataFrame.     # The same syntax applies to SpatialGridDataFrame objects.      ggplot() +       gg(gorillas$gcov$elevation)      # Add Gorilla survey boundary and nest sightings      ggplot() +       gg(gorillas$gcov$elevation) +       gg(gorillas$boundary) +       gg(gorillas$nests)      # Load pantropical dolphin data      data(\"mexdolphin\")      # Plot the pantropiical survey boundary, ship transects and dolphin sightings      ggplot() +       gg(mexdolphin$ppoly) + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers) + # ship transects as SpatialLines       gg(mexdolphin$points) # dolphin sightings as SpatialPoints      # Change color      ggplot() +       gg(mexdolphin$ppoly, color = \"green\") + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers, color = \"red\") + # ship transects as SpatialLines       gg(mexdolphin$points, color = \"blue\") # dolphin sightings as SpatialPoints       # Visualize data annotations: line width by segment number      names(mexdolphin$samplers) # 'seg' holds the segment number     ggplot() +       gg(mexdolphin$samplers, aes(color = seg))      # Visualize data annotations: point size by dolphin group size      names(mexdolphin$points) # 'size' holds the group size     ggplot() +       gg(mexdolphin$points, aes(size = size))   } #> Regions defined for each Polygons #> Regions defined for each Polygons #> Regions defined for each Polygons  # }"},{"path":"/reference/gg.SpatialPoints.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for SpatialPoints objects — gg.SpatialPoints","title":"Geom for SpatialPoints objects — gg.SpatialPoints","text":"function coerces SpatialPoints data.frame uses geom_point plot points. Requires ggplot2 package.","code":""},{"path":"/reference/gg.SpatialPoints.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for SpatialPoints objects — gg.SpatialPoints","text":"","code":"# S3 method for SpatialPoints gg(data, mapping = NULL, crs = NULL, ...)"},{"path":"/reference/gg.SpatialPoints.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for SpatialPoints objects — gg.SpatialPoints","text":"data SpatialPoints object. mapping Aesthetic mappings created aes used update default mapping. default mapping ggplot2::aes(x = .data[[coordnames(data)[1]]], y = .data[[coordnames(data)[2]]]). crs CRS object defining coordinate system project data plotting. ... Arguments passed geom_point.","code":""},{"path":"/reference/gg.SpatialPoints.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for SpatialPoints objects — gg.SpatialPoints","text":"geom_point return value","code":""},{"path":[]},{"path":"/reference/gg.SpatialPoints.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for SpatialPoints objects — gg.SpatialPoints","text":"","code":"# \\donttest{   if (require(ggplot2, quietly = TRUE) &&       require(ggpolypath, quietly = TRUE)) {     # Load Gorilla data      data(\"gorillas\", package = \"inlabru\")      # Plot Gorilla elevation covariate provided as SpatialPixelsDataFrame.     # The same syntax applies to SpatialGridDataFrame objects.      ggplot() +       gg(gorillas$gcov$elevation)      # Add Gorilla survey boundary and nest sightings      ggplot() +       gg(gorillas$gcov$elevation) +       gg(gorillas$boundary) +       gg(gorillas$nests)      # Load pantropical dolphin data      data(\"mexdolphin\")      # Plot the pantropiical survey boundary, ship transects and dolphin sightings      ggplot() +       gg(mexdolphin$ppoly) + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers) + # ship transects as SpatialLines       gg(mexdolphin$points) # dolphin sightings as SpatialPoints      # Change color      ggplot() +       gg(mexdolphin$ppoly, color = \"green\") + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers, color = \"red\") + # ship transects as SpatialLines       gg(mexdolphin$points, color = \"blue\") # dolphin sightings as SpatialPoints       # Visualize data annotations: line width by segment number      names(mexdolphin$samplers) # 'seg' holds the segment number     ggplot() +       gg(mexdolphin$samplers, aes(color = seg))      # Visualize data annotations: point size by dolphin group size      names(mexdolphin$points) # 'size' holds the group size     ggplot() +       gg(mexdolphin$points, aes(size = size))   } #> Regions defined for each Polygons #> Regions defined for each Polygons #> Regions defined for each Polygons  # }"},{"path":"/reference/gg.SpatialPolygons.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for SpatialPolygons objects — gg.SpatialPolygons","title":"Geom for SpatialPolygons objects — gg.SpatialPolygons","text":"Uses ggplot2::fortify() function turn SpatialPolygons objects data.frame. calls geom_polygon plot polygons. Requires ggplot2 package.","code":""},{"path":"/reference/gg.SpatialPolygons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for SpatialPolygons objects — gg.SpatialPolygons","text":"","code":"# S3 method for SpatialPolygons gg(data, mapping = NULL, crs = NULL, ...)"},{"path":"/reference/gg.SpatialPolygons.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for SpatialPolygons objects — gg.SpatialPolygons","text":"data SpatialPolygons SpatialPolygonsDataFrame object. mapping Aesthetic mappings created aes used update default mapping. default mapping ggplot2::aes(x = long, y = lat, group = group). crs CRS object defining coordinate system project data plotting. ... Arguments passed geom_polypath. Unless specified user, arguments colour = \"black\" (polygon colour) alpha = 0.2 (Alpha level polygon filling).","code":""},{"path":"/reference/gg.SpatialPolygons.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for SpatialPolygons objects — gg.SpatialPolygons","text":"ggpolypath::geom_polypath object.","code":""},{"path":"/reference/gg.SpatialPolygons.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Geom for SpatialPolygons objects — gg.SpatialPolygons","text":"Requires ggpolypath package ensure proper plotting, since ggplot::geom_polygon function always handle geometries holes properly.","code":""},{"path":[]},{"path":"/reference/gg.SpatialPolygons.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for SpatialPolygons objects — gg.SpatialPolygons","text":"","code":"# \\donttest{   if (require(ggplot2, quietly = TRUE) &&       require(ggpolypath, quietly = TRUE)) {     # Load Gorilla data      data(\"gorillas\", package = \"inlabru\")      # Plot Gorilla elevation covariate provided as SpatialPixelsDataFrame.     # The same syntax applies to SpatialGridDataFrame objects.      ggplot() +       gg(gorillas$gcov$elevation)      # Add Gorilla survey boundary and nest sightings      ggplot() +       gg(gorillas$gcov$elevation) +       gg(gorillas$boundary) +       gg(gorillas$nests)      # Load pantropical dolphin data      data(\"mexdolphin\")      # Plot the pantropiical survey boundary, ship transects and dolphin sightings      ggplot() +       gg(mexdolphin$ppoly) + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers) + # ship transects as SpatialLines       gg(mexdolphin$points) # dolphin sightings as SpatialPoints      # Change color      ggplot() +       gg(mexdolphin$ppoly, color = \"green\") + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers, color = \"red\") + # ship transects as SpatialLines       gg(mexdolphin$points, color = \"blue\") # dolphin sightings as SpatialPoints       # Visualize data annotations: line width by segment number      names(mexdolphin$samplers) # 'seg' holds the segment number     ggplot() +       gg(mexdolphin$samplers, aes(color = seg))      # Visualize data annotations: point size by dolphin group size      names(mexdolphin$points) # 'size' holds the group size     ggplot() +       gg(mexdolphin$points, aes(size = size))   } #> Regions defined for each Polygons #> Regions defined for each Polygons #> Regions defined for each Polygons  # }"},{"path":"/reference/gg.data.frame.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for data.frame — gg.data.frame","title":"Geom for data.frame — gg.data.frame","text":"geom constructor simply call gg.prediction data provided.","code":""},{"path":"/reference/gg.data.frame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for data.frame — gg.data.frame","text":"","code":"# S3 method for data.frame gg(...)"},{"path":"/reference/gg.data.frame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for data.frame — gg.data.frame","text":"... Arguments passed gg.prediction().","code":""},{"path":"/reference/gg.data.frame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for data.frame — gg.data.frame","text":"Concatenation geom_line value optionally geom_ribbon value.","code":""},{"path":"/reference/gg.data.frame.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Geom for data.frame — gg.data.frame","text":"Requires ggplot2 package.","code":""},{"path":[]},{"path":"/reference/gg.data.frame.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for data.frame — gg.data.frame","text":"","code":"# \\donttest{ if (bru_safe_inla() && require(ggplot2, quietly = TRUE)) {   # Generate some data    input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, y <- 5 + 2 * cos(1:10) + rnorm(10, mean = 0, sd = 0.1))    # Fit a model with fixed effect 'x' and intercept 'Intercept'    fit <- bru(y ~ x, family = \"gaussian\", data = input.df)    # Predict posterior statistics of 'x'    xpost <- predict(fit, data = NULL, formula = ~x_latent)    # The statistics include mean, standard deviation, the 2.5% quantile, the median,   # the 97.5% quantile, minimum and maximum sample drawn from the posterior as well as   # the coefficient of variation and the variance.    xpost    # For a single variable like 'x' the default plotting method invoked by gg() will   # show these statisics in a fashion similar to a box plot:   ggplot() +     gg(xpost)     # The predict function can also be used to simulataneously estimate posteriors   # of multiple variables:    xipost <- predict(fit,     data = NULL,     formula = ~ c(       Intercept = Intercept_latent,       x = x_latent     )   )   xipost    # If we still want a plot in the previous style we have to set the bar parameter to TRUE    p1 <- ggplot() +     gg(xipost, bar = TRUE)   p1    # Note that gg also understands the posterior estimates generated while running INLA    p2 <- ggplot() +     gg(fit$summary.fixed, bar = TRUE)   multiplot(p1, p2)    # By default, if the prediction has more than one row, gg will plot the column 'mean' against   # the row index. This is for instance usefuul for predicting and plotting function   # but not very meaningful given the above example:    ggplot() +     gg(xipost)    # For ease of use we can also type    plot(xipost)    # This type of plot will show a ribbon around the mean, which viszualizes the upper and lower   # quantiles mentioned above (2.5 and 97.5%). Plotting the ribbon can be turned of using the   # \\code{ribbon} parameter    ggplot() +     gg(xipost, ribbon = FALSE)    # Much like the other geomes produced by gg we can adjust the plot using ggplot2 style   # commands, for instance    ggplot() +     gg(xipost) +     gg(xipost, mapping = aes(y = median), ribbon = FALSE, color = \"red\") }   # }"},{"path":"/reference/gg.html","id":null,"dir":"Reference","previous_headings":"","what":"ggplot2 geomes for inlabru related objects — gg","title":"ggplot2 geomes for inlabru related objects — gg","text":"gg generic function generating geomes various kinds spatial objects, e.g. Spatial* data, meshes, Raster objects inla/inlabru predictions. function invokes particular methods depend class first argument.","code":""},{"path":"/reference/gg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ggplot2 geomes for inlabru related objects — gg","text":"","code":"gg(data, ...)"},{"path":"/reference/gg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ggplot2 geomes for inlabru related objects — gg","text":"data object generate geom. ... Arguments passed geom method.","code":""},{"path":"/reference/gg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ggplot2 geomes for inlabru related objects — gg","text":"form value returned gg depends class argument. See documentation particular methods details produced method.","code":""},{"path":[]},{"path":"/reference/gg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ggplot2 geomes for inlabru related objects — gg","text":"","code":"if (require(\"ggplot2\", quietly = TRUE) &&   require(ggpolypath, quietly = TRUE)) {   # Load Gorilla data    data(gorillas, package = \"inlabru\")    # Invoke ggplot and add geomes for the Gorilla nests and the survey boundary    ggplot() +     gg(gorillas$boundary) +     gg(gorillas$nests) } #> Regions defined for each Polygons"},{"path":"/reference/gg.inla.mesh.1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for inla.mesh.1d objects — gg.inla.mesh.1d","title":"Geom for inla.mesh.1d objects — gg.inla.mesh.1d","text":"function generates geom_point object showing knots (vertices) 1D mesh. Requires ggplot2 package.","code":""},{"path":"/reference/gg.inla.mesh.1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for inla.mesh.1d objects — gg.inla.mesh.1d","text":"","code":"# S3 method for inla.mesh.1d gg(   data,   mapping = ggplot2::aes(.data[[\"x\"]], .data[[\"y\"]]),   y = 0,   shape = 4,   ... )"},{"path":"/reference/gg.inla.mesh.1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for inla.mesh.1d objects — gg.inla.mesh.1d","text":"data inla.mesh.1d object. mapping aesthetic mappings created aes. passed geom_point. y Single vector numeric defining y-coordinates mesh knots plot. shape Shape knot markers. ... parameters passed geom_point.","code":""},{"path":"/reference/gg.inla.mesh.1d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for inla.mesh.1d objects — gg.inla.mesh.1d","text":"object generated geom_point.","code":""},{"path":[]},{"path":"/reference/gg.inla.mesh.1d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for inla.mesh.1d objects — gg.inla.mesh.1d","text":"","code":"# \\donttest{ # Some features use the INLA package. if (require(\"INLA\", quietly = TRUE) &&   require(\"ggplot2\", quietly = TRUE)) {    # Create a 1D mesh    mesh <- inla.mesh.1d(seq(0, 10, by = 0.5))    # Plot it    ggplot() +     gg(mesh)    # Plot it using a different shape and size for the mesh nodes    ggplot() +     gg(mesh, shape = \"|\", size = 5) }  # }"},{"path":"/reference/gg.inla.mesh.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for inla.mesh objects — gg.inla.mesh","title":"Geom for inla.mesh objects — gg.inla.mesh","text":"function extracts graph inla.mesh object uses geom_line visualize graph's edges. Alternatively, color argument provided, interpolates colors across set SpatialPixels covering mesh area calls gg.SpatialPixelsDataFrame() plot interpolation. Requires ggplot2 package.","code":""},{"path":"/reference/gg.inla.mesh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for inla.mesh objects — gg.inla.mesh","text":"","code":"# S3 method for inla.mesh gg(   data,   color = NULL,   alpha = NULL,   edge.color = \"grey\",   interior = TRUE,   int.color = \"blue\",   exterior = TRUE,   ext.color = \"black\",   crs = NULL,   mask = NULL,   nx = 500,   ny = 500,   ... )"},{"path":"/reference/gg.inla.mesh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for inla.mesh objects — gg.inla.mesh","text":"data INLA::inla.mesh object. color vector scalar values fill mesh colors. length vector mus correspond number mesh vertices. alternative name colour also recognised. alpha vector scalar values setting alpha value colors provided. edge.color Color mesh edges. interior TRUE, plot interior boundaries mesh. int.color Color used plot interior boundaries. exterior TRUE, plot exterior boundaries mesh. ext.color Color used plot interior boundaries. crs CRS object defining coordinate system project mesh plotting. mask SpatialPolygon defining region plotted. nx Number pixels x direction (plotting using color parameter). ny Number pixels y direction (plotting using color parameter). ... ignored arguments (S3 generic compatibility).","code":""},{"path":"/reference/gg.inla.mesh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for inla.mesh objects — gg.inla.mesh","text":"geom_line return values , color argument used, values gg.SpatialPixelsDataFrame().","code":""},{"path":[]},{"path":"/reference/gg.inla.mesh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for inla.mesh objects — gg.inla.mesh","text":"","code":"# \\donttest{ if (bru_safe_inla() &&     require(ggplot2, quietly = TRUE) &&     require(ggpolypath, quietly = TRUE)) {    # Load Gorilla data   data(\"gorillas\", package = \"inlabru\")    # Plot mesh using default edge colors    ggplot() +     gg(gorillas$mesh)    # Don't show interior and exterior boundaries    ggplot() +     gg(gorillas$mesh, interior = FALSE, exterior = FALSE)    # Change the edge colors    ggplot() +     gg(gorillas$mesh,       edge.color = \"green\",       int.color = \"black\",       ext.color = \"blue\"     )    # Use the x-coordinate of the vertices to colorize the triangles and   # mask the plotted area by the survey boundary, i.e. only plot the inside    xcoord <- gorillas$mesh$loc[, 1]   ggplot() +     gg(gorillas$mesh, color = (xcoord - 580), mask = gorillas$boundary) +     gg(gorillas$boundary) } #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Regions defined for each Polygons  # }"},{"path":"/reference/gg.matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for matrix — gg.matrix","title":"Geom for matrix — gg.matrix","text":"Creates tile geom plotting matrix","code":""},{"path":"/reference/gg.matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for matrix — gg.matrix","text":"","code":"# S3 method for matrix gg(data, mapping = NULL, ...)"},{"path":"/reference/gg.matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for matrix — gg.matrix","text":"data matrix object. mapping set aesthetic mappings created aes. passed geom_tile. ... Arguments passed geom_tile.","code":""},{"path":"/reference/gg.matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for matrix — gg.matrix","text":"geom_tile reversed y scale.","code":""},{"path":"/reference/gg.matrix.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Geom for matrix — gg.matrix","text":"Requires ggplot2 package.","code":""},{"path":[]},{"path":"/reference/gg.matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for matrix — gg.matrix","text":"","code":"if (require(\"ggplot2\", quietly = TRUE)) {   A <- matrix(runif(100), nrow = 10)   ggplot() +     gg(A) }"},{"path":"/reference/gg.prediction.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for predictions — gg.prediction","title":"Geom for predictions — gg.prediction","text":"geom serves visualize prediction objects usually results call predict.bru(). Predictions objects provide summary statistics (mean, median, sd, ...) one random variables. single variables (requested setting bar = TRUE), boxplot-style geom constructed show statistics. multivariate predictions mean variable (y-axis) plotted agains row number varriable prediction data frame (x-axis) using geom_line. addition, geom_ribbon used show confidence interval. Note: gg.prediction also understands format INLA-style posterior summaries, e.g. fit$summary.fixed inla object fit Requires ggplot2 package.","code":""},{"path":"/reference/gg.prediction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for predictions — gg.prediction","text":"","code":"# S3 method for prediction gg(data, mapping = NULL, ribbon = TRUE, alpha = 0.3, bar = FALSE, ...)"},{"path":"/reference/gg.prediction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for predictions — gg.prediction","text":"data prediction object, usually result predict.bru() call. mapping set aesthetic mappings created aes. passed geom_line. ribbon TRUE, plot ribbon around line based smalles largest quantiles present data, found matching names starting q followed numerical value.  inla()-style numeric+\"quant\" names converted inlabru style matching. alpha ribbons numeric alpha (transparency) level [0,1]. bar TRUE plot boxplot-style summary variable. ... Arguments passed geom_line.","code":""},{"path":"/reference/gg.prediction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for predictions — gg.prediction","text":"Concatenation geom_line value optionally geom_ribbon value.","code":""},{"path":[]},{"path":"/reference/gg.prediction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for predictions — gg.prediction","text":"","code":"# \\donttest{ if (bru_safe_inla() && require(ggplot2, quietly = TRUE)) {   # Generate some data    input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, y <- 5 + 2 * cos(1:10) + rnorm(10, mean = 0, sd = 0.1))    # Fit a model with fixed effect 'x' and intercept 'Intercept'    fit <- bru(y ~ x, family = \"gaussian\", data = input.df)    # Predict posterior statistics of 'x'    xpost <- predict(fit, data = NULL, formula = ~x_latent)    # The statistics include mean, standard deviation, the 2.5% quantile, the median,   # the 97.5% quantile, minimum and maximum sample drawn from the posterior as well as   # the coefficient of variation and the variance.    xpost    # For a single variable like 'x' the default plotting method invoked by gg() will   # show these statisics in a fashion similar to a box plot:   ggplot() +     gg(xpost)     # The predict function can also be used to simulataneously estimate posteriors   # of multiple variables:    xipost <- predict(fit,     data = NULL,     formula = ~ c(       Intercept = Intercept_latent,       x = x_latent     )   )   xipost    # If we still want a plot in the previous style we have to set the bar parameter to TRUE    p1 <- ggplot() +     gg(xipost, bar = TRUE)   p1    # Note that gg also understands the posterior estimates generated while running INLA    p2 <- ggplot() +     gg(fit$summary.fixed, bar = TRUE)   multiplot(p1, p2)    # By default, if the prediction has more than one row, gg will plot the column 'mean' against   # the row index. This is for instance usefuul for predicting and plotting function   # but not very meaningful given the above example:    ggplot() +     gg(xipost)    # For ease of use we can also type    plot(xipost)    # This type of plot will show a ribbon around the mean, which viszualizes the upper and lower   # quantiles mentioned above (2.5 and 97.5%). Plotting the ribbon can be turned of using the   # \\code{ribbon} parameter    ggplot() +     gg(xipost, ribbon = FALSE)    # Much like the other geomes produced by gg we can adjust the plot using ggplot2 style   # commands, for instance    ggplot() +     gg(xipost) +     gg(xipost, mapping = aes(y = median), ribbon = FALSE, color = \"red\") }   # }"},{"path":"/reference/globe.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a globe using rgl — globe","title":"Plot a globe using rgl — globe","text":"Creates textured sphere lon/lat coordinate annotations.","code":""},{"path":"/reference/globe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a globe using rgl — globe","text":"","code":"globe(   R = 1,   R.grid = 1.05,   specular = \"black\",   axes = FALSE,   box = FALSE,   xlab = \"\",   ylab = \"\",   zlab = \"\" )"},{"path":"/reference/globe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a globe using rgl — globe","text":"R Radius globe R.grid Radius annotation sphere. specular Light color specular effect. axes TRUE, plot x, y z axes. box TRUE, plot box around globe. xlab, ylab, zlab Axes labels","code":""},{"path":"/reference/globe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a globe using rgl — globe","text":"value, used plotting side effect.","code":""},{"path":"/reference/globe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot a globe using rgl — globe","text":"funciton requires rgl sphereplot packages.","code":""},{"path":[]},{"path":"/reference/globe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a globe using rgl — globe","text":"","code":"if (FALSE) { if (bru_safe_inla() &&   require(\"rgl\", quietly = TRUE) &&   require(\"sphereplot\", quietly = TRUE)) {    # Load pantropoical dolphin data    data(\"mexdolphin\", package = \"inlabru\")    # Show the globe    globe()    # Add mesh, ship transects and dolphin sightings stored   # as inla.mesh, SpatialLines and SpatialPoints objects, respectively    glplot(mexdolphin$mesh)   glplot(mexdolphin$samplers)   glplot(mexdolphin$points) } }"},{"path":"/reference/glplot.SpatialLines.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize SpatialLines using RGL — glplot.SpatialLines","title":"Visualize SpatialLines using RGL — glplot.SpatialLines","text":"function calculate cartesian representation lines provided use rgl.linestrip() order render .","code":""},{"path":"/reference/glplot.SpatialLines.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize SpatialLines using RGL — glplot.SpatialLines","text":"","code":"# S3 method for SpatialLines glplot(object, add = TRUE, ...)"},{"path":"/reference/glplot.SpatialLines.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize SpatialLines using RGL — glplot.SpatialLines","text":"object SpatialLines SpatialLinesDataFrame object. add TRUE, add lines existing plot. FALSE, create new plot. ... Parameters passed rgl.linestrips().","code":""},{"path":[]},{"path":"/reference/glplot.SpatialLines.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize SpatialLines using RGL — glplot.SpatialLines","text":"","code":"if (FALSE) { if (bru_safe_inla() &&   require(\"rgl\", quietly = TRUE) &&   require(\"sphereplot\", quietly = TRUE)) {    # Load pantropoical dolphin data    data(\"mexdolphin\", package = \"inlabru\")    # Show the globe    globe()    # Add mesh, ship transects and dolphin sightings stored   # as inla.mesh, SpatialLines and SpatialPoints objects, respectively    glplot(mexdolphin$mesh)   glplot(mexdolphin$samplers)   glplot(mexdolphin$points) } }"},{"path":"/reference/glplot.SpatialPoints.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize SpatialPoints using RGL — glplot.SpatialPoints","title":"Visualize SpatialPoints using RGL — glplot.SpatialPoints","text":"function calculate cartesian coordinates points provided use rgl.points() order render .","code":""},{"path":"/reference/glplot.SpatialPoints.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize SpatialPoints using RGL — glplot.SpatialPoints","text":"","code":"# S3 method for SpatialPoints glplot(object, add = TRUE, color = \"red\", ...)"},{"path":"/reference/glplot.SpatialPoints.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize SpatialPoints using RGL — glplot.SpatialPoints","text":"object SpatialPoints SpatialPointsDataFrame object. add TRUE, add points existing plot. FALSE, create new plot. color vector R color characters. See rgl.material() details. ... Parameters passed rgl.points()","code":""},{"path":[]},{"path":"/reference/glplot.SpatialPoints.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize SpatialPoints using RGL — glplot.SpatialPoints","text":"","code":"if (FALSE) { if (bru_safe_inla() &&   require(\"rgl\", quietly = TRUE) &&   require(\"sphereplot\", quietly = TRUE)) {    # Load pantropoical dolphin data    data(\"mexdolphin\", package = \"inlabru\")    # Show the globe    globe()    # Add mesh, ship transects and dolphin sightings stored   # as inla.mesh, SpatialLines and SpatialPoints objects, respectively    glplot(mexdolphin$mesh)   glplot(mexdolphin$samplers)   glplot(mexdolphin$points) } }"},{"path":"/reference/glplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Render Spatial* and inla.mesh objects using RGL — glplot","title":"Render Spatial* and inla.mesh objects using RGL — glplot","text":"glplot generic function renders various kinds spatial objects, .e. Spatial* data inla.mesh objects. function invokes particular methods depend class first argument.","code":""},{"path":"/reference/glplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Render Spatial* and inla.mesh objects using RGL — glplot","text":"","code":"glplot(object, ...)"},{"path":"/reference/glplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Render Spatial* and inla.mesh objects using RGL — glplot","text":"object object used select method. ... arguments passed methods.","code":""},{"path":[]},{"path":"/reference/glplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Render Spatial* and inla.mesh objects using RGL — glplot","text":"","code":"if (FALSE) { if (bru_safe_inla() &&   require(\"rgl\", quietly = TRUE) &&   require(\"sphereplot\", quietly = TRUE)) {    # Load pantropoical dolphin data    data(\"mexdolphin\", package = \"inlabru\")    # Show the globe    globe()    # Add mesh, ship transects and dolphin sightings stored   # as inla.mesh, SpatialLines and SpatialPoints objects, respectively    glplot(mexdolphin$mesh)   glplot(mexdolphin$samplers)   glplot(mexdolphin$points) } }"},{"path":"/reference/glplot.inla.mesh.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize SpatialPoints using RGL — glplot.inla.mesh","title":"Visualize SpatialPoints using RGL — glplot.inla.mesh","text":"function transforms mesh 3D cartesian coordinates uses inla.plot.mesh() rgl=TRUE plot result.","code":""},{"path":"/reference/glplot.inla.mesh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize SpatialPoints using RGL — glplot.inla.mesh","text":"","code":"# S3 method for inla.mesh glplot(object, add = TRUE, col = NULL, ...)"},{"path":"/reference/glplot.inla.mesh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize SpatialPoints using RGL — glplot.inla.mesh","text":"object inla.mesh object. add TRUE, add lines existing plot. FALSE, create new plot. col Color specification. single named color, vector scalar values, matrix RGB values. ... Parameters passed plot.inla.mesh()","code":""},{"path":[]},{"path":"/reference/glplot.inla.mesh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize SpatialPoints using RGL — glplot.inla.mesh","text":"","code":"if (FALSE) { if (bru_safe_inla() &&   require(\"rgl\", quietly = TRUE) &&   require(\"sphereplot\", quietly = TRUE)) {    # Load pantropoical dolphin data    data(\"mexdolphin\", package = \"inlabru\")    # Show the globe    globe()    # Add mesh, ship transects and dolphin sightings stored   # as inla.mesh, SpatialLines and SpatialPoints objects, respectively    glplot(mexdolphin$mesh)   glplot(mexdolphin$samplers)   glplot(mexdolphin$points) } }"},{"path":"/reference/gm.html","id":null,"dir":"Reference","previous_headings":"","what":"ggplot geom for spatial data — gm","title":"ggplot geom for spatial data — gm","text":"gm wrapper gg method. take first argument transform coordinate system latitude longitude. Thereafter, gg called using transformed data arguments provided via .... gm intended replace gg whenever data supposed plotted spatial map generated gmap, works coordinate system latitude/longitude.","code":""},{"path":"/reference/gm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ggplot geom for spatial data — gm","text":"","code":"gm(data, ...)"},{"path":"/reference/gm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ggplot geom for spatial data — gm","text":"data object generate geom. ... Arguments passed gg().","code":""},{"path":"/reference/gm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ggplot geom for spatial data — gm","text":"form value returned gm depends class argument. See documentation particular methods details produced method.","code":""},{"path":[]},{"path":"/reference/gm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ggplot geom for spatial data — gm","text":"","code":"if (FALSE) { if (require(\"ggplot2\", quietly = TRUE) &&   require(ggpolypath, quietly = TRUE)) {   # Load the Gorilla data   data(gorillas, package = \"inlabru\")    # Create a base map centered around the nests and plot the boundary as well as the nests   gmap(gorillas$nests, maptype = \"satellite\") +     gm(gorillas$boundary) +     gm(gorillas$nests, color = \"white\", size = 0.5) } }"},{"path":"/reference/gmap.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a map using extend of a spatial object — gmap","title":"Plot a map using extend of a spatial object — gmap","text":"Uses get_map() query map services like Google Maps region centered around spatial object provided. calls ggmap() plot map.","code":""},{"path":"/reference/gmap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a map using extend of a spatial object — gmap","text":"","code":"gmap(data, ...)"},{"path":"/reference/gmap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a map using extend of a spatial object — gmap","text":"data Spatial* object. ... Arguments passed get_map().","code":""},{"path":"/reference/gmap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a map using extend of a spatial object — gmap","text":"ggplot object","code":""},{"path":"/reference/gmap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot a map using extend of a spatial object — gmap","text":"function requires ggmap package.","code":""},{"path":"/reference/gmap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a map using extend of a spatial object — gmap","text":"","code":"if (FALSE) { if (require(\"ggplot2\", quietly = TRUE) &&   require(ggpolypath, quietly = TRUE)) {   # Load the Gorilla data   data(gorillas, package = \"inlabru\")    # Create a base map centered around the nests and plot the boundary as well   # as the nests   ggplot() +     gg(gorillas$boundary) +     gg(gorillas$nests, color = \"white\", size = 0.5)   if (requireNamespace(\"ggmap\", quietly = TRUE)) {     gmap(gorillas$nests, maptype = \"satellite\") +       gm(gorillas$boundary) +       gm(gorillas$nests, color = \"white\", size = 0.5)   } } }"},{"path":"/reference/gorillas.html","id":null,"dir":"Reference","previous_headings":"","what":"Gorilla nesting sites — gorillas","title":"Gorilla nesting sites — gorillas","text":"gorillas dataset package spatstat.data, reformatted point process data use inlabru.","code":""},{"path":"/reference/gorillas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gorilla nesting sites — gorillas","text":"","code":"data(gorillas)"},{"path":"/reference/gorillas.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Gorilla nesting sites — gorillas","text":"data list contains elements: nests: SpatialPointsDataFrame object containing locations gorilla nests. boundary: SpatialPolygonsDataFrame object defining boundary region searched nests. mesh: inla.mesh object containing mesh can used function lgcp fit LGCP nest data. gcov: list SpatialGridDataFrame objects, one spatial covariates: aspect Compass direction terrain slope. Categorical, levels N, NE, E, SE, S, SW, W NW, coded integers 1 8. elevation Digital elevation terrain, metres. heat Heat Load Index point surface (Beer's aspect), discretised. Categorical values Warmest (Beer's aspect 0 0.999), Moderate (Beer's aspect 1 1.999), Coolest (Beer's aspect equals 2). coded integers 1, 2 3, order. slopangle Terrain slope, degrees. slopetype Type slope. Categorical, values Valley, Toe (toe slope), Flat, Midslope, Upper Ridge. coded integers 1 6. vegetation Vegetation type: categorical variable 6 levels coded integers 1 6 (order increasing expected habitat suitability) waterdist Euclidean distance nearest water body, metres. plotsample Plot sample gorilla nests, sampling 9x9 region, 60\\ counts SpatialPointsDataFrame frame elements x, y, count, exposure, x- y-coordinates centre plot, count plot area plot. plots SpatialPolygonsDataFrame defining individual plot boundaries. nests SpatialPointsDataFrame giving locations detected nest.","code":""},{"path":"/reference/gorillas.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Gorilla nesting sites — gorillas","text":"Library spatstat.data.","code":""},{"path":"/reference/gorillas.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Gorilla nesting sites — gorillas","text":"Funwi-Gabga, N. (2008) pastoralist survey fire impact assessment Kagwene Gorilla Sanctuary, Cameroon. M.Sc. thesis, Geology Environmental Science, University Buea, Cameroon. Funwi-Gabga, N. Mateu, J. (2012) Understanding nesting spatial behaviour gorillas Kagwene Sanctuary, Cameroon. Stochastic Environmental Research Risk Assessment 26 (6), 793-811.","code":""},{"path":"/reference/gorillas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gorilla nesting sites — gorillas","text":"","code":"if (bru_safe_inla() &&   require(ggplot2, quietly = TRUE) &&   require(ggpolypath, quietly = TRUE)) {   data(gorillas, package = \"inlabru\") # get the data    # plot all the nests, mesh and boundary   ggplot() +     gg(gorillas$mesh) +     gg(gorillas$boundary) +     gg(gorillas$nests)    # Plot the elevation covariate   plot(gorillas$gcov$elevation)    # Plot the plot sample   ggplot() +     gg(gorillas$plotsample$plots) +     gg(gorillas$plotsample$nests) } #> Regions defined for each Polygons #> Regions defined for each Polygons"},{"path":"/reference/iinla.html","id":null,"dir":"Reference","previous_headings":"","what":"Iterated INLA — iinla","title":"Iterated INLA — iinla","text":"internal wrapper iterated runs INLA::inla. nonlinear models, linearisation done bru_compute_linearisation, line search method iteration. INLA::inla.stack information setup bru_make_stack().","code":""},{"path":"/reference/iinla.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Iterated INLA — iinla","text":"","code":"iinla(model, lhoods, initial = NULL, options)"},{"path":"/reference/iinla.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Iterated INLA — iinla","text":"model bru_model object lhoods list likelihood objects like() initial previous bru result list named latent variable initial states (missing elements set zero), used starting point, NULL. non-null, overrides options$bru_initial options bru_options object. data data.frame","code":""},{"path":"/reference/iinla.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Iterated INLA — iinla","text":"iinla object inherits INLA::inla, added field bru_iinla elements log diagnostic log messages produced run states list linearisation points, one inla run inla_stack inla.stack object final inla run track list convergence tracking vectors inla run aborted error, returned object also contains element error error object.","code":""},{"path":"/reference/import.gorillas.html","id":null,"dir":"Reference","previous_headings":"","what":"Gorilla data import — import.gorillas","title":"Gorilla data import — import.gorillas","text":"Gorilla data import","code":""},{"path":"/reference/import.gorillas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gorilla data import — import.gorillas","text":"","code":"import.gorillas()"},{"path":"/reference/import.gorillas.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gorilla data import — import.gorillas","text":"gorilla data Turn observation window spatial polygon Build mesh Turn covariates int SpatialGridDataFrame Hack: change CRS units covariates km","code":""},{"path":"/reference/import.gorillas.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Gorilla data import — import.gorillas","text":"Fabian E. Bachl bachlfab@gmail.com, David L. Borchers dlb@st-andrews.ac.uk","code":""},{"path":"/reference/import.mexdolphin.html","id":null,"dir":"Reference","previous_headings":"","what":"Mexdolphin data import — import.mexdolphin","title":"Mexdolphin data import — import.mexdolphin","text":"Load mexdolphins survey data dsm package convert spatial formats defined sp package.","code":""},{"path":"/reference/import.mexdolphin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mexdolphin data import — import.mexdolphin","text":"","code":"import.mexdolphin()"},{"path":"/reference/import.mexdolphin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mexdolphin data import — import.mexdolphin","text":"mexdolphin data set","code":""},{"path":"/reference/import.mexdolphin.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Mexdolphin data import — import.mexdolphin","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"/reference/import.mexdolphin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mexdolphin data import — import.mexdolphin","text":"","code":"if (FALSE) { mexdolphin <- import.mexdolphin() }"},{"path":"/reference/import.mrsea.html","id":null,"dir":"Reference","previous_headings":"","what":"MRSea data import — import.mrsea","title":"MRSea data import — import.mrsea","text":"Load mrsea survey data MRSea package convert spatial formats defined sp package. Requires MRSea package https://github.com/lindesaysh/MRSea, normally run package maintainer. regular inlabru use data, use data(\"MRSea\", package = \"inlabru\"), require MRSea package.","code":""},{"path":"/reference/import.mrsea.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MRSea data import — import.mrsea","text":"","code":"import.mrsea()"},{"path":"/reference/import.mrsea.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MRSea data import — import.mrsea","text":"mrsea data set","code":""},{"path":"/reference/import.mrsea.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"MRSea data import — import.mrsea","text":"Lindesay Scott-Hayward lass@st-andrews.ac.uk","code":""},{"path":"/reference/import.mrsea.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MRSea data import — import.mrsea","text":"","code":"if (FALSE) { mrsea <- import.mrsea() }"},{"path":"/reference/import.seals.html","id":null,"dir":"Reference","previous_headings":"","what":"Seal pup edata import — import.seals","title":"Seal pup edata import — import.seals","text":"Generate Spatial objects raw seal pup survey data (inlcuded inlabru). Note function extract one survey transects.","code":""},{"path":"/reference/import.seals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Seal pup edata import — import.seals","text":"","code":"import.seals(   sealfile = \"WestIce2012.csv\",   icefile = \"reflectance_0.0025deg_grid_modis_20120328_1310.tif\" )"},{"path":"/reference/import.seals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Seal pup edata import — import.seals","text":"sealfile Character pointing file containing seal counts photo locations icefile Character pointing .tif file containing ice sheet covariate","code":""},{"path":"/reference/import.seals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Seal pup edata import — import.seals","text":"seals data set","code":""},{"path":"/reference/import.seals.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Seal pup edata import — import.seals","text":"Fabian E. Bachl bachlfab@gmail.com Load seal data Turn seal data spatial object avoid confusion remove x-y coordinates created Martin Change CRS Select strip Add total number seals Build mesh. mesh fine photo locations coarse elsewhere plot observed counts Ice Covariate Interpolate ice covariate Add band1 covariate seals data frame Plot seal count ice together Create data set","code":""},{"path":"/reference/import.shrimp.html","id":null,"dir":"Reference","previous_headings":"","what":"Shrimp data import — import.shrimp","title":"Shrimp data import — import.shrimp","text":"Load shrimp data stored file gamba.Rdata construct spatial object","code":""},{"path":"/reference/import.shrimp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shrimp data import — import.shrimp","text":"","code":"import.shrimp()"},{"path":"/reference/import.shrimp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Shrimp data import — import.shrimp","text":"shrimp data set","code":""},{"path":"/reference/import.shrimp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Shrimp data import — import.shrimp","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"/reference/index_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain indices — index_eval","title":"Obtain indices — index_eval","text":"Indexes components","code":""},{"path":"/reference/index_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain indices — index_eval","text":"","code":"index_eval(...)  # S3 method for component index_eval(component, inla_f, ...)  # S3 method for component_list index_eval(components, inla_f, ...)"},{"path":"/reference/index_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain indices — index_eval","text":"... Unused. component component. inla_f logical; TRUE, must result values compatible INLA::f(...) specification corresponding INLA::inla.stack(...) constructions.","code":""},{"path":"/reference/index_eval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain indices — index_eval","text":"list indices latent variables compatible component mapper.","code":""},{"path":"/reference/index_eval.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Obtain indices — index_eval","text":"Fabian E. Bachl bachlfab@gmail.com, Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"/reference/inla.stack.mjoin.html","id":null,"dir":"Reference","previous_headings":"","what":"Join stacks intended to be run with different likelihoods — inla.stack.mjoin","title":"Join stacks intended to be run with different likelihoods — inla.stack.mjoin","text":"Join stacks intended run different likelihoods","code":""},{"path":"/reference/inla.stack.mjoin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Join stacks intended to be run with different likelihoods — inla.stack.mjoin","text":"","code":"inla.stack.mjoin(   ...,   compress = TRUE,   remove.unused = TRUE,   old.names = \"BRU.response\",   new.name = \"BRU.response\" )"},{"path":"/reference/inla.stack.mjoin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Join stacks intended to be run with different likelihoods — inla.stack.mjoin","text":"... List stacks contain vector observations (existing multi-likelihood observation matrices also permitted) compress TRUE, compress model removing duplicated rows effects, replacing corresponding -matrix columns single column containing sum. remove.unused TRUE, compress model removing rows effects corresponding -zero columns matrix (removing columns). old.names vector strings names observation vector/matrix stack. single string, assumed stacks. (default \"BRU.response\") new.name name used expanded observation matrix, possibly old name. (default \"BRU.response\")","code":""},{"path":"/reference/inla_subset_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain inla index subset information — inla_subset_eval","title":"Obtain inla index subset information — inla_subset_eval","text":"Subsets INLA::f() compatible indexing","code":""},{"path":"/reference/inla_subset_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain inla index subset information — inla_subset_eval","text":"","code":"inla_subset_eval(...)  # S3 method for component_list inla_subset_eval(components, ...)"},{"path":"/reference/inla_subset_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain inla index subset information — inla_subset_eval","text":"... Unused. components component list.","code":""},{"path":"/reference/inla_subset_eval.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Obtain inla index subset information — inla_subset_eval","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"/reference/inlabru-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Deprecated functions in inlabru — summary_bru","title":"Deprecated functions in inlabru — summary_bru","text":"functions still attempt job, removed future version.","code":""},{"path":"/reference/inlabru-deprecated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deprecated functions in inlabru — summary_bru","text":"","code":"summary_bru(object, ...)  iinla.getOption(name = NULL)  iinla.setOption(...)  init.tutorial()"},{"path":"/reference/inlabru-deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deprecated functions in inlabru — summary_bru","text":"object object obtained bru() lgcp() call ... arguments passed methods ignored name character; option name","code":""},{"path":"/reference/inlabru-deprecated.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Deprecated functions in inlabru — summary_bru","text":"summary_bru(): Old summary inlabru fit. Takes fitted bru object produced bru() lgcp() creates various summaries . iinla.getOption(): Use bru_option_get instead. iinla.setOption(): Use bru_option_set instead. init.tutorial(): Global setting tutorial sessions. Use bru_options_set() set specific options instead instead.  versions <= 2.1.15, function set INLA integration strategy \"eb\" speed calculations. normally needed since version 2.2.0, since final iteration use \"eb\".","code":""},{"path":"/reference/inlabru-deprecated.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Deprecated functions in inlabru — summary_bru","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"/reference/inlabru-deprecated.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Deprecated functions in inlabru — summary_bru","text":"","code":"if (FALSE) { # Note: Only run this if you want to change the inlabru options for this session  # Determine current bru defaults: bo <- bru_options_get()  init.tutorial()  # Check if it worked: bru_options_get(\"control.inla\") }"},{"path":"/reference/inlabru.html","id":null,"dir":"Reference","previous_headings":"","what":"inlabru — inlabru","title":"inlabru — inlabru","text":"Convenient model fitting using (iterated) INLA.","code":""},{"path":"/reference/inlabru.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"inlabru — inlabru","text":"inlabru facilitates Bayesian spatial modelling using integrated nested Laplace approximations. heavily based R-inla (https://www.r-inla.org) adds additional modelling abilities simplified syntax (particular) spatial models. Tutorials information can found https://inlabru-org.github.io/inlabru/ http://www.inlabru.org/. iterative method used non-linear predictors documented method vignette. main function inference using inlabru bru(). point process inference lgcp() good starting point. general model specification details documented component() like(). Posterior quantities beyond basic summaries can calculated predict() method, documented predict.bru(). package comes multiple real world data sets, namely gorillas, mexdolphin, seals. Plotting data sets straight forward using inlabru's extensions ggplot2, e.g. gg() function. educational purposes simulated data sets available well, e.g. Poisson1_1D, Poisson2_1D, Poisson2_1D toygroups.","code":""},{"path":"/reference/inlabru.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"inlabru — inlabru","text":"Fabian E. Bachl bachlfab@gmail.com Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"/reference/input_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain covariate values — input_eval","title":"Obtain covariate values — input_eval","text":"Obtain covariate values","code":""},{"path":"/reference/input_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain covariate values — input_eval","text":"","code":"input_eval(...)  # S3 method for component input_eval(component, data, ...)  # S3 method for component_list input_eval(components, data, ...)  # S3 method for bru_input input_eval(input, data, env = NULL, label = NULL, null.on.fail = FALSE, ...)"},{"path":"/reference/input_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain covariate values — input_eval","text":"... Unused. component component. data data.frame Spatial* object covariates /point locations. null, return component's map.","code":""},{"path":"/reference/input_eval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain covariate values — input_eval","text":"vector coordinate matrix","code":""},{"path":"/reference/input_eval.html","id":"simple-covariates-and-the-map-parameter","dir":"Reference","previous_headings":"","what":"Simple covariates and the map parameter","title":"Obtain covariate values — input_eval","text":"unusual random effect act transformation covariate. frameworks mean transformed covariate calculated advance added data frame usually provided via data parameter. inlabru provides option transformation automatically. instance, one might interested effect covariate \\(x^2\\). inla frameworks require add column xsquared input data frame use formula formula = y ~ f(xsquared, model = \"linear\"), inlabru can achived using two ways using main parameter (map version 2.1.13 earlier). components = y ~ psi(main = x^2, model = \"linear\") components = y ~ psi(main = mySquareFun(x), model = \"linear\"), components = y ~ psi(main = myOtherSquareFun, model = \"linear\"), first example inlabru interpret map parameter expression evaluated within data provided. Since \\(x\\) known covariate know calculate . second example expression well uses function alled mySquareFun. function defined user wo accessible within work space setting compoonents. third example provides function myOtherSquareFun directly within expression. case, inlabru call function using data provided via  data parameter. inlabru expects output function data.frame \"psi\" name single existing column. instance, myOtherSquareFun = function(data) {                             data = data[,\"x\", drop = FALSE] ;                             colnames(data) = \"psi\" ;                             return(data)}","code":""},{"path":"/reference/input_eval.html","id":"spatial-covariates","dir":"Reference","previous_headings":"","what":"Spatial Covariates","title":"Obtain covariate values — input_eval","text":"fitting spatial models common work covariates depend space, e.g. sea surface temperature elevation. Although straight forward add data input data frame write covariate function like previous section even convenient way inlabru. Spatial covariates often stored SpatialPixelsDataFrame, SpatialPixelsDataFrame RasterLayer objects. can provided directly via map parameter input data SpatialPointsDataFrame. inlabru automatically evaluate /interpolate coariate data locations using code like components = y ~ psi(mySpatialPixels, model = \"linear\").","code":""},{"path":"/reference/input_eval.html","id":"coordinates","dir":"Reference","previous_headings":"","what":"Coordinates","title":"Obtain covariate values — input_eval","text":"common spatial modelling component using inla SPDE models. important feature inlabru automatically calculate called -matrix maps SPDE values mesh vertices values data locations. purpose, map parameter can se coordinates, sp package function extracts point coordinates SpatialPointsDataFrame provided input bru. code look follows: components = y ~ mySPDE(main = coordinates, model = inla.spde2.matern(...)).","code":""},{"path":"/reference/input_eval.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Obtain covariate values — input_eval","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"/reference/int.html","id":null,"dir":"Reference","previous_headings":"","what":"Weighted summation (integration) of data frame subsets — int","title":"Weighted summation (integration) of data frame subsets — int","text":"typical task statistical inference integrate (multivariate) function along one dimensions domain. purpose, function evaluated points domain values summed using weights depend area integrated . function performs weighting summation conditional level dimensions integrated . parameter dims states dimensions integrate . set dimensions held fixed set difference column names data dimensions stated dims.","code":""},{"path":"/reference/int.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weighted summation (integration) of data frame subsets — int","text":"","code":"int(data, values, dims = NULL)"},{"path":"/reference/int.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Weighted summation (integration) of data frame subsets — int","text":"data data.frame Spatial object. weight column numeric values. values Numerical values summed , usually result function evaluations. dims Column names (dimension names) data object integrate .","code":""},{"path":"/reference/int.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Weighted summation (integration) of data frame subsets — int","text":"data.frame integrals, one level cross product dimensions integrated .","code":""},{"path":"/reference/int.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Weighted summation (integration) of data frame subsets — int","text":"","code":"# \\donttest{ # ipoints needs INLA if (bru_safe_inla(quietly = TRUE)) {   # Create integration points in two dimensions, x and y    ips <- cprod(     ipoints(c(0, 10), 10, name = \"x\"),     ipoints(c(1, 5), 10, name = \"y\")   )    # The sizes of the domains are 10 and 4 for x and y, respectively.   # Integrating f(x,y) = 1 along x and y should result in the total   # domain size 40    int(ips, rep(1, nrow(ips)), c(\"x\", \"y\")) } #>   group integral #> 1     1       40 # }"},{"path":"/reference/int.polygon.html","id":null,"dir":"Reference","previous_headings":"","what":"Integration points for polygons inside an inla.mesh — int.polygon","title":"Integration points for polygons inside an inla.mesh — int.polygon","text":"method handle polygons holes. Use bru_int_polygon() instead.","code":""},{"path":"/reference/int.polygon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Integration points for polygons inside an inla.mesh — int.polygon","text":"","code":"int.polygon(mesh, loc, group = NULL, method = NULL, ...)"},{"path":"/reference/int.polygon.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Integration points for polygons inside an inla.mesh — int.polygon","text":"mesh inla.mesh object loc Locations defining polygons group loc defines multiple polygons ID group location loc method integration method use (\"stable\", aggregation mesh vertices, \"direct\") ... Arguments passed low level integration method (make_stable_integration_points)","code":""},{"path":"/reference/int.polygon.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Integration points for polygons inside an inla.mesh — int.polygon","text":"Fabian E. Bachl f.e.bachl@bath.ac.uk Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"/reference/integration_weight_aggregation.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate integration weights onto mesh nodes — integration_weight_aggregation","title":"Aggregate integration weights onto mesh nodes — integration_weight_aggregation","text":"Aggregate integration weights onto mesh nodes","code":""},{"path":"/reference/integration_weight_aggregation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate integration weights onto mesh nodes — integration_weight_aggregation","text":"","code":"integration_weight_aggregation(mesh, integ)"},{"path":"/reference/integration_weight_aggregation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate integration weights onto mesh nodes — integration_weight_aggregation","text":"mesh Mesh integrate integ list loc, integration points, weight, integration weights, SpatialPointsDataFrame. coordinates weight column handled.","code":""},{"path":"/reference/integration_weight_aggregation.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Aggregate integration weights onto mesh nodes — integration_weight_aggregation","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"/reference/intersection_mesh.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct the intersection mesh of a mesh and a polygon — intersection_mesh","title":"Construct the intersection mesh of a mesh and a polygon — intersection_mesh","text":"Construct intersection mesh mesh polygon","code":""},{"path":"/reference/intersection_mesh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct the intersection mesh of a mesh and a polygon — intersection_mesh","text":"","code":"intersection_mesh(mesh, poly)"},{"path":"/reference/intersection_mesh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct the intersection mesh of a mesh and a polygon — intersection_mesh","text":"mesh inla.mesh object intersected poly inla.mesh.segment object closed polygon intersect mesh","code":""},{"path":"/reference/intersection_mesh.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Construct the intersection mesh of a mesh and a polygon — intersection_mesh","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"/reference/ipoints.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate integration points — ipoints","title":"Generate integration points — ipoints","text":"function generates points one two dimensions weight attached point. weighted sum function evaluated points integral function approximated linear basis functions. parameter samplers describes area(s) integrated . case single dimension samplers supposed two-column matrix row describes start end point interval integrate . two-dimensional case samplers can either SpatialPolygon, inla.mesh SpatialLinesDataFrame describing area integrate . SpatialLineDataFrame provided column called 'weight' order indicate width line. domain parameter inla.mesh.1d inla.mesh object can employed project integration points vertices mesh. reduces final number integration points reduces computational cost integration. projection can also prevent numerical issues spatial LGCP models observed point ideally surrounded three integration point sitting corresponding mesh vertices. controlled int.args$method=\"stable\" (default) \"direct\", latter uses integration points directly, without aggregating mesh vertices. convenience, domain parameter can also single integer setting number equally spaced integration points one-dimensional case.","code":""},{"path":"/reference/ipoints.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate integration points — ipoints","text":"","code":"ipoints(   samplers = NULL,   domain = NULL,   name = NULL,   group = NULL,   int.args = NULL,   project = NULL )"},{"path":"/reference/ipoints.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate integration points — ipoints","text":"samplers Description integration region boundary. 1D, length 2 vector two-column matrix row describes interval, NULL 2D either SpatialPolygon SpatialLinesDataFrame weight column defining width transect line, optionally columns used group argument, NULL.  domain NULL, samplers may also inla.mesh.1d inla.mesh object, treated domain argument instead. domain Either samplers 1D interval(s) definition , domain can single integer number integration points place 1D interval, overriding int.args[[\"nsub1\"]], otherwise samplers NULL, domain can numeric vector points, given integration weight 1 (additional points added ), inla.mesh.1d object continuous 1D integration, inla.mesh.2d object continuous 2D integration. name Character array stating name domains dimension(s). NULL, names taken coordinate names samplers Spatial* objects, otherwise \"x\", \"y\", \"coordinateZ\" 2D regions \"x\" 1D regions group Column names samplers object (applicable) integration points calculated independently merged aggregating mesh nodes. int.args List arguments passed bru_int_polygon. method: \"stable\" (aggregate integration weights onto mesh nodes) \"direct\" (construct within triangle/segment integration scheme without aggregating onto mesh nodes) nsub1, nsub2: integers controlling number internal integration points aggregation. Points per triangle: (nsub2+1)^2. Points per knot segment: nsub1 poly_method: set \"legacy\", selects old polygon integration method handle holes. Currently used debugging purposes. project Deprecated favour int.args(method=...). TRUE, aggregate integration points mesh vertices. Default: project = (identical(int.args$method, \"stable\"))","code":""},{"path":"/reference/ipoints.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate integration points — ipoints","text":"data.frame SpatialPointsDataFrame 1D 2D integration points, respectively.","code":""},{"path":"/reference/ipoints.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate integration points — ipoints","text":"Fabian E. Bachl bachlfab@gmail.com finn.lindgren@gmail.com","code":""},{"path":"/reference/ipoints.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate integration points — ipoints","text":"","code":"# \\donttest{ if (require(\"INLA\", quietly = TRUE) &&   require(\"ggplot2\", quietly = TRUE)) {    # Create 50 integration points covering the dimension 'myDim' between 0 and 10.    ips <- ipoints(c(0, 10), 50, name = \"myDim\")   plot(ips)     # Create integration points for the two intervals [0,3] and [5,10]    ips <- ipoints(matrix(c(0, 3, 5, 10), nrow = 2, byrow = TRUE), 50)   plot(ips)     # Convert a 1D mesh into integration points   mesh <- inla.mesh.1d(seq(0, 10, by = 1))   ips <- ipoints(mesh, name = \"time\")   plot(ips)     # Obtain 2D integration points from a SpatialPolygon    data(gorillas, package = \"inlabru\")   ips <- ipoints(gorillas$boundary)   ggplot() +     gg(gorillas$boundary) +     gg(ips, aes(size = weight))     #' Project integration points to mesh vertices    ips <- ipoints(gorillas$boundary, domain = gorillas$mesh)   ggplot() +     gg(gorillas$mesh) +     gg(gorillas$boundary) +     gg(ips, aes(size = weight))     # Turn a 2D mesh into integration points    ips <- ipoints(gorillas$mesh)   ggplot() +     gg(gorillas$boundary) +     gg(ips, aes(size = weight)) }   #> Warning: Computing integration points from polygon; specify a mesh for better numerical control. #> Regions defined for each Polygons #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Regions defined for each Polygons #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Regions defined for each Polygons   # }"},{"path":"/reference/is.inside.html","id":null,"dir":"Reference","previous_headings":"","what":"Query if a point is inside the mesh boundary — is.inside","title":"Query if a point is inside the mesh boundary — is.inside","text":"Query point inside mesh boundary","code":""},{"path":"/reference/is.inside.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query if a point is inside the mesh boundary — is.inside","text":"","code":"is.inside(mesh, loc, mesh.coords = NULL)"},{"path":"/reference/is.inside.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query if a point is inside the mesh boundary — is.inside","text":"mesh inla.mesh object. loc Points space stored either data.frame, two-column matrix x y coordinates SpatialPoints object. mesh.coords Coordinate names mesh. Use loc data.frame respective column names.","code":""},{"path":"/reference/is.inside.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query if a point is inside the mesh boundary — is.inside","text":"Single column matrix Boolean values indicating point inside mesh.","code":""},{"path":"/reference/is.inside.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Query if a point is inside the mesh boundary — is.inside","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"/reference/is.inside.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query if a point is inside the mesh boundary — is.inside","text":"","code":"if (FALSE) { if (bru_safe_inla(quietly = TRUE)) {   # Load Gorilla data    data(\"gorillas\", package = \"inlabru\")    # Check if all Gorilla nests are inside the mesh    all(is.inside(gorillas$mesh, gorillas$nests))    # Also works for locations not stored as SpatialPoints object    loc <- coordinates(gorillas$nests)   all(is.inside(gorillas$mesh, loc)) } }"},{"path":"/reference/lgcp.html","id":null,"dir":"Reference","previous_headings":"","what":"Log Gaussian Cox process (LGCP) inference using INLA — lgcp","title":"Log Gaussian Cox process (LGCP) inference using INLA — lgcp","text":"function performs inference LGCP observed via points residing possibly multiple dimensions. dimensions defined via left hand side formula provided via model parameter. left hand side determines intensity function assumed drive LGCP. may include effects lead thinning (filtering) point process. default, log intensity assumed linear combination effects defined formula's RHS. sofisticated models, e.g. non-linear thinning, can achieved using predictor argument. latter requires multiple runs INLA improving required approximation predictor. many applications LGCP observed subsets dimensions process living . example, spatial point realizations may known sub-areas modelled space. observed subsets LGCP domain called samplers can provided via respective parameter. samplers NULL assumed LGCP's dimensions observed completely.","code":""},{"path":"/reference/lgcp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log Gaussian Cox process (LGCP) inference using INLA — lgcp","text":"","code":"lgcp(   components,   data,   samplers = NULL,   domain = NULL,   ips = NULL,   formula = . ~ .,   E = NULL,   ...,   options = list() )"},{"path":"/reference/lgcp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log Gaussian Cox process (LGCP) inference using INLA — lgcp","text":"components formula describing latent components data data frame SpatialPoints(DataFrame) object samplers data frame Spatial[Points/Lines/Polygons]DataFrame objects domain Named list domain definitions ips Integration points (overrides samplers) formula NULL, linear combination implied components used predictor point location intensity. (possibly non-linear) expression provided respective Taylor approximation used predictor. Multiple runs INLA required better approximation posterior. E Single numeric used rescale integration weights fixed factor ... arguments passed like() options See bru_options_set()","code":""},{"path":"/reference/lgcp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log Gaussian Cox process (LGCP) inference using INLA — lgcp","text":"bru() object","code":""},{"path":"/reference/lgcp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log Gaussian Cox process (LGCP) inference using INLA — lgcp","text":"","code":"# \\donttest{ if (bru_safe_inla() &&   require(ggplot2, quietly = TRUE)) {    # Load the Gorilla data   data(gorillas, package = \"inlabru\")    # Plot the Gorilla nests, the mesh and the survey boundary   ggplot() +     gg(gorillas$mesh) +     gg(gorillas$nests) +     gg(gorillas$boundary) +     coord_fixed()    # Define SPDE prior   matern <- INLA::inla.spde2.pcmatern(gorillas$mesh,     prior.sigma = c(0.1, 0.01),     prior.range = c(0.01, 0.01)   )    # Define domain of the LGCP as well as the model components (spatial SPDE   # effect and Intercept)   cmp <- coordinates ~ mySmooth(coordinates, model = matern) + Intercept(1)    # Fit the model (with int.strategy=\"eb\" to make the example take less time)   fit <- lgcp(cmp, gorillas$nests,     samplers = gorillas$boundary,     domain = list(coordinates = gorillas$mesh),     options = list(control.inla = list(int.strategy = \"eb\"))   )    # Predict the spatial intensity surface   lambda <- predict(fit, pixels(gorillas$mesh), ~ exp(mySmooth + Intercept))    # Plot the intensity   ggplot() +     gg(lambda) +     gg(gorillas$mesh) +     gg(gorillas$nests) +     gg(gorillas$boundary) +     coord_fixed() } #> Regions defined for each Polygons #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Regions defined for each Polygons  # }"},{"path":"/reference/like.html","id":null,"dir":"Reference","previous_headings":"","what":"Likelihood construction for usage with bru() — like","title":"Likelihood construction for usage with bru() — like","text":"Likelihood construction usage bru()","code":""},{"path":"/reference/like.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Likelihood construction for usage with bru() — like","text":"","code":"like(   formula = . ~ .,   family = \"gaussian\",   data = NULL,   response_data = NULL,   mesh = NULL,   E = NULL,   Ntrials = NULL,   weights = NULL,   samplers = NULL,   ips = NULL,   domain = NULL,   include = NULL,   exclude = NULL,   allow_latent = FALSE,   allow_combine = NULL,   control.family = NULL,   options = list(),   .envir = parent.frame() )  like_list(...)  # S3 method for list like_list(object, envir = NULL, ...)  # S3 method for bru_like like_list(..., envir = NULL)  # S3 method for bru_like_list [(x, i)"},{"path":"/reference/like.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Likelihood construction for usage with bru() — like","text":"formula formula right hand side general R expression defines predictor used model. family string identifying valid INLA::inla likelihood family. default gaussian identity link. addition likelihoods provided inla (see names(INLA::inla.models()$likelihood)) inlabru supports fitting latent Gaussian Cox processes via family = \"cp\". alternative bru(), lgcp() function provides convenient interface fitting Cox processes. data Likelihood-specific data, data.frame SpatialPoints[DataFrame] object. response_data Likelihood-specific data models need different size/format inputs response variables, data.frame SpatialPoints[DataFrame] object. mesh inla.mesh object. Obsolete. E Exposure parameter family = 'poisson' passed INLA::inla. Special case family 'cp': rescale integration weights E. Default taken options$E, normally 1. Ntrials vector containing number trials 'binomial' likelihood. Default taken options$Ntrials, normally 1. weights Fixed (optional) weights parameters likelihood, log-likelihood[] changed weights[] * log_likelihood[]. Default value 1. WARNING: normalizing constant likelihood recomputed, marginals (marginal likelihood) must interpreted great care. samplers Integration domain 'cp' family. ips Integration points 'cp' family. Overrides samplers. domain Named list domain definitions. include Character vector component labels needed predictor expression; Default: NULL (include components explicitly excluded) exclude Character vector component labels used predictor expression. exclusion list applied list determined include parameter; Default: NULL (remove components inclusion list) allow_latent logical. TRUE, latent state component directly available predictor expression, _latent suffix. also makes evaluator functions suffix _eval available, taking parameters main, group, replicate, taking values evaluate component effect different defined component definition (see component_eval()). Default FALSE allow_combine logical; TRUE, predictor expression may involve several rows input data influence row. Default FALSE, forced TRUE response_data NULL data list control.family optional list INLA::control.family options options bru_options options object list options passed bru_options() .envir evaluation environment use special arguments (E, Ntrials, weights) found response_data data. Defaults calling environment. ... like_list.bru_like, one bru_like objects object list bru_like objects envir optional environment new bru_like_list object x bru_like_list object extract element(s) indices specifying elements extract","code":""},{"path":"/reference/like.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Likelihood construction for usage with bru() — like","text":"likelihood configuration can used parameterize bru().","code":""},{"path":"/reference/like.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Likelihood construction for usage with bru() — like","text":"like_list: Combine bru_like likelihoods bru_like_list object like_list.list: Combine list bru_like likelihoods bru_like_list object like_list.bru_like: Combine several bru_like likelihoods bru_like_list object","code":""},{"path":"/reference/like.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Likelihood construction for usage with bru() — like","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"/reference/like.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Likelihood construction for usage with bru() — like","text":"","code":"# \\donttest{ if (bru_safe_inla() &&     require(ggplot2, quietly = TRUE)) {    # The like function's main purpose is to set up models with multiple likelihoods.   # The following example generates some random covariates which are observed through   # two different random effect models with different likelihoods    # Generate the data    set.seed(123)    n1 <- 200   n2 <- 10    x1 <- runif(n1)   x2 <- runif(n2)   z2 <- runif(n2)    y1 <- rnorm(n1, mean = 2 * x1 + 3)   y2 <- rpois(n2, lambda = exp(2 * x2 + z2 + 3))    df1 <- data.frame(y = y1, x = x1)   df2 <- data.frame(y = y2, x = x2, z = z2)    # Single likelihood models and inference using bru are done via    cmp1 <- y ~ -1 + Intercept(1) + x   fit1 <- bru(cmp1, family = \"gaussian\", data = df1)   summary(fit1)    cmp2 <- y ~ -1 + Intercept(1) + x + z   fit2 <- bru(cmp2, family = \"poisson\", data = df2)   summary(fit2)    # A joint model has two likelihoods, which are set up using the like function    lik1 <- like(\"gaussian\", formula = y ~ x + Intercept, data = df1)   lik2 <- like(\"poisson\", formula = y ~ x + z + Intercept, data = df2)    # The union of effects of both models gives the components needed to run bru    jcmp <- ~ x + z + Intercept(1)   jfit <- bru(jcmp, lik1, lik2)    # Compare the estimates    p1 <- ggplot() +     gg(fit1$summary.fixed, bar = TRUE) +     ylim(0, 4) +     ggtitle(\"Model 1\")   p2 <- ggplot() +     gg(fit2$summary.fixed, bar = TRUE) +     ylim(0, 4) +     ggtitle(\"Model 2\")   pj <- ggplot() +     gg(jfit$summary.fixed, bar = TRUE) +     ylim(0, 4) +     ggtitle(\"Joint model\")    multiplot(p1, p2, pj) }  # }"},{"path":"/reference/local_testthat.html","id":null,"dir":"Reference","previous_headings":"","what":"Unit test helpers — local_testthat","title":"Unit test helpers — local_testthat","text":"Local helper functions package unit tests","code":""},{"path":"/reference/local_testthat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unit test helpers — local_testthat","text":"","code":"local_testthat_assign(x, values, envir = parent.frame())  local_testthat_tolerances(   tolerances = c(1e-04, 0.01, 0.1),   envir = parent.frame() )  local_bru_options_set(..., .reset = FALSE, envir = parent.frame())  local_set_PROJ6_warnings(proj4 = FALSE, thin = TRUE, envir = parent.frame())  local_get_rgdal_options()  local_disable_PROJ6_warnings(envir = parent.frame())  local_basic_intercept_testdata()  local_basic_fixed_effect_testdata()  local_mrsea_convert(x, use_km = FALSE)  local_bru_safe_inla(multicore = FALSE, quietly = TRUE, envir = parent.frame())  local_bru_testthat_setup(envir = parent.frame())"},{"path":"/reference/local_testthat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unit test helpers — local_testthat","text":"x character; Name variable assign values object assign x envir environment exit handlers tolerances numeric vector length 3; [lowtol, midtol, hitol] .reset local_bru_options_set, logical indicating global override options list emptied setting new option(s). proj4 logical; whether show PROJ4 conversion warnings. Default FALSE thin logical; whether show thinned version rgdal PROJ6 warnings. Default TRUE multicore logical; TRUE, multiple cores allowed, INLA num.threads option checked altered. Default: FALSE, multicore allowed (used examples unit tests). quietly logical; TRUE, prints diagnostic messages. message always printed INLA num.threads option altered, regardless quietly argument. Default: TRUE.","code":""},{"path":"/reference/local_testthat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unit test helpers — local_testthat","text":"local_bru_options_set() returns copy global override options (including defaults), invisibly.","code":""},{"path":"/reference/local_testthat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Unit test helpers — local_testthat","text":"local_bru_options_set() used set global package options.","code":""},{"path":"/reference/local_testthat.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Unit test helpers — local_testthat","text":"local_testthat_assign(): Assign local variable. Useful easy cleanup global workspace withr::deferred_run() running tests interactively. local_testthat_tolerances(): Assign test tolerances Assign local tolerance variables. Useful easy cleanup global workspace withr::deferred_run() running tests interactively. local_bru_options_set(): Calls bru_options_set() reversible way local_set_PROJ6_warnings(): Disable PROJ4/6 warnings. used within package tests. Restores state exit. local_get_rgdal_options(): Return list current rgdal warning options local_disable_PROJ6_warnings(): Disable rgdal PROJ4 conversion warnings thin PROJ6 warnings. local_bru_safe_inla(): Tests set num.threads = \"1:1\" ensure within-system repeatability calling local_bru_safe_inla(); see also bru_safe_inla() local_bru_testthat_setup(): Initialise environment tests. Disables PROJ4/PROJ6 warnings, assigns tolerance variables. called either top testfile, inside tests. call local_bru_safe_inla(), since may invoke skip called inside test relies INLA.","code":""},{"path":[]},{"path":"/reference/local_testthat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unit test helpers — local_testthat","text":"","code":"my_fun <- function(val) {   local_bru_options_set(bru_verbose = val)   bru_options_get(\"bru_verbose\") } # Inside the function, the bru_verbose option is changed. # Outside the function, the bru_verbose option is unchanged. print(my_fun(TRUE)) #> [1] TRUE print(bru_options_get(\"bru_verbose\")) #> [1] 0 print(my_fun(FALSE)) #> [1] FALSE print(bru_options_get(\"bru_verbose\")) #> [1] 0"},{"path":"/reference/make_stable_integration_points.html","id":null,"dir":"Reference","previous_headings":"","what":"Basic robust integration weights for mesh/polygon intersections — make_stable_integration_points","title":"Basic robust integration weights for mesh/polygon intersections — make_stable_integration_points","text":"Basic robust integration weights mesh/polygon intersections","code":""},{"path":"/reference/make_stable_integration_points.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Basic robust integration weights for mesh/polygon intersections — make_stable_integration_points","text":"","code":"make_stable_integration_points(mesh, bnd, nsub = NULL)"},{"path":"/reference/make_stable_integration_points.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Basic robust integration weights for mesh/polygon intersections — make_stable_integration_points","text":"mesh Mesh integrate bnd inla.mesh.segment defining integration domain nsub number subdivision points along triangle edge, giving (nsub + 1)^2 proto-integration points used compute vertex weights (default NULL=9, giving 100 integration points triangle)","code":""},{"path":"/reference/make_stable_integration_points.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Basic robust integration weights for mesh/polygon intersections — make_stable_integration_points","text":"list elements loc weight integration points intersection mesh polygon","code":""},{"path":"/reference/make_stable_integration_points.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Basic robust integration weights for mesh/polygon intersections — make_stable_integration_points","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"/reference/materncov.bands.html","id":null,"dir":"Reference","previous_headings":"","what":"Matern correlation or covariance function approximate credible bands. — materncov.bands","title":"Matern correlation or covariance function approximate credible bands. — materncov.bands","text":"Evaluate covariance function inla.spde objectPlots posterior distribution range, log(range), variance, log(variance) parameter model's SPDE component. Can also plot Matern correlation covariance function.","code":""},{"path":"/reference/materncov.bands.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matern correlation or covariance function approximate credible bands. — materncov.bands","text":"","code":"materncov.bands(   manifold,   dist,   log.range,   log.variance = NULL,   alpha = 2,   quantile = 0.95,   n = 64,   S1.L = NULL )"},{"path":"/reference/materncov.bands.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matern correlation or covariance function approximate credible bands. — materncov.bands","text":"manifold Either \"R1\", \"S1\", \"R2\", \"S2\", mesh$manifold, full inla.mesh inla.mesh.1d object. dist vector distances calculate covariances/correlations log.range scalar list (mean, sd), produced inla.spde.result(...)$summary.log.range.nominal[[1]][c(\"mean\",\"sd\")] log.variance Either NULL, scalar, vector type log.range. NULL, correlations calculated instead covariances. alpha SPDE operator order. Default 2. quantile target credible probability. Default 0.95. n number parameter combinations use approximation. Default 64. S1.L manifold \"S1\", give length cyclic interval","code":""},{"path":"/reference/materncov.bands.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matern correlation or covariance function approximate credible bands. — materncov.bands","text":"list estimated covariance correlation (log.variance NULL) functions: lower approximate lower bound quantile credible region median function approximate median parameters quantile upper approximate upper bound quantile credible region","code":""},{"path":"/reference/materncov.bands.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Matern correlation or covariance function approximate credible bands. — materncov.bands","text":"Uses Gaussian assumption internal model parameters, finds region parameter space approximately quantile probability.","code":""},{"path":"/reference/materncov.bands.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Matern correlation or covariance function approximate credible bands. — materncov.bands","text":"Finn Lindgren Finn.Lindgren@ed.ac.uk","code":""},{"path":"/reference/mesh_triangle_integration.html","id":null,"dir":"Reference","previous_headings":"","what":"Integration scheme for mesh triangle interiors — mesh_triangle_integration","title":"Integration scheme for mesh triangle interiors — mesh_triangle_integration","text":"Integration scheme mesh triangle interiors","code":""},{"path":"/reference/mesh_triangle_integration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Integration scheme for mesh triangle interiors — mesh_triangle_integration","text":"","code":"mesh_triangle_integration(mesh, tri_subset = NULL, nsub = NULL)"},{"path":"/reference/mesh_triangle_integration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Integration scheme for mesh triangle interiors — mesh_triangle_integration","text":"mesh Mesh integrate tri_subset Optional triangle index vector integration subset mesh triangles (Default NULL) nsub number subdivision points along triangle edge, giving (nsub + 1)^2 proto-integration points used compute vertex weights (default NULL=9, giving 100 integration points triangle)","code":""},{"path":"/reference/mesh_triangle_integration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Integration scheme for mesh triangle interiors — mesh_triangle_integration","text":"list elements loc weight integration points mesh","code":""},{"path":"/reference/mesh_triangle_integration.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Integration scheme for mesh triangle interiors — mesh_triangle_integration","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"/reference/mexdolphin.html","id":null,"dir":"Reference","previous_headings":"","what":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin","text":"version mexdolphins dataset package dsm, reformatted point process data use inlabru. data combination several NOAA shipboard surveys conducted pan-tropical spotted dolphins Gulf Mexico. 47 observations groups dolphins wre detected. group size recorded, well Beaufort sea state time observation. Transect width 16 km, .e. maximal detection distance 8 km (transect half-width 8 km).","code":""},{"path":"/reference/mexdolphin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin","text":"","code":"data(mexdolphin)"},{"path":"/reference/mexdolphin.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin","text":"list objects: points: SpatialPointsDataFrame object containing locations detected dolphin groups, size attribute. samplers: SpatialLinesDataFrame object containing transect lines surveyed. mesh: inla.mesh object containing Delaunay triangulation mesh (type discretization continuous space) covering survey region. ppoly: SpatialPolygonsDataFrame object defining boundary survey region. simulated: SpatialPointsDataFrame object containing locations simulated population dolphin groups. population simulated 'codeinlabru model fitted actual survey data. Note simulated data associated size information.","code":""},{"path":"/reference/mexdolphin.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin","text":"Library dsm.","code":""},{"path":"/reference/mexdolphin.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin","text":"Halpin, P.N., .J. Read, E. Fujioka, B.D. Best, B. Donnelly, L.J. Hazen, C. Kot, K. Urian, E. LaBrecque, . Dimatteo, J. Cleary, C. Good, L.B. Crowder, K.D. Hyrenbach. 2009. OBIS-SEAMAP: world data center marine mammal, sea bird, sea turtle distributions. Oceanography 22(2):104-115 NOAA Southeast Fisheries Science Center. 1996. Report Cetacean Survey Oceanic Selected Continental Shelf Waters Northern Gulf Mexico aboard NOAA Ship Oregon II (Cruise 220)","code":""},{"path":"/reference/mexdolphin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin","text":"","code":"# \\donttest{ if (bru_safe_inla(quietly = TRUE) &&   require(\"ggplot2\", quietly = TRUE) &&   require(\"ggpolypath\", quietly = TRUE)) {   data(mexdolphin, package = \"inlabru\")   ggplot() +     gg(mexdolphin$mesh) +     gg(mexdolphin$ppoly, color = \"blue\") +     gg(mexdolphin$samplers) +     gg(mexdolphin$points, aes(size = size), color = \"red\") +     coord_equal()    ggplot() +     gg(mexdolphin$mesh, col = mexdolphin$lambda, mask = mexdolphin$ppoly) +     coord_equal() } #> Regions defined for each Polygons #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition  # } if (FALSE) { if (requireNamespace(\"ggmap\", quietly = TRUE) &&   require(\"ggplot2\", quietly = TRUE) &&   require(\"ggpolypath\", quietly = TRUE)) {   gmap(mexdolphin$depth) +     gm(mexdolphin$ppoly, color = \"blue\") +     gm(mexdolphin$samplers) +     gm(mexdolphin$points, aes(size = size), color = \"red\")    gmap(mexdolphin$depth) +     gm(mexdolphin$depth, aes(col = depth)) +     gm(mexdolphin$ppoly) } }"},{"path":"/reference/mrsea.html","id":null,"dir":"Reference","previous_headings":"","what":"Marine renewables strategic environmental assessment — mrsea","title":"Marine renewables strategic environmental assessment — mrsea","text":"Data imported package MRSea, see http://creem2.st-andrews.ac.uk/software/","code":""},{"path":"/reference/mrsea.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Marine renewables strategic environmental assessment — mrsea","text":"","code":"data(mrsea)"},{"path":"/reference/mrsea.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Marine renewables strategic environmental assessment — mrsea","text":"list objects: points: SpatialPointsDataFrame object containing locations XXXXX. samplers: SpatialLinesDataFrame object containing transect lines surveyed. mesh: inla.mesh object containing Delaunay triangulation mesh (type discretization continuous space) covering survey region. boundary: SpatialPolygonsDataFrame object defining boundary survey region. covar: SpatialPointsDataFrame containing sea depth estimates.","code":""},{"path":"/reference/mrsea.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Marine renewables strategic environmental assessment — mrsea","text":"Library MRSea.","code":""},{"path":"/reference/mrsea.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Marine renewables strategic environmental assessment — mrsea","text":"NONE YET","code":""},{"path":"/reference/mrsea.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Marine renewables strategic environmental assessment — mrsea","text":"","code":"if (bru_safe_inla() &&   require(ggplot2, quietly = TRUE) &&   require(ggpolypath, quietly = TRUE)) {   data(mrsea)   ggplot() +     gg(mrsea$mesh) +     gg(mrsea$samplers) +     gg(mrsea$points) +     gg(mrsea$boundary) } #> Regions defined for each Polygons"},{"path":"/reference/multiplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiple ggplots on a page. — multiplot","title":"Multiple ggplots on a page. — multiplot","text":"Renders multiple ggplots single page.","code":""},{"path":"/reference/multiplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiple ggplots on a page. — multiplot","text":"","code":"multiplot(..., plotlist = NULL, cols = 1, layout = NULL)"},{"path":"/reference/multiplot.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Multiple ggplots on a page. — multiplot","text":"http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/","code":""},{"path":"/reference/multiplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiple ggplots on a page. — multiplot","text":"... Comma-separated ggplot objects. plotlist list ggplot objects - alternative comma-separated argument . cols Number columns plots page. layout matrix specifying layout. present, 'cols' ignored. layout something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE), plot 1 go upper left, 2 go upper right, 3 go way across bottom.","code":""},{"path":"/reference/multiplot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Multiple ggplots on a page. — multiplot","text":"David L. Borchers dlb@st-andrews.ac.uk","code":""},{"path":"/reference/multiplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multiple ggplots on a page. — multiplot","text":"","code":"if (require(\"ggplot2\", quietly = TRUE)) {   df <- data.frame(x = 1:10, y = 1:10, z = 11:20)   pl1 <- ggplot(data = df) +     geom_line(mapping = aes(x, y), color = \"red\")   pl2 <- ggplot(data = df) +     geom_line(mapping = aes(x, z), color = \"blue\")   multiplot(pl1, pl2, cols = 2) }"},{"path":"/reference/parse_inclusion.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse inclusion of component labels in a predictor expression — parse_inclusion","title":"Parse inclusion of component labels in a predictor expression — parse_inclusion","text":"Parse inclusion component labels predictor expression","code":""},{"path":"/reference/parse_inclusion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse inclusion of component labels in a predictor expression — parse_inclusion","text":"","code":"parse_inclusion(thenames, include = NULL, exclude = NULL)"},{"path":"/reference/parse_inclusion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse inclusion of component labels in a predictor expression — parse_inclusion","text":"thenames Set labels restrict include Character vector component labels needed predictor expression; Default: NULL (include components explicitly excluded) exclude Character vector component labels used predictor expression. exclusion list applied list determined include parameter; Default: NULL (remove components inclusion list)","code":""},{"path":"/reference/pixels.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate SpatialPixels covering an inla.mesh — pixels","title":"Generate SpatialPixels covering an inla.mesh — pixels","text":"Generate SpatialPixels covering inla.mesh","code":""},{"path":"/reference/pixels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate SpatialPixels covering an inla.mesh — pixels","text":"","code":"pixels(mesh, nx = 150, ny = 150, mask = TRUE)"},{"path":"/reference/pixels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate SpatialPixels covering an inla.mesh — pixels","text":"mesh inla.mesh object nx Number pixels x direction ny Number pixels y direction mask logical TRUE, remove pixels outside mesh. mask Spatial object, return pixels covered object.","code":""},{"path":"/reference/pixels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate SpatialPixels covering an inla.mesh — pixels","text":"SpatialPixelsDataFrame covering mesh","code":""},{"path":"/reference/pixels.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate SpatialPixels covering an inla.mesh — pixels","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"/reference/pixels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate SpatialPixels covering an inla.mesh — pixels","text":"","code":"# \\donttest{ if (require(ggplot2, quietly = TRUE)) {   data(\"mrsea\", package = \"inlabru\")   pxl <- pixels(mrsea$mesh, nx = 50, ny = 50, mask = mrsea$boundary)   ggplot() +     gg(pxl, fill = \"grey\", alpha = 0.5) +     gg(mrsea$mesh) }  # }"},{"path":"/reference/plot.bru.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for posterior marginals estimated by bru — plot.bru","title":"Plot method for posterior marginals estimated by bru — plot.bru","text":"bru() uses INLA::inla() fit models. latter estimates posterior densities random effects model. function serves access plot posterior densities convenient way. Requires ggplot2 package.","code":""},{"path":"/reference/plot.bru.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for posterior marginals estimated by bru — plot.bru","text":"","code":"# S3 method for bru plot(x, ...)"},{"path":"/reference/plot.bru.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for posterior marginals estimated by bru — plot.bru","text":"x fitted bru() model. ... character naming effect plot, e.g. \"Intercept\". random effects, adding index = ... plots density single component latent model.","code":""},{"path":"/reference/plot.bru.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot method for posterior marginals estimated by bru — plot.bru","text":"object class gg","code":""},{"path":"/reference/plot.bru.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot method for posterior marginals estimated by bru — plot.bru","text":"","code":"if (FALSE) { if (require(\"ggplot2\", quietly = TRUE)) {   # Generate some data and fit a simple model   input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, y <- 5 + 2 * cos(1:10) + rnorm(10, mean = 0, sd = 0.1))   fit <- bru(y ~ x, family = \"gaussian\", data = input.df)   summary(fit)    # Plot the posterior of the model's x-effect   plot(fit, \"x\") } }"},{"path":"/reference/plot.prediction.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot prediction using ggplot2 — plot.prediction","title":"Plot prediction using ggplot2 — plot.prediction","text":"Generates base ggplot2 using ggplot() adds geom input x using gg.","code":""},{"path":"/reference/plot.prediction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot prediction using ggplot2 — plot.prediction","text":"","code":"# S3 method for prediction plot(x, y = NULL, ...)"},{"path":"/reference/plot.prediction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot prediction using ggplot2 — plot.prediction","text":"x prediction object. y Ignored argument required S3 compatibility. ... Arguments passed gg.prediction.","code":""},{"path":"/reference/plot.prediction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot prediction using ggplot2 — plot.prediction","text":"object class gg","code":""},{"path":"/reference/plot.prediction.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot prediction using ggplot2 — plot.prediction","text":"Requires ggplot2 package.","code":""},{"path":"/reference/plot.prediction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot prediction using ggplot2 — plot.prediction","text":"","code":"# \\donttest{ if (bru_safe_inla() && require(ggplot2, quietly = TRUE)) {   # Generate some data    input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, y <- 5 + 2 * cos(1:10) + rnorm(10, mean = 0, sd = 0.1))    # Fit a model with fixed effect 'x' and intercept 'Intercept'    fit <- bru(y ~ x, family = \"gaussian\", data = input.df)    # Predict posterior statistics of 'x'    xpost <- predict(fit, data = NULL, formula = ~x_latent)    # The statistics include mean, standard deviation, the 2.5% quantile, the median,   # the 97.5% quantile, minimum and maximum sample drawn from the posterior as well as   # the coefficient of variation and the variance.    xpost    # For a single variable like 'x' the default plotting method invoked by gg() will   # show these statisics in a fashion similar to a box plot:   ggplot() +     gg(xpost)     # The predict function can also be used to simulataneously estimate posteriors   # of multiple variables:    xipost <- predict(fit,     data = NULL,     formula = ~ c(       Intercept = Intercept_latent,       x = x_latent     )   )   xipost    # If we still want a plot in the previous style we have to set the bar parameter to TRUE    p1 <- ggplot() +     gg(xipost, bar = TRUE)   p1    # Note that gg also understands the posterior estimates generated while running INLA    p2 <- ggplot() +     gg(fit$summary.fixed, bar = TRUE)   multiplot(p1, p2)    # By default, if the prediction has more than one row, gg will plot the column 'mean' against   # the row index. This is for instance usefuul for predicting and plotting function   # but not very meaningful given the above example:    ggplot() +     gg(xipost)    # For ease of use we can also type    plot(xipost)    # This type of plot will show a ribbon around the mean, which viszualizes the upper and lower   # quantiles mentioned above (2.5 and 97.5%). Plotting the ribbon can be turned of using the   # \\code{ribbon} parameter    ggplot() +     gg(xipost, ribbon = FALSE)    # Much like the other geomes produced by gg we can adjust the plot using ggplot2 style   # commands, for instance    ggplot() +     gg(xipost) +     gg(xipost, mapping = aes(y = median), ribbon = FALSE, color = \"red\") }   # }"},{"path":"/reference/plotsample.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a plot sample. — plotsample","title":"Create a plot sample. — plotsample","text":"Creates plot sample regular grid random start location.","code":""},{"path":"/reference/plotsample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a plot sample. — plotsample","text":"","code":"plotsample(spdf, boundary, x.ppn = 0.25, y.ppn = 0.25, nx = 5, ny = 5)"},{"path":"/reference/plotsample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a plot sample. — plotsample","text":"spdf SpatialPointsDataFrame defining points sampled plot sample. boundary SpatialPolygonsDataFrame defining survey boundary within  points occur. x.ppn proportion x=axis included plots. y.ppn proportion y=axis included plots. nx number plots x-dimension. ny number plots y-dimension.","code":""},{"path":"/reference/plotsample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a plot sample. — plotsample","text":"list three components: plots: SpatialPolygonsDataFrame object containing plots sampled. dets: SpatialPointsDataFrame object containing locations points within plots. counts: dataframe containing following columns x: x-coordinates centres plots within boundary. y: y-coordinates centres plots within boundary. n: numbers points plot. area: areas plots within boundary .","code":""},{"path":"/reference/plotsample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a plot sample. — plotsample","text":"","code":"# \\donttest{ # Some features require the raster package if (require(\"raster\", quietly = TRUE) &&   require(\"ggplot2\", quietly = TRUE)) {   data(gorillas, package = \"inlabru\")   plotpts <- plotsample(gorillas$nests, gorillas$boundary,     x.ppn = 0.4, y.ppn = 0.4, nx = 5, ny = 5   )   ggplot() +     gg(plotpts$plots) +     gg(plotpts$dets, pch = \"+\", cex = 2) +     gg(gorillas$boundary) } #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Regions defined for each Polygons #> Regions defined for each Polygons  # }"},{"path":"/reference/point2count.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a plot sample of points into one of counts. — point2count","title":"Convert a plot sample of points into one of counts. — point2count","text":"Converts plot sample locations point within plot, plot sample count within plot.","code":""},{"path":"/reference/point2count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a plot sample of points into one of counts. — point2count","text":"","code":"point2count(plots, dets)"},{"path":"/reference/point2count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a plot sample of points into one of counts. — point2count","text":"plots SpatialPolygonsDataFrame object containing plots sampled. dets SpatialPointsDataFrame object containing locations points within plots.","code":""},{"path":"/reference/point2count.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a plot sample of points into one of counts. — point2count","text":"SpatialPolygonsDataFrame counts plot contained slot @data$n.","code":""},{"path":"/reference/point2count.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a plot sample of points into one of counts. — point2count","text":"","code":"# \\donttest{ # Some features require the raster package if (require(\"raster\", quietly = TRUE) &&   require(\"ggplot2\", quietly = TRUE)) {   data(gorillas, package = \"inlabru\")   plotpts <- plotsample(gorillas$nests, gorillas$boundary,     x.ppn = 0.4, y.ppn = 0.4, nx = 5, ny = 5   )   p1 <- ggplot() +     gg(plotpts$plots) +     gg(plotpts$dets) +     gg(gorillas$boundary)   countdata <- point2count(plotpts$plots, plotpts$dets)   x <- coordinates(countdata)[, 1]   y <- coordinates(countdata)[, 2]   count <- countdata@data$n   p2 <- ggplot() +     gg(gorillas$boundary) +     gg(plotpts$plots) +     geom_text(aes(label = count, x = x, y = y))   multiplot(p1, p2, cols = 2) } #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Regions defined for each Polygons #> Regions defined for each Polygons #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Warning: CRS object has comment, which is lost in output; in tests, see #> https://cran.r-project.org/web/packages/sp/vignettes/CRS_warnings.html #> Regions defined for each Polygons #> Regions defined for each Polygons  # }"},{"path":"/reference/predict.bru.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction from fitted bru model — predict.bru","title":"Prediction from fitted bru model — predict.bru","text":"Takes fitted bru object produced function bru() produces predictions given new set values model covariates original values used model fit. predictions can based R expression valid given values/covariates joint posterior estimated random effects.","code":""},{"path":"/reference/predict.bru.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction from fitted bru model — predict.bru","text":"","code":"# S3 method for bru predict(   object,   data = NULL,   formula = NULL,   n.samples = 100,   seed = 0L,   probs = c(0.025, 0.5, 0.975),   num.threads = NULL,   include = NULL,   exclude = NULL,   drop = FALSE,   ... )"},{"path":"/reference/predict.bru.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction from fitted bru model — predict.bru","text":"object object obtained calling bru() lgcp(). data data.frame SpatialPointsDataFrame covariates needed prediction. formula formula right hand side defines R expression evaluate generated sample. NULL, latent hyperparameter states returned named list elements. See Details information. n.samples Integer setting number samples draw order calculate posterior statistics. default rather low provides quick approximate result. seed Random number generator seed passed inla.posterior.sample probs numeric vector probabilities values [0, 1], passed stats::quantile num.threads Specification desired number threads parallel computations. Default NULL, leaves INLA. seed != 0, overridden \"1:1\" include Character vector component labels needed predictor expression; Default: NULL (include components explicitly excluded) exclude Character vector component labels used predictor expression. exclusion list applied list determined include parameter; Default: NULL (remove components inclusion list) drop logical; keep=FALSE, data Spatial*DataFrame, prediciton summary number rows data, output Spatial*DataFrame object. Default FALSE. ... Additional arguments passed inla.posterior.sample","code":""},{"path":"/reference/predict.bru.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prediction from fitted bru model — predict.bru","text":"data.frame Spatial* object predicted mean values summary statistics attached.","code":""},{"path":"/reference/predict.bru.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prediction from fitted bru model — predict.bru","text":"Mean value predictions accompanied standard errors, upper lower 2.5% quantiles, median, variance, coefficient variation well variance minimum maximum sample value drawn course estimating statistics. Internally, method calls generate.bru() order draw samples model. addition component names (give effect component evaluated input data), suffix _latent variable name can used directly access latent state component, suffix function _eval can used evaluate component input values expressions defined component definition , e.g. field_eval(cbind(x, y)) component defined field(coordinates, ...) (see also component_eval()). \"iid\" models mapper = bru_mapper_index(n), rnorm() used generate new realisations indices greater n.","code":""},{"path":"/reference/predict.bru.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prediction from fitted bru model — predict.bru","text":"","code":"# \\donttest{ if (bru_safe_inla(multicore = FALSE) &&     require(\"ggplot2\", quietly = TRUE)) {    # Load the Gorilla data    data(gorillas, package = \"inlabru\")    # Plot the Gorilla nests, the mesh and the survey boundary    ggplot() +     gg(gorillas$mesh) +     gg(gorillas$nests) +     gg(gorillas$boundary) +     coord_fixed()    # Define SPDE prior    matern <- INLA::inla.spde2.pcmatern(gorillas$mesh,     prior.sigma = c(0.1, 0.01),     prior.range = c(0.01, 0.01)   )    # Define domain of the LGCP as well as the model components (spatial SPDE effect and Intercept)    cmp <- coordinates ~ mySmooth(main = coordinates, model = matern) + Intercept(1)    # Fit the model, with \"eb\" instead of full Bayes   fit <- lgcp(cmp, gorillas$nests,     samplers = gorillas$boundary,     domain = list(coordinates = gorillas$mesh),     options = list(control.inla = list(int.strategy = \"eb\"))   )    # Once we obtain a fitted model the predict function can serve various purposes.   # The most basic one is to determine posterior statistics of a univariate   # random variable in the model, e.g. the intercept    icpt <- predict(fit, NULL, ~ c(Intercept = Intercept_latent))   plot(icpt)    # The formula argument can take any expression that is valid within the model, for   # instance a non-linear transformation of a random variable    exp.icpt <- predict(fit, NULL, ~ c(     \"Intercept\" = Intercept_latent,     \"exp(Intercept)\" = exp(Intercept_latent)   ))   plot(exp.icpt, bar = TRUE)    # The intercept is special in the sense that it does not depend on other variables   # or covariates. However, this is not true for the smooth spatial effects 'mySmooth'.   # In order to predict 'mySmooth' we have to define where (in space) to predict. For   # this purpose, the second argument of the predict function can take \\code{data.frame}   # objects as well as Spatial objects. For instance, we might want to predict   # 'mySmooth' at the locations of the mesh vertices. Using    vrt <- vertices(gorillas$mesh)    # we obtain these vertices as a SpatialPointsDataFrame    ggplot() +     gg(gorillas$mesh) +     gg(vrt, color = \"red\")    # Predicting 'mySmooth' at these locations works as follows    mySmooth <- predict(fit, vrt, ~mySmooth)    # Note that just like the input also the output will be a SpatialPointsDataFrame   # and that the predicted statistics are simply added as columns    class(mySmooth)   head(vrt)   head(mySmooth)    # Plotting the mean, for instance, at the mesh node is straight forward    ggplot() +     gg(gorillas$mesh) +     gg(mySmooth, aes(color = mean), size = 3)    # However, we are often interested in a spatial field and thus a linear interpolation,   # which can be achieved by using the gg mechanism for meshes    ggplot() +     gg(gorillas$mesh, color = mySmooth$mean)    # Alternatively, we can predict the spatial field at a grid of locations, e.g. a   # SpatialPixels object covering the mesh    pxl <- pixels(gorillas$mesh)   mySmooth2 <- predict(fit, pxl, ~mySmooth)    # This will give us a SpatialPixelDataFrame with the columns we are looking for    head(mySmooth2)   ggplot() +     gg(mySmooth2) } #> Current num.threads is '1:1'. #> No num.threads change needed. #> Regions defined for each Polygons #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition  # }"},{"path":"/reference/predict.inla.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction from fitted inla model — predict.inla","title":"Prediction from fitted inla model — predict.inla","text":"method supported plain inla objects. Please see predict.bru() instead. method supported plain inla objects. Please see generate.bru() instead. See https://github.com/fbachl/inlabru/issues/78 information.","code":""},{"path":"/reference/predict.inla.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction from fitted inla model — predict.inla","text":"","code":"# S3 method for inla predict(object, ...)  # S3 method for inla generate(object, ...)"},{"path":"/reference/predict.inla.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction from fitted inla model — predict.inla","text":"object inla object obtained calling INLA::inla(). ... additional arguments passed togenerate.bru.","code":""},{"path":"/reference/predict.inla.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prediction from fitted inla model — predict.inla","text":"prediction object. List generated samples","code":""},{"path":[]},{"path":"/reference/predict.inla.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prediction from fitted inla model — predict.inla","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"/reference/refine.inla.mesh.html","id":null,"dir":"Reference","previous_headings":"","what":"Refine an inla.mesh object — refine.inla.mesh","title":"Refine an inla.mesh object — refine.inla.mesh","text":"Refine inla.mesh object","code":""},{"path":"/reference/refine.inla.mesh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Refine an inla.mesh object — refine.inla.mesh","text":"","code":"refine.inla.mesh(mesh, refine = list(max.edge = 1))"},{"path":"/reference/refine.inla.mesh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Refine an inla.mesh object — refine.inla.mesh","text":"mesh inla.mesh object refine list refinement options passed INLA::inla.mesh.create","code":""},{"path":"/reference/refine.inla.mesh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Refine an inla.mesh object — refine.inla.mesh","text":"mesh refined inla.mesh object","code":""},{"path":"/reference/refine.inla.mesh.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Refine an inla.mesh object — refine.inla.mesh","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"/reference/robins_subset.html","id":null,"dir":"Reference","previous_headings":"","what":"robins_subset — robins_subset","title":"robins_subset — robins_subset","text":"robins_subset dataset, subset full robins data set used demonstrate spatially varying trend coefficient model Meehan et al. 2019. dataset includes American Robin counts, along time, location, effort information, Audubon Christimas Bird Counts (CBC) conducted six US states 1987 2016.","code":""},{"path":"/reference/robins_subset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"robins_subset — robins_subset","text":"","code":"data(robins_subset)"},{"path":"/reference/robins_subset.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"robins_subset — robins_subset","text":"data data.frame variables circle: Four-letter code CBC circle. bcr: Numeric code bird conservation region encompassing count circle. state: US state encompassing count circle. year: calendar year count conducted. std_yr: transformed year, 2016 = 0. count: number robins recorded. log_hrs: natural log party hours. lon: longitude count circle centroid. lat: latitude count circle centroid. obs: unique record identifier.","code":""},{"path":"/reference/robins_subset.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"robins_subset — robins_subset","text":"https://github.com/tmeeha/inlaSVCBC","code":""},{"path":"/reference/robins_subset.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"robins_subset — robins_subset","text":"Meehan, T.D., Michel, N.L., Rue, H. 2019. Spatial modeling Audubon Christmas Bird Counts reveals fine-scale patterns drivers relative abundance trends. Ecosphere, 10(4), p.e02707.","code":""},{"path":"/reference/robins_subset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"robins_subset — robins_subset","text":"","code":"if (require(ggplot2, quietly = TRUE)) {   data(robins_subset, package = \"inlabru\") # get the data    # plot the counts for one year of data   ggplot(robins_subset[robins_subset$std_yr == 0, ]) +     geom_point(aes(lon, lat, colour = count + 1)) +     scale_colour_gradient(low = \"blue\", high = \"red\", trans = \"log\") }"},{"path":"/reference/row_kron.html","id":null,"dir":"Reference","previous_headings":"","what":"Row-wise Kronecker products — row_kron","title":"Row-wise Kronecker products — row_kron","text":"Takes two Matrices computes row-wise Kronecker product.  Optionally applies row-wise weights /applies additional 0/1 row-wise Kronecker matrix product.","code":""},{"path":"/reference/row_kron.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Row-wise Kronecker products — row_kron","text":"","code":"row_kron(M1, M2, repl = NULL, n.repl = NULL, weights = NULL)"},{"path":"/reference/row_kron.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Row-wise Kronecker products — row_kron","text":"M1 matrix can transformed sparse Matrix. M2 matrix can transformed sparse Matrix. repl optional index vector.  entry, specifies replicate row belongs , sense used INLA::inla.spde.make.n.repl maximum replicate index, sense used INLA::inla.spde.make.(). weights Optional scaling weights applied row-wise resulting matrix.","code":""},{"path":"/reference/row_kron.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Row-wise Kronecker products — row_kron","text":"Matrix::sparseMatrix object.","code":""},{"path":"/reference/row_kron.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Row-wise Kronecker products — row_kron","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"/reference/sample.lgcp.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from an inhomogeneous Poisson process — sample.lgcp","title":"Sample from an inhomogeneous Poisson process — sample.lgcp","text":"function provides point samples one- two-dimensional inhomogeneous Poisson processes. log intensity provided via values nodes inla.mesh.1d inla.mesh object. mesh nodes log intensity assumed linear.","code":""},{"path":"/reference/sample.lgcp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from an inhomogeneous Poisson process — sample.lgcp","text":"","code":"sample.lgcp(   mesh,   loglambda,   strategy = NULL,   R = NULL,   samplers = NULL,   ignore.CRS = FALSE )"},{"path":"/reference/sample.lgcp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from an inhomogeneous Poisson process — sample.lgcp","text":"mesh INLA::inla.mesh object loglambda vector matrix; vector log intensities mesh vertices (higher order basis functions, e.g. inla.mesh.1d meshes, loglambda given mesh$m basis function weights rather values mesh$n vertices) single scalar expanded vector appropriate length. matrix supplied, one process sample column produced. strategy relevant 2D meshes. One 'triangulated', 'rectangle', 'sliced-spherical', 'spherical'. 'rectangle' method valid CRS-less flat 2D meshes. NULL 'auto', likely fastest method chosen; 'rectangle' flat 2D meshes CRS, 'sliced-spherical' CRS 'longlat' meshes, 'triangulated' meshes. R Numerical value applicable spherical geographical meshes. interpreted R equivalent Earth radius, km, used scale lambda intensity. CRS enabled meshes, default 6371. CRS-less spherical meshes, default 1. samplers SpatialPolygonsDataFrame inla.mesh object. Simulated points fall outside polygons discarded. ignore.CRS logical; TRUE, ignore CRS information mesh. Default FALSE. affects R permitted values strategy.","code":""},{"path":"/reference/sample.lgcp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from an inhomogeneous Poisson process — sample.lgcp","text":"data.frame (1D case), SpatialPoints (2D flat 3D spherical surface cases) SpatialPointsDataFrame (2D/3D surface cases multiple samples). multiple samples, data.frame output column 'sample' giving index sample. object point locations.","code":""},{"path":"/reference/sample.lgcp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample from an inhomogeneous Poisson process — sample.lgcp","text":"2D processes sphere R parameter can used adjust sphere's radius implied mesh. intensity high standard strategy \"spherical\" can cause memory issues. Using \"sliced-spherical\" strategy can help case. crs-less meshes R2: Lambda interpreted raw coordinate system. Output NA CRS. crs-less meshes S2: Lambda raw units, scaling mesh radius R, specified. Output given domain mesh, NA CRS. crs meshes R2: Lambda interpreted per km^2, scaling globe Earth radius 6371 km, R, specified. Output given CRS mesh. crs meshes S2: Lambda interpreted per km^2, scaling globe Earth radius 6371 km, R, specified. Output given CRS mesh.","code":""},{"path":"/reference/sample.lgcp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Sample from an inhomogeneous Poisson process — sample.lgcp","text":"Daniel Simpson dp.simpson@gmail.com (base rectangle spherical algorithms), Fabian E. Bachl bachlfab@gmail.com (inclusion inlabru, sliced spherical sampling), Finn Lindgren finn.lindgren@gmail.com (extended CRS support, triangulated sampling)","code":""},{"path":"/reference/sample.lgcp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from an inhomogeneous Poisson process — sample.lgcp","text":"","code":"# \\donttest{ # The INLA package is required if (bru_safe_inla(quietly = TRUE)) {   vertices <- seq(0, 3, by = 0.1)   mesh <- INLA::inla.mesh.1d(vertices)   loglambda <- 5 - 0.5 * vertices   pts <- sample.lgcp(mesh, loglambda)   pts$y <- 0   plot(vertices, exp(loglambda), type = \"l\", ylim = c(0, 150))   points(pts, pch = \"|\") }  # }  # \\donttest{ # The INLA package and PROJ6 are required if (bru_safe_inla(quietly = TRUE) &&   fm_has_PROJ6() &&   require(ggplot2, quietly = TRUE)) {   data(\"gorillas\", package = \"inlabru\")   pts <- sample.lgcp(gorillas$mesh,     loglambda = 1.5,     samplers = gorillas$boundary   )   ggplot() +     gg(gorillas$mesh) +     gg(pts) } #> Warning: 'fm_CRSargs()' should not be used with PROJ6 and rgdal v3 #> Call stack: #> 1: pkgdown::build_site_github_pages(new_process = FALSE, install = FALSE) #> 2: build_site(pkg, preview = FALSE, install = install, new_process = new_process,  #>        ...) #> 3: build_site_local(pkg = pkg, examples = examples, run_dont_run = run_dont_run,  #>        seed = seed, lazy = lazy, override = override, preview = preview,  #>        devel = devel) #> 4: build_reference(pkg, lazy = lazy, examples = examples, run_dont_run = run_ [...] #>        seed = seed, override = override, preview = FALSE, devel = devel) #> 5: purrr::map(topics, build_reference_topic, pkg = pkg, lazy = lazy,  #>        examples_env = examples_env, run_dont_run = run_dont_run) #> 6: .f(.x[[i]], ...) #> 7: withCallingHandlers(data_reference_topic(topic, pkg, examples_env = exampl [...] #>        run_dont_run = run_dont_run), error = function(err) { #>        msg <- c(paste0(\"Failed to parse Rd in \", topic$file_in),  #>            i = err$message) #>        abort(msg, parent = err) #>    }) #> 8: data_reference_topic(topic, pkg, examples_env = examples_env,  #>        run_dont_run = run_dont_run) #> 9: run_examples(tags$tag_examples[[1]], env = if (is.null(examples_env)) NULL [...] #>        topic = tools::file_path_sans_ext(topic$file_in), run_dont_run = run_d [...] #> 10: highlight_examples(code, topic, env = env) #> 11: downlit::evaluate_and_highlight(code, fig_save = fig_save_topic,  #>        env = child_env(env), output_handler = evaluate::new_output_handler(va [...] #> 12: evaluate::evaluate(code, child_env(env), new_device = TRUE, output_handler [...] #> 13: evaluate_call(expr, parsed$src[[i]], envir = envir, enclos = enclos,  #>        debug = debug, last = i == length(out), use_try = stop_on_error !=  #>            2L, keep_warning = keep_warning, keep_message = keep_message,  #>        output_handler = output_handler, include_timing = include_timing) #> 14: timing_fn(handle(ev <- withCallingHandlers(withVisible(eval_with_user_hand [...] #>        envir, enclos, user_handlers)), warning = wHandler, error = eHandler,  #>        message = mHandler))) #> 15: handle(ev <- withCallingHandlers(withVisible(eval_with_user_handlers(expr,  #>        envir, enclos, user_handlers)), warning = wHandler, error = eHandler,  #>        message = mHandler)) #> 16: try(f, silent = TRUE) #> 17: tryCatch(expr, error = function(e) { #>        call <- conditionCall(e) #>        if (!is.null(call)) { #>            if (identical(call[[1L]], quote(doTryCatch)))  #>                call <- sys.call(-4L) #>            dcall <- deparse(call, nlines = 1L) #>            prefix <- paste(\"Error in\", dcall, \": \") #>            LONG <- 75L #>            sm <- strsplit(conditionMessage(e), \"\\n\")[[1L]] #>            w <- 14L + nchar(dcall, type = \"w\") + nchar(sm[1L], type = \"w\") #>            if (is.na(w))  #>                w <- 14L + nchar(dcall, type = \"b\") + nchar(sm[1L],  #>                    type = \"b\") #>            if (w > LONG)  #>                prefix <- paste0(prefix, \"\\n  \") #>        } #>        else prefix <- \"Error : \" #>        msg <- paste0(prefix, conditionMessage(e), \"\\n\") #>        .Internal(seterrmessage(msg[1L])) #>        if (!silent && isTRUE(getOption(\"show.error.messages\"))) { #>            cat(msg, file = outFile) #>            .Internal(printDeferredWarnings()) #>        } #>        invisible(structure(msg, class = \"try-error\", condition = e)) #>    }) #> 18: tryCatchList(expr, classes, parentenv, handlers) #> 19: tryCatchOne(expr, names, parentenv, handlers[[1L]]) #> 20: doTryCatch(return(expr), name, parentenv, handler) #> 21: withCallingHandlers(withVisible(eval_with_user_handlers(expr,  #>        envir, enclos, user_handlers)), warning = wHandler, error = eHandler,  #>        message = mHandler) #> 22: withVisible(eval_with_user_handlers(expr, envir, enclos, user_handlers)) #> 23: eval_with_user_handlers(expr, envir, enclos, user_handlers) #> 24: eval(expr, envir, enclos) #> 25: eval(expr, envir, enclos) #> 26: sample.lgcp(gorillas$mesh, loglambda = 1.5, samplers = gorillas$boundary) #> 27: fm_CRS(fm_CRSargs(mesh$crs)) #> 28: fm_CRSargs(mesh$crs) #> 29: fm_not_for_PROJ6() #> 30: paste0(\"Call stack:\\n\", paste0(fm_call_stack(end = 1), collapse = \"\\n\")) #> Warning: 'fm_CRS' should be given a SRS_string for PROJ6 or a known keyword for a predefined string given in projargs. Using fallback PROJ4 method. #> Warning: 'fm_CRSargs_as_list()' should not be used with PROJ6 and rgdal v3 #> Call stack: #> 1: pkgdown::build_site_github_pages(new_process = FALSE, install = FALSE) #> 2: build_site(pkg, preview = FALSE, install = install, new_process = new_process,  #>        ...) #> 3: build_site_local(pkg = pkg, examples = examples, run_dont_run = run_dont_run,  #>        seed = seed, lazy = lazy, override = override, preview = preview,  #>        devel = devel) #> 4: build_reference(pkg, lazy = lazy, examples = examples, run_dont_run = run_ [...] #>        seed = seed, override = override, preview = FALSE, devel = devel) #> 5: purrr::map(topics, build_reference_topic, pkg = pkg, lazy = lazy,  #>        examples_env = examples_env, run_dont_run = run_dont_run) #> 6: .f(.x[[i]], ...) #> 7: withCallingHandlers(data_reference_topic(topic, pkg, examples_env = exampl [...] #>        run_dont_run = run_dont_run), error = function(err) { #>        msg <- c(paste0(\"Failed to parse Rd in \", topic$file_in),  #>            i = err$message) #>        abort(msg, parent = err) #>    }) #> 8: data_reference_topic(topic, pkg, examples_env = examples_env,  #>        run_dont_run = run_dont_run) #> 9: run_examples(tags$tag_examples[[1]], env = if (is.null(examples_env)) NULL [...] #>        topic = tools::file_path_sans_ext(topic$file_in), run_dont_run = run_d [...] #> 10: highlight_examples(code, topic, env = env) #> 11: downlit::evaluate_and_highlight(code, fig_save = fig_save_topic,  #>        env = child_env(env), output_handler = evaluate::new_output_handler(va [...] #> 12: evaluate::evaluate(code, child_env(env), new_device = TRUE, output_handler [...] #> 13: evaluate_call(expr, parsed$src[[i]], envir = envir, enclos = enclos,  #>        debug = debug, last = i == length(out), use_try = stop_on_error !=  #>            2L, keep_warning = keep_warning, keep_message = keep_message,  #>        output_handler = output_handler, include_timing = include_timing) #> 14: timing_fn(handle(ev <- withCallingHandlers(withVisible(eval_with_user_hand [...] #>        envir, enclos, user_handlers)), warning = wHandler, error = eHandler,  #>        message = mHandler))) #> 15: handle(ev <- withCallingHandlers(withVisible(eval_with_user_handlers(expr,  #>        envir, enclos, user_handlers)), warning = wHandler, error = eHandler,  #>        message = mHandler)) #> 16: try(f, silent = TRUE) #> 17: tryCatch(expr, error = function(e) { #>        call <- conditionCall(e) #>        if (!is.null(call)) { #>            if (identical(call[[1L]], quote(doTryCatch)))  #>                call <- sys.call(-4L) #>            dcall <- deparse(call, nlines = 1L) #>            prefix <- paste(\"Error in\", dcall, \": \") #>            LONG <- 75L #>            sm <- strsplit(conditionMessage(e), \"\\n\")[[1L]] #>            w <- 14L + nchar(dcall, type = \"w\") + nchar(sm[1L], type = \"w\") #>            if (is.na(w))  #>                w <- 14L + nchar(dcall, type = \"b\") + nchar(sm[1L],  #>                    type = \"b\") #>            if (w > LONG)  #>                prefix <- paste0(prefix, \"\\n  \") #>        } #>        else prefix <- \"Error : \" #>        msg <- paste0(prefix, conditionMessage(e), \"\\n\") #>        .Internal(seterrmessage(msg[1L])) #>        if (!silent && isTRUE(getOption(\"show.error.messages\"))) { #>            cat(msg, file = outFile) #>            .Internal(printDeferredWarnings()) #>        } #>        invisible(structure(msg, class = \"try-error\", condition = e)) #>    }) #> 18: tryCatchList(expr, classes, parentenv, handlers) #> 19: tryCatchOne(expr, names, parentenv, handlers[[1L]]) #> 20: doTryCatch(return(expr), name, parentenv, handler) #> 21: withCallingHandlers(withVisible(eval_with_user_handlers(expr,  #>        envir, enclos, user_handlers)), warning = wHandler, error = eHandler,  #>        message = mHandler) #> 22: withVisible(eval_with_user_handlers(expr, envir, enclos, user_handlers)) #> 23: eval_with_user_handlers(expr, envir, enclos, user_handlers) #> 24: eval(expr, envir, enclos) #> 25: eval(expr, envir, enclos) #> 26: sample.lgcp(gorillas$mesh, loglambda = 1.5, samplers = gorillas$boundary) #> 27: fm_CRSargs_as_list(fm_CRSargs(input.crs)) #> 28: fm_not_for_PROJ6() #> 29: paste0(\"Call stack:\\n\", paste0(fm_call_stack(end = 1), collapse = \"\\n\")) #> Warning: 'fm_CRSargs()' should not be used with PROJ6 and rgdal v3 #> Call stack: #> 1: pkgdown::build_site_github_pages(new_process = FALSE, install = FALSE) #> 2: build_site(pkg, preview = FALSE, install = install, new_process = new_process,  #>        ...) #> 3: build_site_local(pkg = pkg, examples = examples, run_dont_run = run_dont_run,  #>        seed = seed, lazy = lazy, override = override, preview = preview,  #>        devel = devel) #> 4: build_reference(pkg, lazy = lazy, examples = examples, run_dont_run = run_ [...] #>        seed = seed, override = override, preview = FALSE, devel = devel) #> 5: purrr::map(topics, build_reference_topic, pkg = pkg, lazy = lazy,  #>        examples_env = examples_env, run_dont_run = run_dont_run) #> 6: .f(.x[[i]], ...) #> 7: withCallingHandlers(data_reference_topic(topic, pkg, examples_env = exampl [...] #>        run_dont_run = run_dont_run), error = function(err) { #>        msg <- c(paste0(\"Failed to parse Rd in \", topic$file_in),  #>            i = err$message) #>        abort(msg, parent = err) #>    }) #> 8: data_reference_topic(topic, pkg, examples_env = examples_env,  #>        run_dont_run = run_dont_run) #> 9: run_examples(tags$tag_examples[[1]], env = if (is.null(examples_env)) NULL [...] #>        topic = tools::file_path_sans_ext(topic$file_in), run_dont_run = run_d [...] #> 10: highlight_examples(code, topic, env = env) #> 11: downlit::evaluate_and_highlight(code, fig_save = fig_save_topic,  #>        env = child_env(env), output_handler = evaluate::new_output_handler(va [...] #> 12: evaluate::evaluate(code, child_env(env), new_device = TRUE, output_handler [...] #> 13: evaluate_call(expr, parsed$src[[i]], envir = envir, enclos = enclos,  #>        debug = debug, last = i == length(out), use_try = stop_on_error !=  #>            2L, keep_warning = keep_warning, keep_message = keep_message,  #>        output_handler = output_handler, include_timing = include_timing) #> 14: timing_fn(handle(ev <- withCallingHandlers(withVisible(eval_with_user_hand [...] #>        envir, enclos, user_handlers)), warning = wHandler, error = eHandler,  #>        message = mHandler))) #> 15: handle(ev <- withCallingHandlers(withVisible(eval_with_user_handlers(expr,  #>        envir, enclos, user_handlers)), warning = wHandler, error = eHandler,  #>        message = mHandler)) #> 16: try(f, silent = TRUE) #> 17: tryCatch(expr, error = function(e) { #>        call <- conditionCall(e) #>        if (!is.null(call)) { #>            if (identical(call[[1L]], quote(doTryCatch)))  #>                call <- sys.call(-4L) #>            dcall <- deparse(call, nlines = 1L) #>            prefix <- paste(\"Error in\", dcall, \": \") #>            LONG <- 75L #>            sm <- strsplit(conditionMessage(e), \"\\n\")[[1L]] #>            w <- 14L + nchar(dcall, type = \"w\") + nchar(sm[1L], type = \"w\") #>            if (is.na(w))  #>                w <- 14L + nchar(dcall, type = \"b\") + nchar(sm[1L],  #>                    type = \"b\") #>            if (w > LONG)  #>                prefix <- paste0(prefix, \"\\n  \") #>        } #>        else prefix <- \"Error : \" #>        msg <- paste0(prefix, conditionMessage(e), \"\\n\") #>        .Internal(seterrmessage(msg[1L])) #>        if (!silent && isTRUE(getOption(\"show.error.messages\"))) { #>            cat(msg, file = outFile) #>            .Internal(printDeferredWarnings()) #>        } #>        invisible(structure(msg, class = \"try-error\", condition = e)) #>    }) #> 18: tryCatchList(expr, classes, parentenv, handlers) #> 19: tryCatchOne(expr, names, parentenv, handlers[[1L]]) #> 20: doTryCatch(return(expr), name, parentenv, handler) #> 21: withCallingHandlers(withVisible(eval_with_user_handlers(expr,  #>        envir, enclos, user_handlers)), warning = wHandler, error = eHandler,  #>        message = mHandler) #> 22: withVisible(eval_with_user_handlers(expr, envir, enclos, user_handlers)) #> 23: eval_with_user_handlers(expr, envir, enclos, user_handlers) #> 24: eval(expr, envir, enclos) #> 25: eval(expr, envir, enclos) #> 26: sample.lgcp(gorillas$mesh, loglambda = 1.5, samplers = gorillas$boundary) #> 27: fm_CRSargs_as_list(fm_CRSargs(input.crs)) #> 28: fm_CRSargs(input.crs) #> 29: fm_not_for_PROJ6() #> 30: paste0(\"Call stack:\\n\", paste0(fm_call_stack(end = 1), collapse = \"\\n\")) #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition  # }"},{"path":"/reference/seals.html","id":null,"dir":"Reference","previous_headings":"","what":"Seal pups — seals","title":"Seal pups — seals","text":"single transect aereal photo seal pup survey Greenland Sea","code":""},{"path":"/reference/seals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Seal pups — seals","text":"","code":"data(seals)"},{"path":"/reference/seals.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Seal pups — seals","text":"data contain objects: points: SpatialPointsDataFrame Center locations photos mesh: inla.mesh enclosing plane's transect ice.data: SpatialPointsDataFrame MODIS ice concentration estimates ice.cv: covdata object interpolated ice coverage data","code":""},{"path":"/reference/seals.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Seal pups — seals","text":"Martin Jullum Martin.Jullum@nr.","code":""},{"path":"/reference/seals.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Seal pups — seals","text":"Oigard, T. . (2013) pup production quotas: current status harp seals Greenland Sea. ICES Journal Marine Science, doi.10.1093/icesjms/fst155. Oigard, T. . (2014) Current status hooded seals Greenland Sea. Victims climate change predation?, Biological Conservation , 2014, 172, 29 - 36.","code":""},{"path":"/reference/seals.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Seal pups — seals","text":"","code":"if (require(ggplot2, quietly = TRUE)) {   data(seals, package = \"inlabru\")   ggplot() +     gg(seals$mesh) +     gg(seals$points) }"},{"path":"/reference/shrimp.html","id":null,"dir":"Reference","previous_headings":"","what":"Blue and red shrimp in the Western Mediterranean Sea — shrimp","title":"Blue and red shrimp in the Western Mediterranean Sea — shrimp","text":"Blue red shrimp Western Mediterranean Sea.","code":""},{"path":"/reference/shrimp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Blue and red shrimp in the Western Mediterranean Sea — shrimp","text":"","code":"data(shrimp)"},{"path":"/reference/shrimp.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Blue and red shrimp in the Western Mediterranean Sea — shrimp","text":"list objects: haul: SpatialPointsDataFrame object containing haul locations mesh: inla.mesh object containing Delaunay triangulation mesh (type discretization continuous space) covering haul locations.","code":""},{"path":"/reference/shrimp.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Blue and red shrimp in the Western Mediterranean Sea — shrimp","text":"Pennino, Maria Grazia. Personal communication.","code":""},{"path":"/reference/shrimp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Blue and red shrimp in the Western Mediterranean Sea — shrimp","text":"Pennino, M. G., Paradinas, ., Munoz, F., Illian, J.,Quilez-Lopez, ., Bellido, J.M., Conesa, D. Accounting preferential sampling species distribution models. Ecology Evolution,  Press.","code":""},{"path":"/reference/shrimp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Blue and red shrimp in the Western Mediterranean Sea — shrimp","text":"","code":"# \\donttest{ if (require(ggplot2, quietly = TRUE)) {   data(shrimp, package = \"inlabru\")   ggplot() +     gg(shrimp$mesh) +     gg(shrimp$hauls) +     coord_equal() }  # }"},{"path":"/reference/sline.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert data frame to SpatialLinesDataFrame — sline","title":"Convert data frame to SpatialLinesDataFrame — sline","text":"line 2D space defined start point, associated 2D coordinates. function takes /codedata.frame input assumes row defines line space. order , data frame must least four columns start.cols end.cols parameters must used point names columns define start end coordinates line. data converted SpatialLinesDataFrame DF. coordinate reference system crs provided attached DF. also .crs provided, coordinate system DF transfromed accordingly. Additional columns input data, e.g. covariates, retained attached DF.","code":""},{"path":"/reference/sline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert data frame to SpatialLinesDataFrame — sline","text":"","code":"sline(data, start.cols, end.cols, crs = CRS(as.character(NA)), to.crs = NULL)"},{"path":"/reference/sline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert data frame to SpatialLinesDataFrame — sline","text":"data data.frame start.cols Character array poitning columns data hold start points lines end.cols Character array poitning columns data hold end points lines crs Coordinate reference system original data .crs Coordinate reference system SpatialLines ouput.","code":""},{"path":"/reference/sline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert data frame to SpatialLinesDataFrame — sline","text":"SpatialLinesDataFrame","code":""},{"path":"/reference/sline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert data frame to SpatialLinesDataFrame — sline","text":"","code":"# \\donttest{ # Create a data frame defining three lines lns <- data.frame(   xs = c(1, 2, 3), ys = c(1, 1, 1), # start points   xe = c(2, 3, 4), ye = c(2, 2, 2) ) # end points   # Conversion to SpatialLinesDataFrame without CRS spl <- sline(lns,   start.cols = c(\"xs\", \"ys\"),   end.cols = c(\"xe\", \"ye\") )  if (require(ggplot2, quietly = TRUE)) {   # Plot the lines   ggplot() +     gg(spl) }  # }"},{"path":"/reference/spatial.to.ppp.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert SpatialPoints and boundary polygon to spatstat ppp object — spatial.to.ppp","title":"Convert SpatialPoints and boundary polygon to spatstat ppp object — spatial.to.ppp","text":"Spatstat point pattern objects consist points observation windows. function uses SpatialPoints object SpatialPolygon object generate points window. Lastly, ppp() function called create ppp object.","code":""},{"path":"/reference/spatial.to.ppp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert SpatialPoints and boundary polygon to spatstat ppp object — spatial.to.ppp","text":"","code":"spatial.to.ppp(points, samplers)"},{"path":"/reference/spatial.to.ppp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert SpatialPoints and boundary polygon to spatstat ppp object — spatial.to.ppp","text":"points SpatialPoints[DataFrame] object describing point pattern. samplers SpatialPolygons[DataFrame] object describing observation window.","code":""},{"path":"/reference/spatial.to.ppp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert SpatialPoints and boundary polygon to spatstat ppp object — spatial.to.ppp","text":"spatstat spatstat  ppp object","code":""},{"path":"/reference/spatial.to.ppp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert SpatialPoints and boundary polygon to spatstat ppp object — spatial.to.ppp","text":"","code":"# \\donttest{ if (require(\"spatstat.geom\")) {   # Load Gorilla data    data(\"gorillas\", package = \"inlabru\")    # Use nest locations and survey boundary to create a spatstat ppp object    gp <- spatial.to.ppp(gorillas$nests, gorillas$boundary)   class(gp)    # Plot it    plot(gp) } #> Loading required package: spatstat.geom #> Loading required package: spatstat.data #>  #> Attaching package: ‘spatstat.data’ #> The following object is masked _by_ ‘.GlobalEnv’: #>  #>     gorillas #> spatstat.geom 2.4-0 #>  #> Attaching package: ‘spatstat.geom’ #> The following objects are masked from ‘package:raster’: #>  #>     area, rotate, shift #> The following object is masked from ‘package:inlabru’: #>  #>     vertices #> Warning: data contain duplicated points  # }"},{"path":"/reference/spde.posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Posteriors of SPDE hyper parameters and Matern correlation or covariance function. — spde.posterior","title":"Posteriors of SPDE hyper parameters and Matern correlation or covariance function. — spde.posterior","text":"Calculate posterior distribution range, log(range), variance, log(variance) parameter model's SPDE component. Can also plot Matern correlation covariance function. inla.spde.result.","code":""},{"path":"/reference/spde.posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posteriors of SPDE hyper parameters and Matern correlation or covariance function. — spde.posterior","text":"","code":"spde.posterior(result, name, what = \"range\")"},{"path":"/reference/spde.posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posteriors of SPDE hyper parameters and Matern correlation or covariance function. — spde.posterior","text":"result object inheriting inla. name Character stating name SPDE effect, see names(result$summary.random). One \"range\", \"log.range\", \"variance\", \"log.variance\", \"matern.correlation\" \"matern.covariance\".","code":""},{"path":"/reference/spde.posterior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posteriors of SPDE hyper parameters and Matern correlation or covariance function. — spde.posterior","text":"prediction object.","code":""},{"path":"/reference/spde.posterior.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Posteriors of SPDE hyper parameters and Matern correlation or covariance function. — spde.posterior","text":"Finn Lindgren Finn.Lindgren@ed.ac.uk","code":""},{"path":"/reference/spde.posterior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Posteriors of SPDE hyper parameters and Matern correlation or covariance function. — spde.posterior","text":"","code":"# \\donttest{ if (bru_safe_inla() && require(ggplot2, quietly = TRUE)) {    # Load 1D Poisson process data    data(Poisson2_1D, package = \"inlabru\")     # Take a look at the point (and frequency) data    ggplot(pts2) +     geom_histogram(aes(x = x), binwidth = 55 / 20, boundary = 0, fill = NA, color = \"black\") +     geom_point(aes(x), y = 0, pch = \"|\", cex = 4) +     coord_fixed(ratio = 1)    # Fit an LGCP model with  and SPDE component    x <- seq(0, 55, length = 20)   mesh1D <- INLA::inla.mesh.1d(x, boundary = \"free\")   mdl <- x ~ spde1D(x, model = INLA::inla.spde2.matern(mesh1D)) + Intercept   fit <- lgcp(mdl, data = pts2, domain = list(x = mesh1D))    # Calculate and plot the posterior range    range <- spde.posterior(fit, \"spde1D\", \"range\")   plot(range)    # Calculate and plot the posterior log range    lrange <- spde.posterior(fit, \"spde1D\", \"log.range\")   plot(lrange)    # Calculate and plot the posterior variance    variance <- spde.posterior(fit, \"spde1D\", \"variance\")   plot(variance)    # Calculate and plot the posterior log variance    lvariance <- spde.posterior(fit, \"spde1D\", \"log.variance\")   plot(lvariance)    # Calculate and plot the posterior Matern correlation    matcor <- spde.posterior(fit, \"spde1D\", \"matern.correlation\")   plot(matcor)    # Calculate and plot the posterior Matern covariance    matcov <- spde.posterior(fit, \"spde1D\", \"matern.covariance\")   plot(matcov) } #> Warning: All covariate evaluations for 'Intercept' are NULL; an intercept component was likely intended. #>   Implicit latent intercept component specification is deprecated since version 2.1.14. #>   Use explicit notation '+ Intercept(1)' instead (or '+1' for '+ Intercept(1)').  # }"},{"path":"/reference/split_lines.html","id":null,"dir":"Reference","previous_headings":"","what":"Split lines at mesh edges — split_lines","title":"Split lines at mesh edges — split_lines","text":"Split lines mesh edges","code":""},{"path":"/reference/split_lines.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split lines at mesh edges — split_lines","text":"","code":"split_lines(mesh, sp, ep, filter.zero.length = TRUE)"},{"path":"/reference/split_lines.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split lines at mesh edges — split_lines","text":"mesh inla.mesh object sp Start points lines ep End points lines filter.zero.length Filter segments zero length? (Bool) ... argments int.quadrature","code":""},{"path":"/reference/split_lines.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split lines at mesh edges — split_lines","text":"List start end points resulting splitting given lines","code":""},{"path":"/reference/split_lines.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Split lines at mesh edges — split_lines","text":"Fabian E. Bachl f.e.bachl@bath.ac.uk","code":""},{"path":"/reference/spoly.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a data.frame of boundary points into a SpatialPolgonsDataFrame — spoly","title":"Convert a data.frame of boundary points into a SpatialPolgonsDataFrame — spoly","text":"polygon can described sequence points defining polygon's boundary. given sequence (anti clockwise!) function creates SpatialPolygonsDataFrame holding polygon decribed. default, first two columns data assumed define x y coordinates points. behavior can ba changed using cols parameter, points names columns holding coordinates. coordinate reference system resulting spatial polygon can set via crs paraemter. Posterior conversion different CRS supported using .crs parameter.","code":""},{"path":"/reference/spoly.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a data.frame of boundary points into a SpatialPolgonsDataFrame — spoly","text":"","code":"spoly(   data,   cols = colnames(data)[1:2],   crs = CRS(NA_character_),   to.crs = NULL )"},{"path":"/reference/spoly.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a data.frame of boundary points into a SpatialPolgonsDataFrame — spoly","text":"data data.frame points describing boundary polygon cols Column names x y coordinates within data crs Coordinate reference system points .crs Coordinate reference system SpatialLines ouput.","code":""},{"path":"/reference/spoly.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a data.frame of boundary points into a SpatialPolgonsDataFrame — spoly","text":"SpatialPolygonsDataFrame","code":""},{"path":"/reference/spoly.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a data.frame of boundary points into a SpatialPolgonsDataFrame — spoly","text":"","code":"# \\donttest{ # Create data frame of boundary points (anti clockwise!) pts <- data.frame(   x = c(1, 2, 1.7, 1.3),   y = c(1, 1, 2, 2) )  # Convert to SpatialPolygonsDataFrame pol <- spoly(pts)  if (require(ggplot2, quietly = TRUE) &&   require(ggpolypath, quietly = TRUE)) {   # Plot it!   ggplot() +     gg(pol) } #> Regions defined for each Polygons  # }"},{"path":"/reference/stransform.html","id":null,"dir":"Reference","previous_headings":"","what":"Coordinate transformation for spatial objects — stransform","title":"Coordinate transformation for spatial objects — stransform","text":"wrapper spTransform function provided sp package. Given spatial object (list thereof) transform coordinate system according parameter crs. addition usual spatial objects function also capables transforming INLA::inla.mesh objects equipped coordinate system.#'","code":""},{"path":"/reference/stransform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coordinate transformation for spatial objects — stransform","text":"","code":"stransform(splist, crs)"},{"path":"/reference/stransform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coordinate transformation for spatial objects — stransform","text":"splist list Spatial* objects crs Coordinate reference system change ","code":""},{"path":"/reference/stransform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coordinate transformation for spatial objects — stransform","text":"List Spatial* objects","code":""},{"path":"/reference/stransform.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coordinate transformation for spatial objects — stransform","text":"","code":"# \\donttest{ # Load Gorilla data data(\"gorillas\", package = \"inlabru\")  # Take the mesh and transform it to latitude/longitude tmesh <- stransform(gorillas$mesh, crs = CRS(\"+proj=longlat\")) #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=1 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=longlat +R=6378137 +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition #> Warning: Discarded ellps unknown in Proj4 definition: +proj=geocent +R=1 +units=m +no_defs +type=crs #> Warning: Discarded datum unknown in Proj4 definition  # Compare original and transformed mesh  if (require(ggplot2, quietly = TRUE)) {   multiplot(     ggplot() +       gg(gorillas$mesh) +       ggtitle(\"Original mesh\"),     ggplot() +       gg(tmesh) +       ggtitle(\"Transformed mesh\")   ) }  # }"},{"path":"/reference/summary.bru.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary for an inlabru fit — summary.bru","title":"Summary for an inlabru fit — summary.bru","text":"Takes fitted bru object produced bru() lgcp() creates various summaries .","code":""},{"path":"/reference/summary.bru.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary for an inlabru fit — summary.bru","text":"","code":"# S3 method for bru summary(object, ...)  # S3 method for summary_bru print(x, ...)"},{"path":"/reference/summary.bru.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary for an inlabru fit — summary.bru","text":"object object obtained bru() lgcp() call ... ignored arguments x summary_bru2 object","code":""},{"path":"/reference/summary.bru.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary for an inlabru fit — summary.bru","text":"","code":"# \\donttest{ if (bru_safe_inla(multicore = FALSE)) {    # Simulate some covariates x and observations y   input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, y <- 5 + 2 * x + rnorm(10, mean = 0, sd = 0.1))    # Fit a Gaussian likelihood model   fit <- bru(y ~ x + Intercept, family = \"gaussian\", data = input.df)    # Obtain summary   fit$summary.fixed } #> Current num.threads is '1:1'. #> No num.threads change needed. #> Warning: All covariate evaluations for 'Intercept' are NULL; an intercept component was likely intended. #>   Implicit latent intercept component specification is deprecated since version 2.1.14. #>   Use explicit notation '+ Intercept(1)' instead (or '+1' for '+ Intercept(1)'). #>               mean         sd 0.025quant 0.5quant 0.975quant     mode #> x         2.018472 0.04802930   1.922441 2.018472   2.114498 2.018473 #> Intercept 5.017068 0.03396442   4.949159 5.017068   5.084972 5.017069 #>                    kld #> x         1.026020e-06 #> Intercept 1.022203e-06   if (bru_safe_inla(multicore = FALSE)) {    # Alternatively, we can use the like() function to construct the likelihood:    lik <- like(family = \"gaussian\", formula = y ~ x + Intercept, data = input.df)   fit <- bru(~ x + Intercept(1), lik)   fit$summary.fixed } #> Current num.threads is '1:1'. #> No num.threads change needed. #>               mean         sd 0.025quant 0.5quant 0.975quant     mode #> x         2.018472 0.04803055   1.922439 2.018472   2.114500 2.018473 #> Intercept 5.017068 0.03396531   4.949158 5.017068   5.084973 5.017069 #>                    kld #> x         1.030500e-06 #> Intercept 1.026669e-06  # An important addition to the INLA methodology is bru's ability to use # non-linear predictors. Such a predictor can be formulated via like()'s # \\code{formula} parameter. The z(1) notation is needed to ensure that # the z component should be interpreted as single latent variable and not # a covariate:  if (bru_safe_inla(multicore = FALSE)) {   z <- 2   input.df <- within(input.df, y <- 5 + exp(z) * x + rnorm(10, mean = 0, sd = 0.1))   lik <- like(     family = \"gaussian\", data = input.df,     formula = y ~ exp(z) * x + Intercept   )   fit <- bru(~ z(1) + Intercept(1), lik)    # Check the result (z posterior should be around 2)   fit$summary.fixed } #> Current num.threads is '1:1'. #> No num.threads change needed. #>               mean          sd 0.025quant 0.5quant 0.975quant     mode #> z         1.999145 0.006725715   1.985711 1.999145   2.012579 1.999146 #> Intercept 5.014824 0.034727715   4.945390 5.014825   5.084255 5.014826 #>                    kld #> z         8.437850e-07 #> Intercept 1.018356e-06 # }"},{"path":"/reference/summary.bru_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Print inlabru options — summary.bru_options","title":"Print inlabru options — summary.bru_options","text":"Print inlabru options","code":""},{"path":"/reference/summary.bru_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print inlabru options — summary.bru_options","text":"","code":"# S3 method for bru_options summary(   object,   legend = TRUE,   include_global = TRUE,   include_default = TRUE,   ... )  # S3 method for summary_bru_options print(x, ...)"},{"path":"/reference/summary.bru_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print inlabru options — summary.bru_options","text":"object bru_options object summarised legend logical; TRUE, include explanatory text, Default: TRUE include_global logical; TRUE, include global override options include_default logical; TRUE, include default options ... parameters, currently ignored x summary_bru_options object printed","code":""},{"path":"/reference/summary.bru_options.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print inlabru options — summary.bru_options","text":"","code":"if (interactive()) {   options <- bru_options(verbose = TRUE)    # Don't print options only set in default:   print(options, include_default = FALSE)    # Only include options set in the object:   print(options, include_default = FALSE, include_global = FALSE) }"},{"path":"/reference/summary.component.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise components — summary.component","title":"Summarise components — summary.component","text":"Summarise components","code":""},{"path":"/reference/summary.component.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise components — summary.component","text":"","code":"# S3 method for component summary(object, ...)  # S3 method for component_list summary(object, ...)  # S3 method for summary_component print(x, ...)  # S3 method for summary_component_list print(x, ...)"},{"path":"/reference/summary.component.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise components — summary.component","text":"object component component_list. ... ignored. x summary object printed.","code":""},{"path":"/reference/summary.component.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarise components — summary.component","text":"Fabian E. Bachl bachlfab@gmail.com Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"/reference/toygroups.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated 1D animal group locations and group sizes — toygroups","title":"Simulated 1D animal group locations and group sizes — toygroups","text":"data set serves teach concept modelling species gather groups grouping behaviour depends space.","code":""},{"path":"/reference/toygroups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated 1D animal group locations and group sizes — toygroups","text":"","code":"data(toygroups)"},{"path":"/reference/toygroups.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated 1D animal group locations and group sizes — toygroups","text":"data list contains elements: groups: data.frame group locations x size size df.size: IGNORE df.intensity: data.frame Poisson process intensity d.lambda locations x df.rate: data.frame locations x associated rate parameterized exponential distribution group sizes drawn.","code":""},{"path":"/reference/toygroups.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated 1D animal group locations and group sizes — toygroups","text":"","code":"# \\donttest{ if (require(ggplot2, quietly = TRUE)) {   # Load the data    data(\"toygroups\", package = \"inlabru\")    # The data set is a simulation of animal groups residing in a 1D space. Their   # locations in x-space are sampled from a Cox process with intensity    ggplot(toygroups$df.intensity) +     geom_line(aes(x = x, y = g.lambda))    # Adding the simulated group locations to this plot we obtain    ggplot(toygroups$df.intensity) +     geom_line(aes(x = x, y = g.lambda)) +     geom_point(data = toygroups$groups, aes(x, y = 0), pch = \"|\")    # Each group has a size mark attached to it.   # These group sizes are sampled from an exponential distribution   # for which the rate parameter depends on the x-coordinate    ggplot(toygroups$groups) +     geom_point(aes(x = x, y = size))    ggplot(toygroups$df.rate) +     geom_line(aes(x, rate)) }  # }"},{"path":"/reference/tsplit.inla.mesh.html","id":null,"dir":"Reference","previous_headings":"","what":"Split triangles of a mesh into four triangles — tsplit.inla.mesh","title":"Split triangles of a mesh into four triangles — tsplit.inla.mesh","text":"Warning: reconstruct interior boundary Warning2: Works euclidean coordinates. suitable sphere.","code":""},{"path":"/reference/tsplit.inla.mesh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split triangles of a mesh into four triangles — tsplit.inla.mesh","text":"","code":"tsplit.inla.mesh(mesh, n = 1)"},{"path":"/reference/tsplit.inla.mesh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split triangles of a mesh into four triangles — tsplit.inla.mesh","text":"mesh inla.mesh object n number splitting recursions","code":""},{"path":"/reference/tsplit.inla.mesh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split triangles of a mesh into four triangles — tsplit.inla.mesh","text":"mesh refined inla.mesh object","code":""},{"path":"/reference/tsplit.inla.mesh.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Split triangles of a mesh into four triangles — tsplit.inla.mesh","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"/reference/vertices.html","id":null,"dir":"Reference","previous_headings":"","what":"Vertices — vertices","title":"Vertices — vertices","text":"generic function. outcome depends object provided","code":""},{"path":"/reference/vertices.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Vertices — vertices","text":"","code":"vertices(object)  # S4 method for inla.mesh vertices(object)"},{"path":"/reference/vertices.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Vertices — vertices","text":"object object call particular vertices method.","code":""},{"path":"/reference/vertices.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Vertices — vertices","text":"form value returned vertices() depends class argument. See documentation particular methods details produced method.","code":""},{"path":"/reference/vertices.inla.mesh.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract vertex locations from an inla.mesh — vertices.inla.mesh","title":"Extract vertex locations from an inla.mesh — vertices.inla.mesh","text":"Converts vertices inla.mesh object SpatialPointsDataFrame.","code":""},{"path":"/reference/vertices.inla.mesh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract vertex locations from an inla.mesh — vertices.inla.mesh","text":"","code":"vertices.inla.mesh(object)"},{"path":"/reference/vertices.inla.mesh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract vertex locations from an inla.mesh — vertices.inla.mesh","text":"object inla.mesh object.","code":""},{"path":"/reference/vertices.inla.mesh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract vertex locations from an inla.mesh — vertices.inla.mesh","text":"SpatialPointsDataFrame mesh vertex locations. vrt column indicates internal vertex id.","code":""},{"path":"/reference/vertices.inla.mesh.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract vertex locations from an inla.mesh — vertices.inla.mesh","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"/reference/vertices.inla.mesh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract vertex locations from an inla.mesh — vertices.inla.mesh","text":"","code":"# \\donttest{ if (require(ggplot2, quietly = TRUE)) {   data(\"mrsea\", package = \"inlabru\")   vrt <- vertices(mrsea$mesh)   ggplot() +     gg(mrsea$mesh) +     gg(vrt, color = \"red\") } #> Error in UseMethod(\"vertices\"): no applicable method for 'vertices' applied to an object of class \"inla.mesh\" # }"},{"path":"/reference/wkt_tree.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal WKT handling — fm_wkt_as_wkt_tree","title":"Internal WKT handling — fm_wkt_as_wkt_tree","text":"Conversion WKT tree representation","code":""},{"path":"/reference/wkt_tree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal WKT handling — fm_wkt_as_wkt_tree","text":"","code":"fm_wkt_as_wkt_tree(x, ...)  fm_wkt_tree_as_wkt(x, pretty = FALSE, ...)  fm_wkt_tree_get_item(x, item, duplicate = 1)  fm_wkt_tree_set_item(x, item_tree, duplicate = 1)"},{"path":"/reference/wkt_tree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal WKT handling — fm_wkt_as_wkt_tree","text":"x WKT2 string, wkt_tree list structure ... Unused pretty logical; TRUE, use pretty formatting. Default: FALSE item character vector item labels identifying parameter item entry. duplicate items one match, duplicate indicates index number desired version. Default: 1 item_tree item tree identifying parameter item entry","code":""},{"path":[]},{"path":"/news/index.html","id":"feaures-development-version","dir":"Changelog","previous_headings":"","what":"Feaures","title":"inlabru (development version)","text":"Add bru_get_mapper generic, associated methods inla.spde inla.rgeneric objects. allows inlabru automatically extract appropriate bru_mapper object model component, can used hook external packages implementing new INLA object classes. Add weights argument like(), likelihood-specific log-likelihood weights, passed INLA::inla() weights argument. Evaluated data context.","code":""},{"path":"/news/index.html","id":"bug-fixes-development-version","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"inlabru (development version)","text":"Enable datum/ensemble container ellipsoid information, support epsg:4326. Fixes #154 Make duplicated component names error instead warning. Relates #155","code":""},{"path":"/news/index.html","id":"inlabru-253","dir":"Changelog","previous_headings":"","what":"inlabru 2.5.3","title":"inlabru 2.5.3","text":"CRAN release: 2022-09-05","code":""},{"path":"/news/index.html","id":"features-2-5-3","dir":"Changelog","previous_headings":"","what":"Features","title":"inlabru 2.5.3","text":"Add bru_mapper_harmonics mapper cos sin basis sets. Allow predict() input data list. Allow arbitrary quantile summaries predict() Remove cv, var, smin, smax summaries predict() Add mean.mc_std_err sd.mc_std_err output predict() Add robins_subset data set associated variable coefficient web vignette","code":""},{"path":"/news/index.html","id":"bug-fixes-2-5-3","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"inlabru 2.5.3","text":"Propagate multi-likelihood -matrix information instead recomputing. Fixes iteration issue bym2 bru_mapper_collect models. Turn predictor summaries iterations allow inla.mode=\"classic\" use proper line search. Avoid deprecated Matrix (>=1.4-2) class coercion methods Work around lack full Matrix ModelMatrix support unique method. Fixes #145","code":""},{"path":"/news/index.html","id":"inlabru-252","dir":"Changelog","previous_headings":"","what":"inlabru 2.5.2","title":"inlabru 2.5.2","text":"CRAN release: 2022-03-30 robust package checks robust namespace INLA availability checks Add package vignette links website examples","code":""},{"path":"/news/index.html","id":"inlabru-251","dir":"Changelog","previous_headings":"","what":"inlabru 2.5.1","title":"inlabru 2.5.1","text":"Revert R language features compatible R 4.0.5 Use strategy=\"gaussian\" iterations.","code":""},{"path":"/news/index.html","id":"inlabru-250","dir":"Changelog","previous_headings":"","what":"inlabru 2.5.0","title":"inlabru 2.5.0","text":"CRAN release: 2022-03-21","code":""},{"path":"/news/index.html","id":"features-2-5-0","dir":"Changelog","previous_headings":"","what":"Features","title":"inlabru 2.5.0","text":"Add bru() timing information $bru_timings $bru_iinla$timings Add SpatialPolygonsDataFrame support gg() methods Allow accessing E Ntrials response_data data (special arguments remain added) deltaIC improvements New transformation helper tools bru_{forward/inverse}_transformation() Experimental support matrix formula component inputs. E.g. ~ name(~ -1 + + b + :b, model = \"fixed\"), covariate fixed effect interaction specifications can made. formula input, MatrixModels::model.Matrix() called construct matrix input used -matrix fixed effects, one per column, added form combined effect. Documentation examples improvements","code":""},{"path":"/news/index.html","id":"bug-fixes-2-5-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"inlabru 2.5.0","text":"Fix -matrix construction evaluate_model() cases inla_f argument matters efficient robust mesh integration code Cleanup environment handling component lists","code":""},{"path":"/news/index.html","id":"inlabru-240","dir":"Changelog","previous_headings":"","what":"inlabru 2.4.0","title":"inlabru 2.4.0","text":"CRAN release: 2021-12-19","code":""},{"path":"/news/index.html","id":"features-2-4-0","dir":"Changelog","previous_headings":"","what":"Features","title":"inlabru 2.4.0","text":"Allow predictors different size input data. data argument now allowed list(), new argument response_data allows separate specification component inputs response variables. Add bru_mapper_collect class handling sequential collections mappers, including collections first mapper hidden INLA::f() arguments n values, needed support e.g. “bym2” models. Add control.family direct argument like(). Gives warning control.family argument supplied options argument bru(), least one likelihood control.family information. (Issue #109)","code":""},{"path":"/news/index.html","id":"bugfixes-2-4-0","dir":"Changelog","previous_headings":"","what":"Bugfixes","title":"inlabru 2.4.0","text":"Fix support SpatialPointsDataFrame SpatialGridDataFrame input bru_fill_missing() Force explicit model = \"offset\" components instead special options, avoid interfering linearisation system (Issue #123) Make iterations robust resetting internal INLA predictor states initial value zero step","code":""},{"path":"/news/index.html","id":"miscellaneous-2-4-0","dir":"Changelog","previous_headings":"","what":"Miscellaneous","title":"inlabru 2.4.0","text":"Rename option bru_method$stop_at_max_rel_deviation bru_method$rel_tol. Automatic conversion new name, warning given. Add option bru_method$max_step control largest allowed line search scaling factor. See ?bru_options New default option bru_compress_cp set TRUE compress predictor expression family=\"cp\" use single element linear predictor sum.","code":""},{"path":"/news/index.html","id":"inlabru-231","dir":"Changelog","previous_headings":"","what":"inlabru 2.3.1","title":"inlabru 2.3.1","text":"CRAN release: 2021-03-22 Documentation dependency updates CRAN compatibility See NEWS version 2.3.0 major updates since version 2.1.13","code":""},{"path":"/news/index.html","id":"inlabru-230","dir":"Changelog","previous_headings":"","what":"inlabru 2.3.0","title":"inlabru 2.3.0","text":"CRAN release: 2021-03-16","code":""},{"path":"/news/index.html","id":"breaking-changes-since-version-2-3-0","dir":"Changelog","previous_headings":"","what":"Breaking changes since version 2.1.13","title":"inlabru 2.3.0","text":"model component argument map deprecated. Use main specify main component input, ~ elev(main = elevation, model = \"rw2\"). Unlike old map argument, main first one, shorter version ~ elev(elevation, model = \"rw2\") also works. Intercept-like components now explicit inputs, e.g. ~ Intercept(1) avoid accidental confusion variables. argument list bru() simplified, arguments except components options must either outputs calls like(), arguments can sent single like() call. option setting system replaced coherent system; see ?bru_options() details. samplers domain system lgcp models now stricter, requires explicit domain definitions point process dimensions. Alternatively, user-defined integration schemes can supplied via ips argument.","code":""},{"path":"/news/index.html","id":"new-features-since-version-2-3-0","dir":"Changelog","previous_headings":"","what":"New features since version 2.1.13","title":"inlabru 2.3.0","text":"model component input arguments main, group, replicate, weights can now take general R expressions using data inputs. Special cases detected: SpatialPixels/GridDataFrame objects evaluated spatial locations input data SpatialPointsDataFrame object. Functions evaluated data object, e.g. field(coordinates, model = spde) component arguments mapper, group_mapper, replicate_mapper can used precise control mapping inputs latent variables. See ?bru_mapper details. Mapper information automatically extracted INLA::inla.spde2.pcmatern() model objects. R-INLA weights copy features now supported. predictor expressions can access data object directly via .data. data several rows can affect output row, allow_combine = TRUE argument must supplied like() include exclude arguments like(), generate(), predict() can used specify components used given likelihood model predictor expression. can used prevent evaluation components invalid likelihood predictor. Predictor expressions can access latent state model component directly, adding suffix _latent component name, e.g. name_latent. like(), requires allow_latent = TRUE activate needed linearisation code . Predictor expressions can evaluate component effects arbitrary inputs adding suffix _eval access special evaluator functions, e.g. name_eval(1:10). useful evaluating 1D effect spatial covariates. See NEWS item version 2.2.8 details. internal system predictor linearisation iterated INLA inference rewritten faster robust See NEWS entries versions 2.1.14 2.2.8 details new features bug fixes","code":""},{"path":"/news/index.html","id":"inlabru-228","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.8","title":"inlabru 2.2.8","text":"Add _eval suffix feature generate.bru predict.bru, provides general evaluator function component, allowing evaluation e.g. nonlinear effects spatial covariates function covariate value instead spatial evaluator used component definition. example, components = ~ covar(spatial_grid_df, model = \"rw1\"), prediction expression can ~ covar_eval(covariate), covariate data column prediction data object. components group replicate features, also need provided _eval function, ..._eval(..., group = ..., replicate = ...) feature built top _latent suffix feature, gives direct access latent state variables component, order use _eval model predictor , must use like(..., allow_latent = TRUE) model definition.","code":""},{"path":"/news/index.html","id":"inlabru-227","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.7","title":"inlabru 2.2.7","text":"Add support ngroup nrep component definitions Updated mexdolphin mrsea data sets, consistent km units improved mesh designs","code":""},{"path":"/news/index.html","id":"inlabru-226","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.6","title":"inlabru 2.2.6","text":"Add predict(..., include) discussion distance sampling vignette, handling non-spatial prediction spatial models. Fix bugs gg.SpatialLines","code":""},{"path":"/news/index.html","id":"inlabru-225","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.5","title":"inlabru 2.2.5","text":"Vignette corrections Documentation improvements Fix minor bug Spatial* object handling plotting","code":""},{"path":"/news/index.html","id":"inlabru-224","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.4","title":"inlabru 2.2.4","text":"Properly extract joint latent conditional mode instead marginal latent conditional mode","code":""},{"path":"/news/index.html","id":"inlabru-222","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.2","title":"inlabru 2.2.2","text":"Fixed issue predict() logic converting output Spatial*DataFrame Use control.mode=list(restart=FALSE) final inla run nonlinear models, avoid unnecessary optimisation. Fix issues pixels() bru_fill_missing() Spatial*DataFrame objects ncol=0 data frame parts.","code":""},{"path":"/news/index.html","id":"inlabru-221","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.1","title":"inlabru 2.2.1","text":"Fixed code regression bug function input covariates","code":""},{"path":"/news/index.html","id":"inlabru-220","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.0","title":"inlabru 2.2.0","text":"Support INLA “copy” feature, comp2(input, copy = \"comp1\") Allow component weights unnamed parameter, comp(input, weights, ...) Direct access data objects component inputs predictor expressions, .data., allowing e.g. covar(fun(.data.), ...) complex covariate extractor method fun() Partial support spherical manifold meshes Uses INLA integration strategy “eb” initial nonlinear iterations, specified integration strategy final iteration, computations faster, uses conditional latent mode linearisation point.","code":""},{"path":"/news/index.html","id":"inlabru-2115","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.15","title":"inlabru 2.1.15","text":"New options system New faster linearisation method New line search method make nonlinear inla iterations robust Method updating old stored estimation objects System supplying mappings latent models evaluated effects via bru_mapper objects Improved factor support; Either “contrast 1st level”, via special \"factor_contrast\" model, levels model \"factor_full\". options planned (e.g. simpler options fix precision parameter). estimated coefficients appear random effects inla() output. Interface restructuring support new features keeping backwards compatibility. Change map= main= unnamed first argument; Since main first parameter, doesn’t need named argument. Keep components zero derivative linearisation PROJ6 support Add random seed option posterior sampling Add package unit testing New backend code make extended feature support easier New int.args option control spatial integration resolution, thanks Martin Jullum (martinju)","code":""},{"path":"/news/index.html","id":"inlabru-2113","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.13","title":"inlabru 2.1.13","text":"CRAN release: 2020-02-16 Fix CRAN complaint regarding documentation","code":""},{"path":"/news/index.html","id":"inlabru-2112","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.12","title":"inlabru 2.1.12","text":"CRAN release: 2019-06-24 Workaround integration points error old (ca pre-2018) INLA versions","code":""},{"path":"/news/index.html","id":"inlabru-2111","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.11","title":"inlabru 2.1.11","text":"Add CITATION file","code":""},{"path":"/news/index.html","id":"inlabru-2110","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.10","title":"inlabru 2.1.10","text":"Fix internal sampling bug due INLA changes","code":""},{"path":"/news/index.html","id":"inlabru-219","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.9","title":"inlabru 2.1.9","text":"CRAN release: 2018-07-24 Remove unused VignetteBuilder entry DESCRIPTION","code":""},{"path":"/news/index.html","id":"inlabru-218","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.8","title":"inlabru 2.1.8","text":"Update default options Prevent int.polygon integrating outside mesh domain, generally robust integration scheme construction. Fix bru() like() parameter logic. (Thanks Peter Vesk bug example)","code":""},{"path":"/news/index.html","id":"inlabru-217","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.7","title":"inlabru 2.1.7","text":"Added NEWS.md file track changes package. Added inla methods predict() generate() convert inla output bru objects calling bru prediction posterior sample generator. Added protection examples requiring optional packages Fix sample.lgcp output formatting, extended CRS support, efficient sampling algorithm Avoid dense matrices effect mapping","code":""},{"path":"/news/index.html","id":"inlabru-214","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.4","title":"inlabru 2.1.4","text":"iinla() tracks convergence fixed random effects","code":""},{"path":"/news/index.html","id":"inlabru-213","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.3","title":"inlabru 2.1.3","text":"CRAN release: 2018-02-11 Added matrix geom gg.matrix() Fixed CRAN test issues","code":""}]
