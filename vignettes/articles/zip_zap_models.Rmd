---
title: "Devel: ZIP and ZAP models"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Devel: ZIP and ZAP models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
header-includes:
  - \newcommand{\bm}[1]{\boldsymbol{#1}}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = TRUE
)
```

(Vignette under construction!)

```{r setup, eval=TRUE, echo=TRUE, include=TRUE, message=FALSE}
library(dplyr)
library(ggplot2)
library(inlabru)
library(terra)
library(sf)
library(RColorBrewer)
library(magrittr)
library(patchwork)

# We want to obtain CPO data from the estimations
bru_options_set(control.compute = list(cpo = TRUE))
```

# Count model

In addition to point process models, `inlabru` can handle models with positive integer response, e.g. abundance models where species counts are recorded in every observed location. Count models can be seen as coarse aggregations of point process models.

The following example uses `gorillas` dataset. In order to obtain the counts data we rasterize the species count to the same granularity as the spatial covariates available for the `gorilla` data, and then aggregate the pixels to cover 25 times bigger area (5x5 pixels in original covariate raster dimensions). Finally, we mask the regions outside of study area.

```{r fig-count-raster, fig.cap="Counts of gorilla nests", fig.width=7, fig.height=5,out.width="80%", fig.align='center'}
gorillas_sf <- inlabru::gorillas_sf
nests <- gorillas_sf$nests
mesh <- gorillas_sf$mesh
boundary <- gorillas_sf$boundary
gcov <- gorillas_sf_gcov()
counts_rstr <- terra::rasterize(vect(nests), gcov, fun = sum, background = 0) %>%
  terra::aggregate(fact = 4, fun = sum) %>%
  mask(vect(boundary))
plot(counts_rstr)
counts_rstr <- counts_rstr %>%
  cellSize(unit = "km") %>%
  c(counts_rstr)
```

Now we need to extract the coordinates for these pixels. The plot below shows pixel locations for all pixels with non-zero counts.

```{r}
counts_df <- crds(counts_rstr, df = TRUE, na.rm = TRUE) %>%
  bind_cols(values(counts_rstr, mat = TRUE, na.rm = TRUE)) %>%
  rename(count = sum) %>%
  mutate(present = count > 0) %>%
  st_as_sf(coords = c("x", "y"), crs = st_crs(nests))
```


> What is the probability of encountering 0,1,2... nests per study site?

We create a mesh over the study sites and define a prior for it.

```{r fig-count-mesh, fig.cap="Mesh over the count locations", fig.width=7, fig.height=5,out.width="80%", fig.align='center'}
px_mesh <- fm_mesh_2d_inla(
  loc = st_intersection(st_as_sfc(counts_df), st_buffer(boundary, -0.05)),
  boundary = boundary,
  max.edge = c(0.5, 1),
  crs = st_crs(counts_df)
)

px_matern <- INLA::inla.spde2.pcmatern(px_mesh,
  prior.sigma = c(0.1, 0.01),
  prior.range = c(0.1, 0.01)
)

ggplot() +
  geom_fm(data = px_mesh) +
  # geom_sf(data=counts_df, aes(color=count), size=1, pch=4)+
  theme_minimal()
```

## Poisson GLM

Now we can define the Poisson model which relates the species count per observation plot to the spatial covariates, such as the vegetation type and elevation. In order to make the vegetation effect estimates identifiable relative to the intercept, we use `model = "factor_full"` and a sum-to-zero constraint. 
An alternative would be `model = "factor_contrast"` without constraint, but that would require a factor level reordering to avoid the most uncommon vegetation type being the reference level.

```{r fig-predict-poi, fig.width=7, fig.height=5, out.width="80%", fig.align='center'}
comps <- ~ vegetation(gcov$vegetation,
  model = "factor_full",
  hyper = list(prec = list(initial = log(1 / 0.1^2), fixed = TRUE)),
  constr = TRUE
) +
  elevation(gcov$elevation, model = "linear") +
  field(geometry, model = px_matern) + Intercept(1)

fit_poi <- bru(
  comps,
  like(
    family = "poisson", data = counts_df,
    formula = count ~ vegetation + elevation + field + Intercept,
    E = area
  )
)
summary(fit_poi)


expect_poi <- predict(
  fit_poi, counts_df,
  ~ exp(vegetation + elevation + field + Intercept) * area,
  n.samples = 2500
)
# For Poisson, the posterior conditional variance is equal to
# the posterior conditional mean, so no need to compute it separately.
expect_poi$pred_var <- expect_poi$mean + expect_poi$sd^2

ggplot() +
  geom_fm(data = px_mesh) +
  gg(expect_poi, aes(fill = mean / area), geom = "tile") +
  geom_sf(data = nests, color = "firebrick", size = 1, pch = 4, alpha = 0.2) +
  ggtitle("Nest intensity per 1.2 ha")
```

## True zeroes and false zeroes

The Poisson GLM model may produce zeros in some locations. These are called "true zeroes", because they are explained by the model and the covariates. The "false zeroes" do not comply with the covariates. They can appear because of the imperfection in sampling (wrong time or place), observer errors, non-suitable environment characteristics, etc. 

The number of zeros in our data is large and our model may not be able to accommodate for them. We should pick a model which can handle "inflated" number of zeros, i.e. in excess of what is implied by a regular Poisson model. For that we pick a "zero-inflated Poisson model", or simply, ZIP.

## ZIP model

The [Type 1 Zero-inflated Poisson model](https://inla.r-inla-download.org/r-inla.org/doc/likelihood/zeroinflated.pdf) is given by

$$
\text{Prob}(y\vert\dots)=p\times 1_{y=0}+(1-p)\times \text{Poisson}(y)
$$

where $p=\text{logit}^{-1}(\theta)$

The expectation and variance for the counts are calculated as 

$$
\begin{gathered}
E(count)=(1-p)\lambda \\
Var(count)= (1-p)(\lambda+p \lambda^2)
\end{gathered}
$$


```{r fig-pred-zip, fig.cap="Predictions from zero-inflated model",fig.width=7, fig.height=5, out.width="80%", fig.align='center'}
fit_zip <- bru(
  comps,
  like(
    family = "zeroinflatedpoisson1", data = counts_df,
    formula = count ~ vegetation + elevation + field + Intercept,
    E = area
  )
)

summary(fit_zip)

pred_zip <- predict(
  fit_zip, counts_df,
  ~ {
    scaling_prob <- (1 - zero_probability_parameter_for_zero_inflated_poisson_1)
    lambda <- exp(vegetation + elevation + field + Intercept)
    expect <- scaling_prob * lambda * area
    variance <- expect * (1 + (1 - scaling_prob) * lambda * area)
    list(
      lambda = lambda,
      expect = expect,
      variance = variance
    )
  },
  n.samples = 2500
)
expect_zip <- pred_zip$expect
expect_zip$pred_var <- pred_zip$variance$mean + expect_zip$sd^2

ggplot() +
  geom_fm(data = px_mesh) +
  gg(expect_zip, aes(fill = mean / area), geom = "tile") +
  geom_sf(data = nests, color = "firebrick", size = 1, pch = 4, alpha = 0.2) +
  ggtitle("Nest intensity per 1.2 ha")
```

We will compare the performance of the models in the diagnostic section below.
<!-- This model is much better at differentiating between the sites and produces sensible predictions. [Note: this may not be the case; need to sort out the factor ordering and priors; check the diagnostic section below as well.] -->

## ZAP model

Judging by the distribution of nests in relation to the [spatial covariates](2d_lgcp_covars.Rmd), gorillas do not like to set their nests in certain vegetation. The type of vegetation may not influence the density of the nests, but it definitely drives the presence/absence. In this case the `vegetation` covariate should be included in the binomial part of the model, but not the Poisson part. 

Whenever the process that drives presence/absence is substantially different from the process that drives the abundance it is wise to switch to the Zero-Adjusted Poisson (ZAP) model, which consists of binomial and the truncated Poisson parts.

We switch to `zeroinflatedpoisson0` which has the [following likelihood](https://inla.r-inla-download.org/r-inla.org/doc/likelihood/zeroinflated.pdf)

$$
\text{Prob}(y\vert\dots)=p\times 1_{y=0}+(1-p)\times \text{Poisson}(y\vert y>0)
$$

where $p=\text{logit}^{-1}(\theta)$.  

Here ZIP distribution only governs the positive counts and the absences will be handled by a separate binomial model which can have its own covariates. Note, that we exclude the observations with absent nests from the ZIP part of the model by subsetting the data to include only observations where `present` is `TRUE`.

The expectation and variance are computed as

$$
\begin{aligned}
E(count)&=\frac{1}{1-\exp(-\lambda)}p\lambda \\
Var(count)&= \frac{1}{1-\exp(-\lambda)}  p(\lambda+p \lambda^2)-\left(\frac{1}{1-\exp(-\lambda)}p\lambda\right)^2 \\
&= E(count) (1+p\lambda) - E(count)^2 \\
&= E(count) (1+p\lambda-E(count)) \\
&= E(count) \left(1+p\lambda\left(1-\frac{1}{1-\exp(-\lambda)}\right)\right) \\
&= E(count) \left(1-p\lambda\frac{\exp(-\lambda)}{1-\exp(-\lambda)}\right) \\
&= E(count) \left(1-\exp(-\lambda) E(count)\right)
\end{aligned}
$$

```{r fig-pred-zap, fig.cap="Predictions from zero-adjusted model",fig.width=10, fig.height=5, out.width="100%", fig.align='center'}
comps <- ~ vegetation(gcov$vegetation,
  model = "factor_full",
  hyper = list(prec = list(initial = log(1 / 0.1^2), fixed = TRUE)),
  constr = TRUE
) +
  elevation(gcov$elevation, model = "linear") +
  field(geometry, model = px_matern) + Intercept_present(1) + Intercept_count(1) +
  elevation_present(gcov$elevation, model = "linear") +
  field_present(geometry, copy = "field")

fit_zap <- bru(
  comps,
  like(
    family = "binomial",
    data = counts_df,
    formula = present ~ vegetation + elevation_present + field_present + Intercept_present
  ),
  like(
    family = "zeroinflatedpoisson0",
    data = counts_df[counts_df$present, ],
    formula = count ~ elevation + field + Intercept_count,
    E = area,
    control.family = list(hyper = list(theta = list(initial = -20, fixed = TRUE)))
  )
)
summary(fit_zap)

# Predict intensity on the original raster locations
pred_zap <- predict(
  fit_zap,
  counts_df,
  ~ {
    presence_prob <-
      plogis(vegetation + elevation_present + field_present + Intercept_present)
    lambda <- exp(elevation + field + Intercept_count)
    expect <- presence_prob * lambda * area / (1 - exp(-lambda * area))
    variance <- expect * (1 - exp(-lambda * area) * expect)
    list(
      presence = presence_prob,
      lambda = lambda,
      expect = expect,
      variance = variance
    )
  },
  n.samples = 2500
)
presence_zap <- pred_zap$presence
expect_zap <- pred_zap$expect
expect_zap$pred_var <- pred_zap$variance$mean + expect_zap$sd^2

p1 <- ggplot() +
  geom_fm(data = px_mesh) +
  gg(presence_zap, aes(fill = mean), geom = "tile") +
  geom_sf(data = nests, color = "firebrick", size = 1, pch = 4, alpha = 0.2) +
  ggtitle("Presence probability")
p2 <- ggplot() +
  geom_fm(data = px_mesh) +
  gg(expect_zap, aes(fill = mean / area), geom = "tile") +
  geom_sf(data = nests, color = "firebrick", size = 1, pch = 4, alpha = 0.2) +
  ggtitle("Nest expect per 1.2 ha")

patchwork::wrap_plots(p1, p2, nrow = 1)
```

In order to make sure that Poisson distribution will be properly truncated, we included the `control.family` argument with the parameter `theta` (which gets translated into the probability $p$) is fixed to a large negative value, such that when transformed by $\text{logit}^{-1}(\theta)=p$ it would end up close to zero.

## Model comparison

The count prediction variance can be obtained from the posterior predictions of expectations and variances previously computed for each grid box. Let $m_i$ denote the count expectation in each grid box, and let $s_i^2$ denote the count variance, both conditionally on the model predictor $\eta_i$. Then the posterior predictive variance of the count $X_i$ is

$$
\begin{aligned}
V(X_i) &= E(V(X_i|\eta_i)) + V(E(X_i|\eta_i)) \\
&= E(s_i^2) + V(m_i) .
\end{aligned}
$$


```{r, out.width="100%", fig.width=10, fig.height=5, fig.align='center'}
zap_pit <- rep(NA_real_, nrow(counts_df))
zap_pit[counts_df$count > 0] <- fit_zap$cpo$pit[-seq_len(nrow(counts_df))]

df <- data.frame(
  count = rep(counts_df$count, times = 3),
  pred_mean = c(
    expect_poi$mean,
    expect_zip$mean,
    expect_zap$mean
  ),
  pred_var = c(
    expect_poi$pred_var,
    expect_zip$pred_var,
    expect_zap$pred_var
  ),
  pred_median = c(
    expect_poi$median,
    expect_zip$median,
    expect_zap$median
  ),
  pit = c(
    fit_poi$cpo$pit * c(NA_real_, 1)[1 + (counts_df$count > 0)],
    fit_zip$cpo$pit * c(NA_real_, 1)[1 + (counts_df$count > 0)],
    zap_pit
  ),
  Model = rep(c("Poisson", "ZIP", "ZAP"), each = nrow(counts_df))
)

p1 <- ggplot(df) +
  geom_point(aes(pred_mean, count - pred_mean, color = Model)) +
  ggtitle("Residuals")

p2 <- ggplot(df) +
  stat_ecdf(aes(pit, color = Model), na.rm = TRUE) +
  scale_x_continuous(expand = c(0, 0)) +
  ggtitle("PIT")

patchwork::wrap_plots(p1, p2, nrow = 1, guides = "collect")
```

### Prediction scores

We compute three prediction scores, Absolute Error (AE), Squared Error (SE),
and Dawid-Sebastiani (DS):

$$
\begin{aligned}
\text{AE}_i&=|y_i-\text{median}_i|,\\
\text{SE}_i&=(y_i-E(X_i))^2, \text{ and}\\
\text{DS}_i&=\frac{\sum_i (y_i-E(X_i))^2}{V(X_i)} + \log[V(X_i)].
\end{aligned}
$$
The Dawid-Sebastiani score is a proper scoring rule for the
predictive mean $E(X_i)$ and variance $V(X_i)$. AE and SE are proper scores for
the median and expectation, respectively.

```{r, out.width="100%", fig.width=15, fig.height=5, fig.align='center'}
df <- df %>%
  mutate(
    AE = abs(count - pred_median),
    SE = (count - pred_mean)^2,
    DS = (count - pred_mean)^2 / pred_var + log(pred_var)
  )

scores <- df %>%
  group_by(Model) %>%
  summarise(
    MAE = mean(AE),
            MSE = sqrt(mean(SE)),
            MDS = mean(DS)) %>%
  left_join(data.frame(
    Model = c("Poisson", "ZIP", "ZAP"),
                       Order = 1:3),
            by = "Model") %>%
  arrange(Order) %>%
  select(-Order)
knitr::kable(scores)
```
We see that the average scores are very similar between all three models.

```{r, out.width="100%", fig.width=15, fig.height=5, fig.align='center'}
df <- df %>%
  tibble::as_tibble() %>%
  cbind(geometry = c(counts_df$geometry, counts_df$geometry, counts_df$geometry))
df_ <- df %>%
  left_join(df %>%
              filter(Model == "Poisson") %>%
              select(geometry, DS_Poisson = DS),
            by = c("geometry")) %>%
  sf::st_as_sf()
p1 <- ggplot() +
  geom_fm(data = px_mesh) +
  gg(df_, aes(fill = DS), geom = "tile") +
  geom_sf(data = nests, color = "firebrick", size = 1, pch = 4, alpha = 0.2) +
  ggtitle("Poisson Dawid-Sebastiani scores") +
  guides(fill = guide_legend("DS"))
p2 <- ggplot() +
  geom_fm(data = px_mesh) +
  gg(df_, aes(fill = DS - DS_Poisson), geom = "tile") +
  geom_sf(data = nests, color = "firebrick", size = 1, pch = 4, alpha = 0.2) +
  ggtitle("ZIP Dawid-Sebastiani score difference") +
  guides(fill = guide_legend("DS-DS_poi"))
p3 <- ggplot() +
  geom_fm(data = px_mesh) +
  gg(df_, aes(fill = DS - DS_Poisson), geom = "tile") +
  geom_sf(data = nests, color = "firebrick", size = 1, pch = 4, alpha = 0.2) +
  ggtitle("ZAP Dawid-Sebastiani score difference") +
  guides(fill = guide_legend("DS-DS_poi"))

patchwork::wrap_plots(p1, p2, p3, nrow = 1)
```
